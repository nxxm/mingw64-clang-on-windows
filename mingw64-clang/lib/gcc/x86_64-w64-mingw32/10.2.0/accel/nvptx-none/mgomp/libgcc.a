!<arch>
//                                              24        `
enable-execute-stack.o/
_muldi3.o/      1608280938  0     0     100666  2209      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __multi3
.visible .func __multi3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __multi3
.visible .func __multi3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,16;
sub.u64 %stack,%frame,0;
}
.reg .u64 %r41;
.reg .u64 %r42;
.reg .u64 %r43;
.reg .u64 %r44;
.reg .u64 %r45;
.reg .u64 %r46;
.reg .u64 %r48;
.reg .u64 %r49;
.reg .u64 %r55;
.reg .u64 %r56;
.reg .u64 %r57;
.reg .u64 %r59;
.reg .u64 %r62;
.reg .pred %r63;
.reg .u64 %r64;
.reg .u64 %r65;
.reg .u64 %r67;
.reg .u64 %r68;
.reg .u64 %r69;
.reg .u64 %r74;
.reg .u64 %r78;
.reg .u64 %r83;
.reg .u64 %r84;
.reg .u64 %r85;
.reg .u64 %r86;
mov.u64 %r56,%ar0;
mov.u64 %r57,%ar1;
ld.u64 %r83,[%r57];
ld.u64 %r84,[%r57+8];
mov.u64 %r59,%ar2;
ld.u64 %r85,[%r59];
ld.u64 %r86,[%r59+8];
.loc 1 552 22
and.b64 %r42,%r83,4294967295;
shr.u64 %r43,%r83,32;
and.b64 %r44,%r85,4294967295;
shr.u64 %r45,%r85,32;
mul.lo.u64 %r46,%r42,%r44;
mul.lo.u64 %r48,%r43,%r44;
mul.lo.u64 %r41,%r43,%r45;
mad.lo.u64 %r55,%r42,%r45,%r48;
shr.u64 %r62,%r46,32;
add.u64 %r49,%r62,%r55;
setp.le.u64 %r63,%r48,%r49;
@ %r63 bra $L2;
add.u64 %r41,%r41,4294967296;
$L2:
shr.u64 %r64,%r49,32;
add.u64 %r65,%r64,%r41;
shl.b64 %r67,%r49,32;
and.b64 %r68,%r46,4294967295;
add.u64 %r69,%r67,%r68;
.loc 1 554 12
mad.lo.u64 %r74,%r83,%r86,%r65;
mad.lo.u64 %r78,%r85,%r84,%r74;
.loc 1 557 11
st.u64 [%r56],%r69;
st.u64 [%r56+8],%r78;
.loc 1 558 1
ret;
}

_negdi2.o/      1608280938  0     0     100666  1325      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __negti2
.visible .func __negti2 (.param .u64 %in_ar0, .param .u64 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __negti2
.visible .func __negti2 (.param .u64 %in_ar0, .param .u64 %in_ar1)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,16;
sub.u64 %stack,%frame,0;
}
.reg .u64 %r30;
.reg .u64 %r31;
.reg .u64 %r33;
.reg .u64 %r36;
.reg .u32 %r37;
.reg .u64 %r39;
.reg .u64 %r42;
.reg .u64 %r43;
mov.u64 %r30,%ar0;
mov.u64 %r31,%ar1;
ld.u64 %r42,[%r31];
ld.u64 %r43,[%r31+8];
.loc 1 67 31
neg.s64 %r33,%r42;
.loc 1 68 51
set.u32.ne.u64 %r37,%r42,0;
cvt.s64.s32 %r36,%r37;
.loc 1 68 29
sub.u64 %r39,%r36,%r43;
.loc 1 70 11
st.u64 [%r30],%r33;
st.u64 [%r30+8],%r39;
.loc 1 71 1
ret;
}

_lshrdi3.o/     1608280939  0     0     100666  2284      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __lshrti3
.visible .func __lshrti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __lshrti3
.visible .func __lshrti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,16;
sub.u64 %stack,%frame,0;
}
.reg .u32 %r25;
.reg .u64 %r33;
.reg .u32 %r35;
.reg .u64 %r38;
.reg .u64 %r39;
.reg .u64 %r41;
.reg .pred %r42;
.reg .u64 %r45;
.reg .pred %r46;
.reg .u64 %r47;
.reg .u32 %r48;
.reg .u64 %r49;
.reg .u64 %r50;
.reg .u64 %r51;
.reg .u64 %r53;
.reg .u64 %r54;
.reg .u64 %r55;
.reg .u64 %r56;
.reg .u64 %r57;
.reg .u64 %r58;
mov.u64 %r38,%ar0;
mov.u64 %r39,%ar1;
ld.u64 %r57,[%r39];
ld.u64 %r58,[%r39+8];
mov.u64 %r41,%ar2;
.loc 1 406 6
setp.ne.u64 %r42,%r41,0;
@ %r42 bra $L2;
.loc 1 407 12
st.u64 [%r38],%r57;
st.u64 [%r38+8],%r58;
bra $L1;
$L2:
.loc 1 410 26
mov.u64 %r45,64;
sub.u64 %r33,%r45,%r41;
.loc 1 416 36
cvt.u32.u64 %r35,%r33;
.loc 1 413 6
setp.gt.s64 %r46,%r33,0;
@ %r46 bra $L4;
.loc 1 415 16
mov.u64 %r47,0;
st.u64 [%frame+8],%r47;
.loc 1 416 36
neg.s32 %r48,%r35;
shr.u64 %r49,%r58,%r48;
.loc 1 416 15
st.u64 [%frame],%r49;
bra $L5;
$L4:
.loc 1 422 37
cvt.u32.u64 %r25,%r41;
shr.u64 %r50,%r58,%r25;
.loc 1 422 16
st.u64 [%frame+8],%r50;
.loc 1 423 36
shr.u64 %r51,%r57,%r25;
.loc 1 420 20
shl.b64 %r53,%r58,%r35;
.loc 1 423 42
or.b64 %r54,%r51,%r53;
.loc 1 423 15
st.u64 [%frame],%r54;
$L5:
.loc 1 426 11
ld.u64 %r55,[%frame];
st.u64 [%r38],%r55;
ld.u64 %r56,[%frame+8];
st.u64 [%r38+8],%r56;
$L1:
.loc 1 427 1
ret;
}
_ashldi3.o/     1608280939  0     0     100666  2284      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __ashlti3
.visible .func __ashlti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __ashlti3
.visible .func __ashlti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,16;
sub.u64 %stack,%frame,0;
}
.reg .u32 %r25;
.reg .u64 %r33;
.reg .u32 %r36;
.reg .u64 %r38;
.reg .u64 %r39;
.reg .u64 %r41;
.reg .pred %r42;
.reg .u64 %r45;
.reg .pred %r46;
.reg .u64 %r47;
.reg .u32 %r48;
.reg .u64 %r49;
.reg .u64 %r50;
.reg .u64 %r51;
.reg .u64 %r53;
.reg .u64 %r54;
.reg .u64 %r55;
.reg .u64 %r56;
.reg .u64 %r57;
.reg .u64 %r58;
mov.u64 %r38,%ar0;
mov.u64 %r39,%ar1;
ld.u64 %r57,[%r39];
ld.u64 %r58,[%r39+8];
mov.u64 %r41,%ar2;
.loc 1 434 6
setp.ne.u64 %r42,%r41,0;
@ %r42 bra $L2;
.loc 1 435 12
st.u64 [%r38],%r57;
st.u64 [%r38+8],%r58;
bra $L1;
$L2:
.loc 1 438 26
mov.u64 %r45,64;
sub.u64 %r33,%r45,%r41;
.loc 1 444 36
cvt.u32.u64 %r36,%r33;
.loc 1 441 6
setp.gt.s64 %r46,%r33,0;
@ %r46 bra $L4;
.loc 1 443 15
mov.u64 %r47,0;
st.u64 [%frame],%r47;
.loc 1 444 36
neg.s32 %r48,%r36;
shl.b64 %r49,%r57,%r48;
.loc 1 444 16
st.u64 [%frame+8],%r49;
bra $L5;
$L4:
.loc 1 450 35
cvt.u32.u64 %r25,%r41;
shl.b64 %r50,%r57,%r25;
.loc 1 450 15
st.u64 [%frame],%r50;
.loc 1 451 38
shl.b64 %r51,%r58,%r25;
.loc 1 448 20
shr.u64 %r53,%r57,%r36;
.loc 1 451 44
or.b64 %r54,%r51,%r53;
.loc 1 451 16
st.u64 [%frame+8],%r54;
$L5:
.loc 1 454 11
ld.u64 %r55,[%frame];
st.u64 [%r38],%r55;
ld.u64 %r56,[%frame+8];
st.u64 [%r38+8],%r56;
$L1:
.loc 1 455 1
ret;
}
_ashrdi3.o/     1608280939  0     0     100666  2305      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __ashrti3
.visible .func __ashrti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __ashrti3
.visible .func __ashrti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,16;
sub.u64 %stack,%frame,0;
}
.reg .u32 %r26;
.reg .u64 %r33;
.reg .u32 %r36;
.reg .u64 %r37;
.reg .u64 %r38;
.reg .u64 %r40;
.reg .pred %r41;
.reg .u64 %r44;
.reg .pred %r45;
.reg .u64 %r46;
.reg .u32 %r47;
.reg .u64 %r48;
.reg .u64 %r49;
.reg .u64 %r50;
.reg .u64 %r52;
.reg .u64 %r53;
.reg .u64 %r54;
.reg .u64 %r55;
.reg .u64 %r56;
.reg .u64 %r57;
mov.u64 %r37,%ar0;
mov.u64 %r38,%ar1;
ld.u64 %r56,[%r38];
ld.u64 %r57,[%r38+8];
mov.u64 %r40,%ar2;
.loc 1 462 6
setp.ne.u64 %r41,%r40,0;
@ %r41 bra $L2;
.loc 1 463 12
st.u64 [%r37],%r56;
st.u64 [%r37+8],%r57;
bra $L1;
$L2:
.loc 1 466 26
mov.u64 %r44,64;
sub.u64 %r33,%r44,%r40;
.loc 1 473 27
cvt.u32.u64 %r36,%r33;
.loc 1 469 6
setp.gt.s64 %r45,%r33,0;
@ %r45 bra $L4;
.loc 1 472 28
shr.s64 %r46,%r57,63;
.loc 1 472 16
st.u64 [%frame+8],%r46;
.loc 1 473 27
neg.s32 %r47,%r36;
shr.s64 %r48,%r57,%r47;
.loc 1 473 15
st.u64 [%frame],%r48;
bra $L5;
$L4:
.loc 1 479 28
cvt.u32.u64 %r26,%r40;
shr.s64 %r49,%r57,%r26;
.loc 1 479 16
st.u64 [%frame+8],%r49;
.loc 1 480 36
shr.u64 %r50,%r56,%r26;
.loc 1 477 20
shl.b64 %r52,%r57,%r36;
.loc 1 480 42
or.b64 %r53,%r50,%r52;
.loc 1 480 15
st.u64 [%frame],%r53;
$L5:
.loc 1 483 11
ld.u64 %r54,[%frame];
st.u64 [%r37],%r54;
ld.u64 %r55,[%frame+8];
st.u64 [%r37+8],%r55;
$L1:
.loc 1 484 1
ret;
}

_cmpdi2.o/      1608280939  0     0     100666  1330      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __cmpti2
.visible .func (.param .u64 %value_out) __cmpti2 (.param .u64 %in_ar0, .param .u64 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __cmpti2
.visible .func (.param .u64 %value_out) __cmpti2 (.param .u64 %in_ar0, .param .u64 %in_ar1)
{
.reg .u64 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %r26;
.reg .u64 %r27;
.reg .u64 %r29;
.reg .pred %r31;
.reg .pred %r32;
.reg .pred %r33;
.reg .pred %r34;
.reg .u64 %r36;
.reg .u64 %r37;
.reg .u64 %r38;
.reg .u64 %r39;
mov.u64 %r27,%ar0;
ld.u64 %r36,[%r27];
ld.u64 %r37,[%r27+8];
mov.u64 %r29,%ar1;
ld.u64 %r38,[%r29];
ld.u64 %r39,[%r29+8];
.loc 1 1331 6
setp.lt.s64 %r31,%r37,%r39;
@ %r31 bra $L3;
.loc 1 1333 11
setp.gt.s64 %r32,%r37,%r39;
@ %r32 bra $L4;
.loc 1 1335 6
setp.lt.u64 %r33,%r36,%r38;
@ %r33 bra $L5;
.loc 1 1337 11
setp.gt.u64 %r34,%r36,%r38;
.loc 1 1339 10
selp.u64 %r26,2,1,%r34;
bra $L1;
$L3:
.loc 1 1332 12
mov.u64 %r26,0;
bra $L1;
$L4:
.loc 1 1338 12
mov.u64 %r26,2;
bra $L1;
$L5:
.loc 1 1332 12
mov.u64 %r26,0;
$L1:
.loc 1 1340 1
mov.u64 %value,%r26;
st.param.u64 [%value_out],%value;
ret;
}
_ucmpdi2.o/     1608280939  0     0     100666  1334      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __ucmpti2
.visible .func (.param .u64 %value_out) __ucmpti2 (.param .u64 %in_ar0, .param .u64 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __ucmpti2
.visible .func (.param .u64 %value_out) __ucmpti2 (.param .u64 %in_ar0, .param .u64 %in_ar1)
{
.reg .u64 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %r28;
.reg .u64 %r29;
.reg .u64 %r31;
.reg .pred %r33;
.reg .pred %r34;
.reg .pred %r35;
.reg .pred %r36;
.reg .u64 %r38;
.reg .u64 %r39;
.reg .u64 %r40;
.reg .u64 %r41;
mov.u64 %r29,%ar0;
ld.u64 %r38,[%r29];
ld.u64 %r39,[%r29+8];
mov.u64 %r31,%ar1;
ld.u64 %r40,[%r31];
ld.u64 %r41,[%r31+8];
.loc 1 1350 6
setp.lt.u64 %r33,%r39,%r41;
@ %r33 bra $L3;
.loc 1 1352 11
setp.gt.u64 %r34,%r39,%r41;
@ %r34 bra $L4;
.loc 1 1354 6
setp.lt.u64 %r35,%r38,%r40;
@ %r35 bra $L5;
.loc 1 1356 11
setp.gt.u64 %r36,%r38,%r40;
.loc 1 1358 10
selp.u64 %r28,2,1,%r36;
bra $L1;
$L3:
.loc 1 1351 12
mov.u64 %r28,0;
bra $L1;
$L4:
.loc 1 1357 12
mov.u64 %r28,2;
bra $L1;
$L5:
.loc 1 1351 12
mov.u64 %r28,0;
$L1:
.loc 1 1359 1
mov.u64 %value,%r28;
st.param.u64 [%value_out],%value;
ret;
}
_clear_cache.o/ 1608280939  0     0     100666  482       `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __clear_cache
.visible .func __clear_cache (.param .u64 %in_ar0, .param .u64 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __clear_cache
.visible .func __clear_cache (.param .u64 %in_ar0, .param .u64 %in_ar1)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.loc 1 2174 1
ret;
}
_trampoline.o/  1608280939  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_absvsi2.o/     1608280939  0     0     100666  1549      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __absvdi2
.visible .func (.param .u64 %value_out) __absvdi2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DECL: __absvsi2
.visible .func (.param .u32 %value_out) __absvsi2 (.param .u32 %in_ar0);
// BEGIN GLOBAL FUNCTION DECL: abort
.extern .func abort;
// BEGIN GLOBAL FUNCTION DEF: __absvdi2
.visible .func (.param .u64 %value_out) __absvdi2 (.param .u64 %in_ar0)
{
.reg .u64 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r25;
.reg .pred %r26;
.reg .pred %r27;
mov.u64 %r25,%ar0;
.loc 1 221 6
setp.ge.s64 %r26,%r25,0;
@ %r26 bra $L2;
.loc 1 225 9
neg.s64 %r25,%r25;
.loc 1 227 6
setp.ge.s64 %r27,%r25,0;
@ %r27 bra $L2;
.loc 1 228 5
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L2:
.loc 1 232 1
mov.u64 %value,%r25;
st.param.u64 [%value_out],%value;
ret;
}
// BEGIN GLOBAL FUNCTION DEF: __absvsi2
.visible .func (.param .u32 %value_out) __absvsi2 (.param .u32 %in_ar0)
{
.reg .u32 %value;
.reg .u32 %ar0;
ld.param.u32 %ar0,[%in_ar0];
.reg .u32 %r25;
.reg .pred %r26;
.reg .pred %r27;
mov.u32 %r25,%ar0;
.loc 1 239 6
setp.ge.s32 %r26,%r25,0;
@ %r26 bra $L4;
.loc 1 243 9
neg.s32 %r25,%r25;
.loc 1 245 6
setp.ge.s32 %r27,%r25,0;
@ %r27 bra $L4;
.loc 1 246 5
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L4:
.loc 1 250 1
mov.u32 %value,%r25;
st.param.u32 [%value_out],%value;
ret;
}

_absvdi2.o/     1608280940  0     0     100666  1152      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __absvti2
.visible .func __absvti2 (.param .u64 %in_ar0, .param .u64 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DECL: abort
.extern .func abort;
// BEGIN GLOBAL FUNCTION DEF: __absvti2
.visible .func __absvti2 (.param .u64 %in_ar0, .param .u64 %in_ar1)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %r24;
.reg .u64 %r25;
.reg .pred %r28;
.reg .u64 %r34;
.reg .u32 %r36;
.reg .u64 %r40;
.reg .pred %r42;
.reg .u64 %r45;
.reg .u64 %r46;
mov.u64 %r24,%ar0;
mov.u64 %r25,%ar1;
ld.u64 %r45,[%r25];
ld.u64 %r46,[%r25+8];
.loc 1 260 6
setp.ge.s64 %r28,%r46,0;
@ %r28 bra $L2;
.loc 1 264 9
set.u32.ne.u64 %r36,%r45,0;
cvt.s64.s32 %r34,%r36;
sub.u64 %r40,%r34,%r46;
neg.s64 %r45,%r45;
mov.u64 %r46,%r40;
.loc 1 266 6
setp.ge.s64 %r42,%r40,0;
@ %r42 bra $L2;
.loc 1 267 5
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L2:
.loc 1 270 10
st.u64 [%r24],%r45;
st.u64 [%r24+8],%r46;
.loc 1 271 1
ret;
}
_addvsi3.o/     1608280940  0     0     100666  2019      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __addvdi3
.visible .func (.param .u64 %value_out) __addvdi3 (.param .u64 %in_ar0, .param .u64 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DECL: __addvsi3
.visible .func (.param .u32 %value_out) __addvsi3 (.param .u32 %in_ar0, .param .u32 %in_ar1);
// BEGIN GLOBAL FUNCTION DECL: abort
.extern .func abort;
// BEGIN GLOBAL FUNCTION DEF: __addvdi3
.visible .func (.param .u64 %value_out) __addvdi3 (.param .u64 %in_ar0, .param .u64 %in_ar1)
{
.reg .u64 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %r25;
.reg .u64 %r26;
.reg .u64 %r27;
.reg .pred %r28;
.reg .pred %r29;
.reg .pred %r30;
mov.u64 %r26,%ar0;
mov.u64 %r27,%ar1;
.loc 1 78 30
add.u64 %r25,%r26,%r27;
.loc 1 80 7
setp.lt.s64 %r28,%r27,0;
@ %r28 bra $L2;
.loc 1 80 6
setp.gt.s64 %r29,%r26,%r25;
@ ! %r29 bra $L1;
bra $L3;
$L2:
setp.ge.s64 %r30,%r26,%r25;
@ %r30 bra $L1;
$L3:
.loc 1 81 5
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L1:
.loc 1 84 1
mov.u64 %value,%r25;
st.param.u64 [%value_out],%value;
ret;
}
// BEGIN GLOBAL FUNCTION DEF: __addvsi3
.visible .func (.param .u32 %value_out) __addvsi3 (.param .u32 %in_ar0, .param .u32 %in_ar1)
{
.reg .u32 %value;
.reg .u32 %ar0;
ld.param.u32 %ar0,[%in_ar0];
.reg .u32 %ar1;
ld.param.u32 %ar1,[%in_ar1];
.reg .u32 %r25;
.reg .u32 %r26;
.reg .u32 %r27;
.reg .pred %r28;
.reg .pred %r29;
.reg .pred %r30;
mov.u32 %r26,%ar0;
mov.u32 %r27,%ar1;
.loc 1 89 32
add.u32 %r25,%r26,%r27;
.loc 1 91 7
setp.lt.s32 %r28,%r27,0;
@ %r28 bra $L6;
.loc 1 91 6
setp.gt.s32 %r29,%r26,%r25;
@ ! %r29 bra $L5;
bra $L7;
$L6:
setp.ge.s32 %r30,%r26,%r25;
@ %r30 bra $L5;
$L7:
.loc 1 92 5
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L5:
.loc 1 95 1
mov.u32 %value,%r25;
st.param.u32 [%value_out],%value;
ret;
}

_addvdi3.o/     1608280940  0     0     100666  1753      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __addvti3
.visible .func __addvti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DECL: abort
.extern .func abort;
// BEGIN GLOBAL FUNCTION DEF: __addvti3
.visible .func __addvti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %r26;
.reg .u64 %r27;
.reg .u64 %r29;
.reg .u64 %r32;
.reg .u64 %r35;
.reg .u32 %r37;
.reg .u64 %r38;
.reg .u64 %r41;
.reg .pred %r43;
.reg .pred %r46;
.reg .pred %r49;
.reg .pred %r52;
.reg .pred %r55;
.reg .pred %r58;
.reg .pred %r61;
.reg .u64 %r66;
.reg .u64 %r67;
.reg .u64 %r68;
.reg .u64 %r69;
mov.u64 %r26,%ar0;
mov.u64 %r27,%ar1;
ld.u64 %r66,[%r27];
ld.u64 %r67,[%r27+8];
mov.u64 %r29,%ar2;
ld.u64 %r68,[%r29];
ld.u64 %r69,[%r29+8];
.loc 1 103 32
add.u64 %r32,%r66,%r68;
set.u32.lt.u64 %r37,%r32,%r66;
cvt.s64.s32 %r35,%r37;
add.u64 %r38,%r67,%r69;
sub.u64 %r41,%r38,%r35;
.loc 1 105 7
setp.lt.s64 %r43,%r69,0;
@ %r43 bra $L2;
.loc 1 105 6
setp.gt.s64 %r46,%r67,%r41;
@ %r46 bra $L4;
setp.ne.u64 %r49,%r67,%r41;
@ %r49 bra $L6;
setp.gt.u64 %r52,%r66,%r32;
@ ! %r52 bra $L6;
bra $L4;
$L2:
setp.gt.s64 %r55,%r41,%r67;
@ %r55 bra $L4;
setp.ne.u64 %r58,%r41,%r67;
@ %r58 bra $L6;
setp.gt.u64 %r61,%r32,%r66;
@ ! %r61 bra $L6;
$L4:
.loc 1 106 5
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L6:
.loc 1 108 10
st.u64 [%r26],%r32;
st.u64 [%r26+8],%r41;
.loc 1 109 1
ret;
}

_subvsi3.o/     1608280940  0     0     100666  2029      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __subvdi3
.visible .func (.param .u64 %value_out) __subvdi3 (.param .u64 %in_ar0, .param .u64 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DECL: __subvsi3
.visible .func (.param .u32 %value_out) __subvsi3 (.param .u32 %in_ar0, .param .u32 %in_ar1);
// BEGIN GLOBAL FUNCTION DECL: abort
.extern .func abort;
// BEGIN GLOBAL FUNCTION DEF: __subvdi3
.visible .func (.param .u64 %value_out) __subvdi3 (.param .u64 %in_ar0, .param .u64 %in_ar1)
{
.reg .u64 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %r25;
.reg .u64 %r26;
.reg .u64 %r27;
.reg .pred %r28;
.reg .pred %r29;
.reg .pred %r30;
mov.u64 %r26,%ar0;
mov.u64 %r27,%ar1;
.loc 1 116 30
sub.u64 %r25,%r26,%r27;
.loc 1 118 7
setp.lt.s64 %r28,%r27,0;
@ %r28 bra $L2;
.loc 1 118 6
setp.lt.s64 %r29,%r26,%r25;
@ ! %r29 bra $L1;
bra $L3;
$L2:
setp.le.s64 %r30,%r26,%r25;
@ %r30 bra $L1;
$L3:
.loc 1 119 5
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L1:
.loc 1 122 1
mov.u64 %value,%r25;
st.param.u64 [%value_out],%value;
ret;
}
// BEGIN GLOBAL FUNCTION DEF: __subvsi3
.visible .func (.param .u32 %value_out) __subvsi3 (.param .u32 %in_ar0, .param .u32 %in_ar1)
{
.reg .u32 %value;
.reg .u32 %ar0;
ld.param.u32 %ar0,[%in_ar0];
.reg .u32 %ar1;
ld.param.u32 %ar1,[%in_ar1];
.reg .u32 %r25;
.reg .u32 %r26;
.reg .u32 %r27;
.reg .pred %r28;
.reg .pred %r29;
.reg .pred %r30;
mov.u32 %r26,%ar0;
mov.u32 %r27,%ar1;
.loc 1 127 32
sub.u32 %r25,%r26,%r27;
.loc 1 129 7
setp.lt.s32 %r28,%r27,0;
@ %r28 bra $L6;
.loc 1 129 6
setp.lt.s32 %r29,%r26,%r25;
@ ! %r29 bra $L5;
bra $L7;
$L6:
setp.le.s32 %r30,%r26,%r25;
@ %r30 bra $L5;
$L7:
.loc 1 130 5
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L5:
.loc 1 133 1
mov.u32 %value,%r25;
st.param.u32 [%value_out],%value;
ret;
}

_subvdi3.o/     1608280940  0     0     100666  1753      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __subvti3
.visible .func __subvti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DECL: abort
.extern .func abort;
// BEGIN GLOBAL FUNCTION DEF: __subvti3
.visible .func __subvti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %r26;
.reg .u64 %r27;
.reg .u64 %r29;
.reg .u64 %r32;
.reg .u64 %r35;
.reg .u32 %r37;
.reg .u64 %r38;
.reg .u64 %r41;
.reg .pred %r43;
.reg .pred %r46;
.reg .pred %r49;
.reg .pred %r52;
.reg .pred %r55;
.reg .pred %r58;
.reg .pred %r61;
.reg .u64 %r66;
.reg .u64 %r67;
.reg .u64 %r68;
.reg .u64 %r69;
mov.u64 %r26,%ar0;
mov.u64 %r27,%ar1;
ld.u64 %r66,[%r27];
ld.u64 %r67,[%r27+8];
mov.u64 %r29,%ar2;
ld.u64 %r68,[%r29];
ld.u64 %r69,[%r29+8];
.loc 1 141 32
sub.u64 %r32,%r66,%r68;
set.u32.gt.u64 %r37,%r32,%r66;
cvt.s64.s32 %r35,%r37;
sub.u64 %r38,%r67,%r69;
add.u64 %r41,%r38,%r35;
.loc 1 143 7
setp.lt.s64 %r43,%r69,0;
@ %r43 bra $L2;
.loc 1 143 6
setp.gt.s64 %r46,%r41,%r67;
@ %r46 bra $L4;
setp.ne.u64 %r49,%r41,%r67;
@ %r49 bra $L6;
setp.gt.u64 %r52,%r32,%r66;
@ ! %r52 bra $L6;
bra $L4;
$L2:
setp.gt.s64 %r55,%r67,%r41;
@ %r55 bra $L4;
setp.ne.u64 %r58,%r67,%r41;
@ %r58 bra $L6;
setp.gt.u64 %r61,%r66,%r32;
@ ! %r61 bra $L6;
$L4:
.loc 1 144 5
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L6:
.loc 1 146 10
st.u64 [%r26],%r32;
st.u64 [%r26+8],%r41;
.loc 1 147 1
ret;
}

_mulvsi3.o/     1608280940  0     0     100666  3293      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __mulvdi3
.visible .func (.param .u64 %value_out) __mulvdi3 (.param .u64 %in_ar0, .param .u64 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DECL: __mulvsi3
.visible .func (.param .u32 %value_out) __mulvsi3 (.param .u32 %in_ar0, .param .u32 %in_ar1);
// BEGIN GLOBAL FUNCTION DECL: __multi3
.extern .func __multi3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
// BEGIN GLOBAL FUNCTION DECL: abort
.extern .func abort;
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __mulvdi3
.visible .func (.param .u64 %value_out) __mulvdi3 (.param .u64 %in_ar0, .param .u64 %in_ar1)
{
.reg .u64 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,48;
sub.u64 %stack,%frame,0;
st.shared.u64 [%sspslot],%stack;
}
.reg .u64 %r29;
.reg .u64 %r30;
.reg .u64 %r32;
.reg .u64 %r34;
.reg .u64 %r38;
.reg .u64 %r42;
.reg .u64 %r50;
.reg .pred %r52;
.reg .u64 %r60;
.reg .u64 %r61;
mov.u64 %r29,%ar0;
mov.u64 %r30,%ar1;
.loc 1 154 20
shr.s64 %r32,%r29,63;
.loc 1 154 33
shr.s64 %r34,%r30,63;
.loc 1 154 16
add.u64 %r38,%frame,16;
add.u64 %r42,%frame,32;
st.u64 [%frame+16],%r29;
st.u64 [%frame+24],%r32;
st.u64 [%frame+32],%r30;
st.u64 [%frame+40],%r34;
{
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%frame;
.param .u64 %out_arg2;
st.param.u64 [%out_arg2],%r38;
.param .u64 %out_arg3;
st.param.u64 [%out_arg3],%r42;
call __multi3,(%out_arg1,%out_arg2,%out_arg3);
}
ld.u64 %r60,[%frame];
ld.u64 %r61,[%frame+8];
.loc 1 156 47
shr.s64 %r50,%r60,63;
.loc 1 156 6
setp.eq.u64 %r52,%r50,%r61;
@ %r52 bra $L1;
.loc 1 157 5
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L1:
.loc 1 160 1
mov.u64 %value,%r60;
st.shared.u64 [%sspslot],%sspprev;
st.param.u64 [%value_out],%value;
ret;
}
// BEGIN GLOBAL FUNCTION DEF: __mulvsi3
.visible .func (.param .u32 %value_out) __mulvsi3 (.param .u32 %in_ar0, .param .u32 %in_ar1)
{
.reg .u32 %value;
.reg .u32 %ar0;
ld.param.u32 %ar0,[%in_ar0];
.reg .u32 %ar1;
ld.param.u32 %ar1,[%in_ar1];
.reg .u64 %r27;
.reg .u32 %r28;
.reg .u32 %r29;
.reg .u32 %r30;
.reg .u64 %r31;
.reg .u64 %r32;
.reg .u64 %r33;
.reg .u32 %r34;
.reg .u32 %r35;
.reg .pred %r36;
mov.u32 %r29,%ar0;
mov.u32 %r30,%ar1;
.loc 1 167 20
cvt.s64.s32 %r31,%r29;
.loc 1 167 33
cvt.s64.s32 %r32,%r30;
.loc 1 167 16
mul.lo.u64 %r27,%r31,%r32;
.loc 1 169 36
cvt.u32.u64 %r28,%r27;
.loc 1 169 19
shr.s64 %r33,%r27,32;
.loc 1 169 47
shr.s32 %r34,%r28,31;
.loc 1 169 6
cvt.u32.u64 %r35,%r33;
setp.eq.u32 %r36,%r34,%r35;
@ %r36 bra $L3;
.loc 1 170 5
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L3:
.loc 1 173 1
cvt.u32.u64 %value,%r27;
st.param.u32 [%value_out],%value;
ret;
}

_mulvdi3.o/     1608280941  0     0     100666  12281     `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __mulvti3
.visible .func __mulvti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DECL: __multi3
.extern .func __multi3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
// BEGIN GLOBAL FUNCTION DECL: abort
.extern .func abort;
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __mulvti3
.visible .func __mulvti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,80;
sub.u64 %stack,%frame,0;
st.shared.u64 [%sspslot],%stack;
}
.reg .u64 %r68;
.reg .u64 %r70;
.reg .u64 %r76;
.reg .u64 %r85;
.reg .u64 %r114;
.reg .u64 %r115;
.reg .u64 %r117;
.reg .u64 %r119;
.reg .pred %r120;
.reg .pred %r121;
.reg .u64 %r126;
.reg .u64 %r130;
.reg .u64 %r134;
.reg .u64 %r141;
.reg .u64 %r148;
.reg .u64 %r152;
.reg .u64 %r156;
.reg .pred %r175;
.reg .u64 %r176;
.reg .pred %r178;
.reg .u64 %r180;
.reg .u64 %r183;
.reg .u32 %r185;
.reg .u64 %r186;
.reg .u64 %r192;
.reg .u64 %r195;
.reg .u32 %r197;
.reg .u64 %r201;
.reg .u64 %r202;
.reg .pred %r204;
.reg .u64 %r205;
.reg .pred %r207;
.reg .u64 %r210;
.reg .u64 %r217;
.reg .u64 %r221;
.reg .u64 %r225;
.reg .pred %r244;
.reg .u64 %r245;
.reg .pred %r247;
.reg .u64 %r249;
.reg .u64 %r252;
.reg .u32 %r254;
.reg .u64 %r255;
.reg .u64 %r261;
.reg .u64 %r264;
.reg .u32 %r266;
.reg .u64 %r270;
.reg .u64 %r271;
.reg .pred %r273;
.reg .u64 %r274;
.reg .pred %r276;
.reg .pred %r277;
.reg .u64 %r278;
.reg .pred %r279;
.reg .u64 %r290;
.reg .u64 %r294;
.reg .u64 %r298;
.reg .pred %r302;
.reg .u32 %r306;
.reg .u32 %r307;
.reg .u32 %r309;
.reg .u32 %r310;
.reg .u16 %r311;
.reg .u16 %r312;
.reg .u16 %r313;
.reg .u32 %r314;
.reg .u16 %r315;
.reg .pred %r316;
.reg .u64 %r320;
.reg .u64 %r327;
.reg .u64 %r331;
.reg .u64 %r335;
.reg .pred %r341;
.reg .pred %r344;
.reg .u32 %r346;
.reg .u32 %r347;
.reg .u32 %r349;
.reg .u32 %r350;
.reg .u16 %r351;
.reg .u16 %r352;
.reg .u16 %r353;
.reg .u32 %r354;
.reg .u16 %r355;
.reg .pred %r356;
.reg .u64 %r360;
.reg .u64 %r367;
.reg .u64 %r371;
.reg .u64 %r375;
.reg .pred %r381;
.reg .u64 %r384;
.reg .pred %r385;
.reg .u64 %r386;
.reg .pred %r387;
.reg .u64 %r391;
.reg .u64 %r398;
.reg .u64 %r402;
.reg .u64 %r406;
.reg .u64 %r411;
.reg .pred %r413;
.reg .u64 %r420;
.reg .u64 %r421;
.reg .u64 %r428;
.reg .u64 %r429;
.reg .u64 %r440;
.reg .u64 %r441;
.reg .u64 %r442;
.reg .u64 %r443;
.reg .u64 %r448;
.reg .u64 %r449;
.reg .u64 %r452;
.reg .u64 %r453;
.reg .u64 %r456;
.reg .u64 %r466;
.reg .u64 %r467;
.reg .u64 %r470;
.reg .u64 %r482;
.reg .u64 %r483;
.reg .u64 %r488;
.reg .u64 %r489;
.reg .u64 %r494;
.reg .u64 %r495;
.reg .u64 %r500;
.reg .u64 %r501;
mov.u64 %r114,%ar0;
mov.u64 %r115,%ar1;
ld.u64 %r440,[%r115];
ld.u64 %r441,[%r115+8];
mov.u64 %r117,%ar2;
ld.u64 %r442,[%r117];
ld.u64 %r443,[%r117+8];
.loc 1 286 51
shr.s64 %r70,%r442,63;
.loc 1 283 47
shr.s64 %r119,%r440,63;
.loc 1 283 6
setp.ne.u64 %r120,%r119,%r441;
@ %r120 bra $L2;
.loc 1 286 10
setp.ne.u64 %r121,%r70,%r443;
@ %r121 bra $L3;
.loc 1 290 29
add.u64 %r126,%frame,32;
add.u64 %r130,%frame,48;
add.u64 %r134,%frame,64;
st.u64 [%frame+48],%r440;
st.u64 [%frame+56],%r119;
st.u64 [%frame+64],%r442;
st.u64 [%frame+72],%r70;
{
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%r126;
.param .u64 %out_arg2;
st.param.u64 [%out_arg2],%r130;
.param .u64 %out_arg3;
st.param.u64 [%out_arg3],%r134;
call __multi3,(%out_arg1,%out_arg2,%out_arg3);
}
ld.u64 %r448,[%frame+32];
ld.u64 %r449,[%frame+40];
st.u64 [%r114],%r448;
st.u64 [%r114+8],%r449;
bra $L1;
$L3:
.loc 1 295 24
mov.u64 %r141,0;
.loc 1 296 4
add.u64 %r148,%frame,32;
add.u64 %r152,%frame,48;
add.u64 %r156,%frame,64;
st.u64 [%frame+48],%r442;
st.u64 [%frame+56],%r141;
st.u64 [%frame+64],%r440;
st.u64 [%frame+72],%r141;
{
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%r148;
.param .u64 %out_arg2;
st.param.u64 [%out_arg2],%r152;
.param .u64 %out_arg3;
st.param.u64 [%out_arg3],%r156;
call __multi3,(%out_arg1,%out_arg2,%out_arg3);
}
ld.u64 %r452,[%frame+32];
ld.u64 %r453,[%frame+40];
.loc 1 295 12
st.u64 [%frame+16],%r452;
st.u64 [%frame+24],%r453;
.loc 1 298 4
st.u64 [%frame+48],%r443;
st.u64 [%frame+56],%r141;
st.u64 [%frame+64],%r440;
st.u64 [%frame+72],%r141;
{
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%r148;
.param .u64 %out_arg2;
st.param.u64 [%out_arg2],%r152;
.param .u64 %out_arg3;
st.param.u64 [%out_arg3],%r156;
call __multi3,(%out_arg1,%out_arg2,%out_arg3);
}
ld.u64 %r456,[%frame+32];
mov.u64 %r420,%r456;
ld.u64 %r421,[%frame+40];
.loc 1 297 12
st.u64 [%frame],%r456;
st.u64 [%frame+8],%r421;
.loc 1 300 7
setp.ge.s64 %r175,%r443,0;
@ %r175 bra $L5;
.loc 1 301 16
sub.u64 %r176,%r421,%r440;
st.u64 [%frame+8],%r176;
.loc 1 303 12
mov.u64 %r421,%r176;
$L5:
.loc 1 302 7
setp.ge.s64 %r178,%r440,0;
@ %r178 bra $L6;
.loc 1 303 12
sub.u64 %r180,%r456,%r442;
set.u32.gt.u64 %r185,%r180,%r456;
cvt.s64.s32 %r183,%r185;
sub.u64 %r186,%r421,%r443;
mov.u64 %r420,%r180;
add.u64 %r421,%r186,%r183;
$L6:
.loc 1 304 10
add.u64 %r192,%r453,%r420;
set.u32.lt.u64 %r197,%r192,%r453;
cvt.s64.s32 %r195,%r197;
sub.u64 %r201,%r421,%r195;
.loc 1 305 48
shr.s64 %r202,%r192,63;
.loc 1 305 7
setp.ne.u64 %r204,%r202,%r201;
@ %r204 bra $L8;
.loc 1 308 17
ld.u64 %r205,[%frame+16];
st.u64 [%r114],%r205;
st.u64 [%r114+8],%r192;
bra $L1;
$L2:
.loc 1 314 10
setp.ne.u64 %r207,%r70,%r443;
@ %r207 bra $L9;
.loc 1 319 6
mov.u64 %r210,0;
.loc 1 319 4
add.u64 %r217,%frame,32;
add.u64 %r221,%frame,48;
add.u64 %r225,%frame,64;
st.u64 [%frame+48],%r440;
st.u64 [%frame+56],%r210;
st.u64 [%frame+64],%r442;
st.u64 [%frame+72],%r210;
{
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%r217;
.param .u64 %out_arg2;
st.param.u64 [%out_arg2],%r221;
.param .u64 %out_arg3;
st.param.u64 [%out_arg3],%r225;
call __multi3,(%out_arg1,%out_arg2,%out_arg3);
}
ld.u64 %r466,[%frame+32];
ld.u64 %r467,[%frame+40];
.loc 1 318 12
st.u64 [%frame+16],%r466;
st.u64 [%frame+24],%r467;
.loc 1 321 4
st.u64 [%frame+48],%r441;
st.u64 [%frame+56],%r210;
st.u64 [%frame+64],%r442;
st.u64 [%frame+72],%r210;
{
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%r217;
.param .u64 %out_arg2;
st.param.u64 [%out_arg2],%r221;
.param .u64 %out_arg3;
st.param.u64 [%out_arg3],%r225;
call __multi3,(%out_arg1,%out_arg2,%out_arg3);
}
ld.u64 %r470,[%frame+32];
mov.u64 %r428,%r470;
ld.u64 %r429,[%frame+40];
.loc 1 320 12
st.u64 [%frame],%r470;
st.u64 [%frame+8],%r429;
.loc 1 323 7
setp.ge.s64 %r244,%r441,0;
@ %r244 bra $L10;
.loc 1 324 16
sub.u64 %r245,%r429,%r442;
st.u64 [%frame+8],%r245;
.loc 1 326 12
mov.u64 %r429,%r245;
$L10:
.loc 1 325 7
setp.ge.s64 %r247,%r442,0;
@ %r247 bra $L11;
.loc 1 326 12
sub.u64 %r249,%r470,%r440;
set.u32.gt.u64 %r254,%r249,%r470;
cvt.s64.s32 %r252,%r254;
sub.u64 %r255,%r429,%r441;
mov.u64 %r428,%r249;
add.u64 %r429,%r255,%r252;
$L11:
.loc 1 327 10
add.u64 %r261,%r467,%r428;
set.u32.lt.u64 %r266,%r261,%r467;
cvt.s64.s32 %r264,%r266;
sub.u64 %r270,%r429,%r264;
.loc 1 328 48
shr.s64 %r271,%r261,63;
.loc 1 328 7
setp.ne.u64 %r273,%r271,%r270;
@ %r273 bra $L8;
.loc 1 331 17
ld.u64 %r274,[%frame+16];
st.u64 [%r114],%r274;
st.u64 [%r114+8],%r261;
bra $L1;
$L9:
.loc 1 337 7
setp.lt.s64 %r276,%r441,0;
@ %r276 bra $L13;
.loc 1 339 11
setp.lt.s64 %r277,%r443,0;
@ %r277 bra $L14;
.loc 1 341 24
or.b64 %r278,%r443,%r441;
setp.ne.u64 %r279,%r278,0;
@ %r279 bra $L8;
.loc 1 344 4
add.u64 %r290,%frame,32;
add.u64 %r294,%frame,48;
add.u64 %r298,%frame,64;
st.u64 [%frame+48],%r440;
st.u64 [%frame+56],%r278;
st.u64 [%frame+64],%r442;
st.u64 [%frame+72],%r278;
{
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%r290;
.param .u64 %out_arg2;
st.param.u64 [%out_arg2],%r294;
.param .u64 %out_arg3;
st.param.u64 [%out_arg3],%r298;
call __multi3,(%out_arg1,%out_arg2,%out_arg3);
}
ld.u64 %r482,[%frame+32];
ld.u64 %r483,[%frame+40];
.loc 1 345 12
setp.lt.s64 %r302,%r483,0;
@ %r302 bra $L8;
.loc 1 346 11
st.u64 [%r114],%r482;
st.u64 [%r114+8],%r483;
bra $L1;
$L14:
.loc 1 351 24
set.u32.eq.u64 %r306,%r443,-1;
neg.s32 %r307,%r306;
.loc 1 351 8
set.u32.eq.u64 %r309,%r441,0;
neg.s32 %r310,%r309;
.loc 1 351 24
cvt.u16.u32 %r312,%r307;
cvt.u16.u32 %r313,%r310;
and.b16 %r311,%r312,%r313;
cvt.u32.u16 %r314,%r311;
cvt.u16.u8 %r315,%r314;
setp.eq.u16 %r316,%r315,0;
@ %r316 bra $L8;
.loc 1 353 29
mov.u64 %r320,0;
.loc 1 354 9
add.u64 %r327,%frame,32;
add.u64 %r331,%frame,48;
add.u64 %r335,%frame,64;
st.u64 [%frame+48],%r440;
st.u64 [%frame+56],%r320;
st.u64 [%frame+64],%r442;
st.u64 [%frame+72],%r320;
{
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%r327;
.param .u64 %out_arg2;
st.param.u64 [%out_arg2],%r331;
.param .u64 %out_arg3;
st.param.u64 [%out_arg3],%r335;
call __multi3,(%out_arg1,%out_arg2,%out_arg3);
}
ld.u64 %r488,[%frame+32];
ld.u64 %r489,[%frame+40];
.loc 1 353 17
st.u64 [%frame],%r488;
.loc 1 356 19
sub.u64 %r68,%r489,%r440;
st.u64 [%frame+8],%r68;
.loc 1 357 12
setp.ge.s64 %r341,%r68,0;
@ %r341 bra $L8;
.loc 1 358 13
st.u64 [%r114],%r488;
st.u64 [%r114+8],%r68;
bra $L1;
$L13:
.loc 1 364 11
setp.lt.s64 %r344,%r443,0;
@ %r344 bra $L17;
.loc 1 366 33
set.u32.eq.u64 %r346,%r443,0;
neg.s32 %r347,%r346;
.loc 1 366 8
set.u32.eq.u64 %r349,%r441,-1;
neg.s32 %r350,%r349;
.loc 1 366 33
cvt.u16.u32 %r352,%r347;
cvt.u16.u32 %r353,%r350;
and.b16 %r351,%r352,%r353;
cvt.u32.u16 %r354,%r351;
cvt.u16.u8 %r355,%r354;
setp.eq.u16 %r356,%r355,0;
@ %r356 bra $L8;
.loc 1 368 29
mov.u64 %r360,0;
.loc 1 369 9
add.u64 %r367,%frame,32;
add.u64 %r371,%frame,48;
add.u64 %r375,%frame,64;
st.u64 [%frame+48],%r440;
st.u64 [%frame+56],%r360;
st.u64 [%frame+64],%r442;
st.u64 [%frame+72],%r360;
{
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%r367;
.param .u64 %out_arg2;
st.param.u64 [%out_arg2],%r371;
.param .u64 %out_arg3;
st.param.u64 [%out_arg3],%r375;
call __multi3,(%out_arg1,%out_arg2,%out_arg3);
}
ld.u64 %r494,[%frame+32];
ld.u64 %r495,[%frame+40];
.loc 1 368 17
st.u64 [%frame],%r494;
.loc 1 371 19
sub.u64 %r76,%r495,%r442;
st.u64 [%frame+8],%r76;
.loc 1 372 12
setp.ge.s64 %r381,%r76,0;
@ %r381 bra $L8;
.loc 1 373 13
st.u64 [%r114],%r494;
st.u64 [%r114+8],%r76;
bra $L1;
$L17:
.loc 1 378 20
and.b64 %r384,%r443,%r441;
.loc 1 378 8
setp.ne.u64 %r385,%r384,-1;
@ %r385 bra $L8;
.loc 1 379 22
or.b64 %r386,%r442,%r440;
.loc 1 379 9
setp.eq.u64 %r387,%r386,0;
@ %r387 bra $L8;
.loc 1 381 29
mov.u64 %r391,0;
.loc 1 382 9
add.u64 %r398,%frame,32;
add.u64 %r402,%frame,48;
add.u64 %r406,%frame,64;
st.u64 [%frame+48],%r440;
st.u64 [%frame+56],%r391;
st.u64 [%frame+64],%r442;
st.u64 [%frame+72],%r391;
{
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%r398;
.param .u64 %out_arg2;
st.param.u64 [%out_arg2],%r402;
.param .u64 %out_arg3;
st.param.u64 [%out_arg3],%r406;
call __multi3,(%out_arg1,%out_arg2,%out_arg3);
}
ld.u64 %r500,[%frame+32];
ld.u64 %r501,[%frame+40];
.loc 1 381 17
st.u64 [%frame],%r500;
.loc 1 384 19
sub.u64 %r411,%r501,%r440;
.loc 1 385 19
sub.u64 %r85,%r411,%r442;
st.u64 [%frame+8],%r85;
.loc 1 386 12
setp.lt.s64 %r413,%r85,0;
@ %r413 bra $L8;
.loc 1 387 13
st.u64 [%r114],%r500;
st.u64 [%r114+8],%r85;
bra $L1;
$L8:
.loc 1 395 3
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L1:
.loc 1 396 1
st.shared.u64 [%sspslot],%sspprev;
ret;
}

_negvsi2.o/     1608280941  0     0     100666  1755      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __negvdi2
.visible .func (.param .u64 %value_out) __negvdi2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DECL: __negvsi2
.visible .func (.param .u32 %value_out) __negvsi2 (.param .u32 %in_ar0);
// BEGIN GLOBAL FUNCTION DECL: abort
.extern .func abort;
// BEGIN GLOBAL FUNCTION DEF: __negvdi2
.visible .func (.param .u64 %value_out) __negvdi2 (.param .u64 %in_ar0)
{
.reg .u64 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r24;
.reg .u64 %r25;
.reg .pred %r26;
.reg .pred %r27;
.reg .pred %r28;
mov.u64 %r25,%ar0;
.loc 1 181 19
neg.s64 %r24,%r25;
.loc 1 183 7
setp.lt.s64 %r26,%r25,0;
@ %r26 bra $L2;
.loc 1 183 6
setp.gt.s64 %r27,%r24,0;
@ ! %r27 bra $L1;
bra $L3;
$L2:
setp.ge.s64 %r28,%r24,0;
@ %r28 bra $L1;
$L3:
.loc 1 184 5
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L1:
.loc 1 187 1
mov.u64 %value,%r24;
st.param.u64 [%value_out],%value;
ret;
}
// BEGIN GLOBAL FUNCTION DEF: __negvsi2
.visible .func (.param .u32 %value_out) __negvsi2 (.param .u32 %in_ar0)
{
.reg .u32 %value;
.reg .u32 %ar0;
ld.param.u32 %ar0,[%in_ar0];
.reg .u32 %r24;
.reg .u32 %r25;
.reg .pred %r26;
.reg .pred %r27;
.reg .pred %r28;
mov.u32 %r25,%ar0;
.loc 1 192 20
neg.s32 %r24,%r25;
.loc 1 194 7
setp.lt.s32 %r26,%r25,0;
@ %r26 bra $L6;
.loc 1 194 6
setp.gt.s32 %r27,%r24,0;
@ ! %r27 bra $L5;
bra $L7;
$L6:
setp.ge.s32 %r28,%r24,0;
@ %r28 bra $L5;
$L7:
.loc 1 195 5
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L5:
.loc 1 198 1
mov.u32 %value,%r24;
st.param.u32 [%value_out],%value;
ret;
}

_negvdi2.o/     1608280941  0     0     100666  1357      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __negvti2
.visible .func __negvti2 (.param .u64 %in_ar0, .param .u64 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DECL: abort
.extern .func abort;
// BEGIN GLOBAL FUNCTION DEF: __negvti2
.visible .func __negvti2 (.param .u64 %in_ar0, .param .u64 %in_ar1)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %r25;
.reg .u64 %r26;
.reg .u64 %r30;
.reg .u64 %r33;
.reg .u32 %r35;
.reg .u64 %r39;
.reg .pred %r41;
.reg .pred %r43;
.reg .pred %r45;
.reg .pred %r47;
.reg .pred %r49;
.reg .u64 %r54;
.reg .u64 %r55;
mov.u64 %r25,%ar0;
mov.u64 %r26,%ar1;
ld.u64 %r54,[%r26];
ld.u64 %r55,[%r26+8];
.loc 1 206 20
neg.s64 %r30,%r54;
set.u32.ne.u64 %r35,%r54,0;
cvt.s64.s32 %r33,%r35;
sub.u64 %r39,%r33,%r55;
.loc 1 208 7
setp.lt.s64 %r41,%r55,0;
@ %r41 bra $L2;
.loc 1 208 6
setp.gt.s64 %r43,%r39,0;
@ %r43 bra $L4;
setp.ne.u64 %r45,%r39,0;
@ %r45 bra $L6;
setp.ne.u64 %r47,%r30,0;
@ ! %r47 bra $L6;
bra $L4;
$L2:
setp.ge.s64 %r49,%r39,0;
@ %r49 bra $L6;
$L4:
.loc 1 209 5
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L6:
.loc 1 211 10
st.u64 [%r25],%r30;
st.u64 [%r25+8],%r39;
.loc 1 212 1
ret;
}

_ctors.o/       1608280941  0     0     100666  263       `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// BEGIN GLOBAL VAR DEF: __CTOR_LIST__
.visible .global .align 8 .u64 __CTOR_LIST__[2];
// END PREAMBLE
// BEGIN GLOBAL VAR DEF: __DTOR_LIST__
.visible .global .align 8 .u64 __DTOR_LIST__[2];

_ffssi2.o/      1608280941  0     0     100666  1521      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __ffsdi2
.visible .func (.param .u32 %value_out) __ffsdi2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL FUNCTION DEF: __ffsdi2
.visible .func (.param .u32 %value_out) __ffsdi2 (.param .u64 %in_ar0)
{
.reg .u32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r23;
.reg .u64 %r29;
.reg .u64 %r30;
.reg .u64 %r33;
.reg .u32 %r34;
.reg .u64 %r35;
.reg .pred %r36;
.reg .u64 %r37;
.reg .u32 %r38;
.reg .u64 %r39;
.reg .pred %r40;
.reg .pred %r41;
.reg .u64 %r42;
.reg .u64 %r43;
.reg .u64 %r44;
.reg .u64 %r45;
.reg .u32 %r46;
mov.u64 %r35,%ar0;
.loc 1 518 6
setp.eq.u64 %r36,%r35,0;
@ %r36 bra $L6;
.loc 1 521 3
neg.s64 %r37,%r35;
and.b64 %r29,%r37,%r35;
mov.u64 %r30,56;
$L4:
cvt.u32.u64 %r38,%r30;
shr.u64 %r23,%r29,%r38;
and.b64 %r39,%r23,255;
setp.ne.u64 %r40,%r39,0;
@ %r40 bra $L3;
add.u64 %r30,%r30,-8;
setp.ne.u64 %r41,%r30,0;
@ %r41 bra $L4;
mov.u64 %r33,-1;
bra $L5;
$L3:
add.u64 %r33,%r30,-1;
mov.u64 %r29,%r23;
$L5:
cvta.const.u64 %r42,__clz_tab;
add.u64 %r43,%r42,%r29;
ld.u8 %r44,[%r43];
add.u64 %r45,%r44,%r33;
.loc 1 522 16
cvt.u32.u64 %r46,%r45;
add.u32 %r34,%r46,1;
bra $L1;
$L6:
.loc 1 519 12
cvt.u32.u64 %r34,%r35;
$L1:
.loc 1 523 1
mov.u32 %value,%r34;
st.param.u32 [%value_out],%value;
ret;
}

_ffsdi2.o/      1608280941  0     0     100666  1839      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __ffsti2
.visible .func (.param .u32 %value_out) __ffsti2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL FUNCTION DEF: __ffsti2
.visible .func (.param .u32 %value_out) __ffsti2 (.param .u64 %in_ar0)
{
.reg .u32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r23;
.reg .u64 %r29;
.reg .u64 %r31;
.reg .u64 %r33;
.reg .u32 %r36;
.reg .u64 %r37;
.reg .u32 %r38;
.reg .u64 %r39;
.reg .pred %r42;
.reg .pred %r43;
.reg .u64 %r44;
.reg .u32 %r45;
.reg .u64 %r46;
.reg .pred %r47;
.reg .pred %r48;
.reg .u64 %r49;
.reg .u64 %r50;
.reg .u64 %r51;
.reg .u64 %r52;
.reg .u32 %r53;
.reg .u64 %r55;
.reg .u64 %r56;
mov.u64 %r39,%ar0;
ld.u64 %r55,[%r39];
ld.u64 %r56,[%r39+8];
.loc 1 534 6
setp.eq.u64 %r42,%r55,0;
@ %r42 bra $L2;
.loc 1 535 10
mov.u64 %r29,%r55;
mov.u32 %r36,1;
bra $L3;
$L2:
.loc 1 536 11
setp.eq.u64 %r43,%r56,0;
@ %r43 bra $L8;
.loc 1 537 10
mov.u64 %r29,%r56;
mov.u32 %r36,65;
$L3:
.loc 1 541 3
neg.s64 %r44,%r29;
and.b64 %r31,%r44,%r29;
mov.u64 %r33,56;
$L6:
cvt.u32.u64 %r45,%r33;
shr.u64 %r23,%r31,%r45;
and.b64 %r46,%r23,255;
setp.ne.u64 %r47,%r46,0;
@ %r47 bra $L5;
add.u64 %r33,%r33,-8;
setp.ne.u64 %r48,%r33,0;
@ %r48 bra $L6;
mov.u64 %r37,-1;
bra $L7;
$L5:
add.u64 %r37,%r33,-1;
mov.u64 %r31,%r23;
$L7:
cvta.const.u64 %r49,__clz_tab;
add.u64 %r50,%r49,%r31;
ld.u8 %r51,[%r50];
add.u64 %r52,%r51,%r37;
.loc 1 542 22
cvt.u32.u64 %r53,%r52;
add.u32 %r38,%r36,%r53;
bra $L1;
$L8:
.loc 1 539 12
cvt.u32.u64 %r38,%r56;
$L1:
.loc 1 543 1
mov.u32 %value,%r38;
st.param.u32 [%value_out],%value;
ret;
}

_clz.o/         1608280941  0     0     100666  683       `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL VAR DEF: __clz_tab
.visible .const .align 1 .u8 __clz_tab[256] =
{0,1,2,2,3,3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8 };

_clzsi2.o/      1608280941  0     0     100666  1252      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __clzdi2
.visible .func (.param .u32 %value_out) __clzdi2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL FUNCTION DEF: __clzdi2
.visible .func (.param .u32 %value_out) __clzdi2 (.param .u64 %in_ar0)
{
.reg .u32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r22;
.reg .u64 %r27;
.reg .u64 %r29;
.reg .u64 %r31;
.reg .u32 %r32;
.reg .u64 %r33;
.reg .pred %r34;
.reg .pred %r35;
.reg .u64 %r36;
.reg .u64 %r38;
.reg .u64 %r39;
.reg .u64 %r40;
.reg .u64 %r41;
mov.u64 %r31,%ar0;
.loc 1 710 3
mov.u64 %r27,56;
$L3:
cvt.u32.u64 %r32,%r27;
shr.u64 %r22,%r31,%r32;
and.b64 %r33,%r22,255;
setp.ne.u64 %r34,%r33,0;
@ %r34 bra $L2;
add.u64 %r27,%r27,-8;
setp.ne.u64 %r35,%r27,0;
@ %r35 bra $L3;
mov.u64 %r29,64;
bra $L4;
$L2:
mov.u64 %r36,64;
sub.u64 %r29,%r36,%r27;
mov.u64 %r31,%r22;
$L4:
cvta.const.u64 %r38,__clz_tab;
add.u64 %r39,%r38,%r31;
ld.u8 %r40,[%r39];
sub.u64 %r41,%r29,%r40;
.loc 1 713 1
cvt.u32.u64 %value,%r41;
st.param.u32 [%value_out],%value;
ret;
}
_clzdi2.o/      1608280942  0     0     100666  1623      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __clzti2
.visible .func (.param .u32 %value_out) __clzti2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL FUNCTION DEF: __clzti2
.visible .func (.param .u32 %value_out) __clzti2 (.param .u64 %in_ar0)
{
.reg .u32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r23;
.reg .u64 %r30;
.reg .u64 %r32;
.reg .u32 %r34;
.reg .u64 %r35;
.reg .u64 %r37;
.reg .pred %r39;
.reg .u32 %r40;
.reg .u64 %r41;
.reg .pred %r42;
.reg .pred %r43;
.reg .u64 %r44;
.reg .u64 %r46;
.reg .u64 %r47;
.reg .u64 %r48;
.reg .u64 %r49;
.reg .u32 %r50;
.reg .u64 %r51;
.reg .u64 %r52;
mov.u64 %r37,%ar0;
ld.u64 %r51,[%r37];
ld.u64 %r52,[%r37+8];
.loc 1 725 6
setp.eq.u64 %r39,%r52,0;
@ %r39 bra $L2;
.loc 1 726 10
mov.u64 %r30,%r52;
mov.u32 %r34,0;
bra $L3;
$L2:
.loc 1 728 10
mov.u64 %r30,%r51;
mov.u32 %r34,64;
$L3:
.loc 1 730 3
mov.u64 %r32,56;
$L5:
cvt.u32.u64 %r40,%r32;
shr.u64 %r23,%r30,%r40;
and.b64 %r41,%r23,255;
setp.ne.u64 %r42,%r41,0;
@ %r42 bra $L4;
add.u64 %r32,%r32,-8;
setp.ne.u64 %r43,%r32,0;
@ %r43 bra $L5;
mov.u64 %r35,64;
bra $L6;
$L4:
mov.u64 %r44,64;
sub.u64 %r35,%r44,%r32;
mov.u64 %r30,%r23;
$L6:
cvta.const.u64 %r46,__clz_tab;
add.u64 %r47,%r46,%r30;
ld.u8 %r48,[%r47];
sub.u64 %r49,%r35,%r48;
.loc 1 731 14
cvt.u32.u64 %r50,%r49;
add.u32 %value,%r34,%r50;
.loc 1 732 1
st.param.u32 [%value_out],%value;
ret;
}

_ctzsi2.o/      1608280942  0     0     100666  1294      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __ctzdi2
.visible .func (.param .u32 %value_out) __ctzdi2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL FUNCTION DEF: __ctzdi2
.visible .func (.param .u32 %value_out) __ctzdi2 (.param .u64 %in_ar0)
{
.reg .u32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r23;
.reg .u64 %r28;
.reg .u64 %r29;
.reg .u64 %r31;
.reg .u64 %r33;
.reg .u64 %r34;
.reg .u32 %r35;
.reg .u64 %r36;
.reg .pred %r37;
.reg .pred %r38;
.reg .u64 %r40;
.reg .u64 %r41;
.reg .u64 %r42;
.reg .u64 %r43;
mov.u64 %r33,%ar0;
.loc 1 742 3
neg.s64 %r34,%r33;
and.b64 %r28,%r34,%r33;
mov.u64 %r29,56;
$L3:
cvt.u32.u64 %r35,%r29;
shr.u64 %r23,%r28,%r35;
and.b64 %r36,%r23,255;
setp.ne.u64 %r37,%r36,0;
@ %r37 bra $L2;
add.u64 %r29,%r29,-8;
setp.ne.u64 %r38,%r29,0;
@ %r38 bra $L3;
mov.u64 %r31,-1;
bra $L4;
$L2:
add.u64 %r31,%r29,-1;
mov.u64 %r28,%r23;
$L4:
cvta.const.u64 %r40,__clz_tab;
add.u64 %r41,%r40,%r28;
ld.u8 %r42,[%r41];
add.u64 %r43,%r42,%r31;
.loc 1 745 1
cvt.u32.u64 %value,%r43;
st.param.u32 [%value_out],%value;
ret;
}
_ctzdi2.o/      1608280942  0     0     100666  1665      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __ctzti2
.visible .func (.param .u32 %value_out) __ctzti2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL FUNCTION DEF: __ctzti2
.visible .func (.param .u32 %value_out) __ctzti2 (.param .u64 %in_ar0)
{
.reg .u32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r24;
.reg .u64 %r31;
.reg .u64 %r32;
.reg .u64 %r34;
.reg .u32 %r37;
.reg .u64 %r38;
.reg .u64 %r40;
.reg .pred %r43;
.reg .u64 %r44;
.reg .u32 %r45;
.reg .u64 %r46;
.reg .pred %r47;
.reg .pred %r48;
.reg .u64 %r50;
.reg .u64 %r51;
.reg .u64 %r52;
.reg .u64 %r53;
.reg .u32 %r54;
.reg .u64 %r55;
.reg .u64 %r56;
mov.u64 %r40,%ar0;
ld.u64 %r55,[%r40];
ld.u64 %r56,[%r40+8];
.loc 1 757 6
setp.eq.u64 %r43,%r55,0;
@ %r43 bra $L2;
.loc 1 758 10
mov.u64 %r31,%r55;
mov.u32 %r37,0;
bra $L3;
$L2:
.loc 1 760 10
mov.u64 %r31,%r56;
mov.u32 %r37,64;
$L3:
.loc 1 762 3
neg.s64 %r44,%r31;
and.b64 %r32,%r44,%r31;
mov.u64 %r34,56;
$L5:
cvt.u32.u64 %r45,%r34;
shr.u64 %r24,%r32,%r45;
and.b64 %r46,%r24,255;
setp.ne.u64 %r47,%r46,0;
@ %r47 bra $L4;
add.u64 %r34,%r34,-8;
setp.ne.u64 %r48,%r34,0;
@ %r48 bra $L5;
mov.u64 %r38,-1;
bra $L6;
$L4:
add.u64 %r38,%r34,-1;
mov.u64 %r32,%r24;
$L6:
cvta.const.u64 %r50,__clz_tab;
add.u64 %r51,%r50,%r32;
ld.u8 %r52,[%r51];
add.u64 %r53,%r52,%r38;
.loc 1 763 14
cvt.u32.u64 %r54,%r53;
add.u32 %value,%r37,%r54;
.loc 1 764 1
st.param.u32 [%value_out],%value;
ret;
}

_popcount_tab.o/1608280942  0     0     100666  693       `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL VAR DEF: __popcount_tab
.visible .const .align 1 .u8 __popcount_tab[256] =
{0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8 };

_popcountsi2.o/ 1608280942  0     0     100666  1305      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __popcountdi2
.visible .func (.param .u32 %value_out) __popcountdi2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __popcountdi2
.visible .func (.param .u32 %value_out) __popcountdi2 (.param .u64 %in_ar0)
{
.reg .u32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r23;
.reg .u64 %r24;
.reg .u64 %r26;
.reg .u64 %r28;
.reg .u64 %r31;
.reg .u64 %r32;
.reg .u64 %r35;
.reg .u64 %r36;
.reg .u64 %r37;
.reg .u64 %r38;
.reg .u64 %r40;
.reg .u64 %r41;
.reg .u64 %r42;
mov.u64 %r35,%ar0;
.loc 1 848 15
shr.u64 %r36,%r35,1;
.loc 1 848 21
and.b64 %r23,%r36,6148914691236517205;
.loc 1 848 5
sub.u64 %r31,%r35,%r23;
.loc 1 849 10
and.b64 %r24,%r31,3689348814741910323;
.loc 1 849 38
shr.u64 %r37,%r31,2;
.loc 1 849 44
and.b64 %r26,%r37,3689348814741910323;
.loc 1 849 5
add.u64 %r32,%r24,%r26;
.loc 1 850 15
shr.u64 %r38,%r32,4;
.loc 1 850 10
add.u64 %r28,%r38,%r32;
.loc 1 850 5
and.b64 %r40,%r28,1085102592571150095;
.loc 1 851 13
mul.lo.u64 %r41,%r40,72340172838076673;
.loc 1 851 35
shr.u64 %r42,%r41,56;
.loc 1 860 1
cvt.u32.u64 %value,%r42;
st.param.u32 [%value_out],%value;
ret;
}

_popcountdi2.o/ 1608280942  0     0     100666  2057      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __popcountti2
.visible .func (.param .u32 %value_out) __popcountti2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __popcountti2
.visible .func (.param .u32 %value_out) __popcountti2 (.param .u64 %in_ar0)
{
.reg .u32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r24;
.reg .u64 %r26;
.reg .u64 %r27;
.reg .u64 %r29;
.reg .u64 %r30;
.reg .u64 %r32;
.reg .u64 %r34;
.reg .u64 %r36;
.reg .u64 %r41;
.reg .u64 %r42;
.reg .u64 %r43;
.reg .u64 %r44;
.reg .u64 %r45;
.reg .u64 %r50;
.reg .u64 %r52;
.reg .u64 %r53;
.reg .u64 %r54;
.reg .u64 %r55;
.reg .u64 %r56;
.reg .u64 %r57;
.reg .u64 %r59;
.reg .u64 %r60;
.reg .u64 %r61;
.reg .u64 %r62;
.reg .u64 %r63;
.reg .u64 %r64;
mov.u64 %r50,%ar0;
ld.u64 %r63,[%r50];
ld.u64 %r64,[%r50+8];
.loc 1 874 18
shr.u64 %r52,%r63,1;
.loc 1 874 24
and.b64 %r24,%r52,6148914691236517205;
.loc 1 874 6
sub.u64 %r41,%r63,%r24;
.loc 1 875 18
shr.u64 %r53,%r64,1;
.loc 1 875 24
and.b64 %r26,%r53,6148914691236517205;
.loc 1 875 6
sub.u64 %r42,%r64,%r26;
.loc 1 876 12
and.b64 %r27,%r41,3689348814741910323;
.loc 1 876 41
shr.u64 %r54,%r41,2;
.loc 1 876 47
and.b64 %r29,%r54,3689348814741910323;
.loc 1 876 6
add.u64 %r43,%r27,%r29;
.loc 1 877 12
and.b64 %r30,%r42,3689348814741910323;
.loc 1 877 41
shr.u64 %r55,%r42,2;
.loc 1 877 47
and.b64 %r32,%r55,3689348814741910323;
.loc 1 877 6
add.u64 %r44,%r30,%r32;
.loc 1 878 18
shr.u64 %r56,%r43,4;
.loc 1 878 12
add.u64 %r34,%r56,%r43;
.loc 1 878 6
and.b64 %r45,%r34,1085102592571150095;
.loc 1 879 18
shr.u64 %r57,%r44,4;
.loc 1 879 12
add.u64 %r36,%r57,%r44;
.loc 1 879 6
and.b64 %r59,%r36,1085102592571150095;
.loc 1 880 6
add.u64 %r60,%r59,%r45;
.loc 1 881 14
mul.lo.u64 %r61,%r60,72340172838076673;
.loc 1 881 36
shr.u64 %r62,%r61,56;
.loc 1 890 1
cvt.u32.u64 %value,%r62;
st.param.u32 [%value_out],%value;
ret;
}

_paritysi2.o/   1608280943  0     0     100666  1196      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __paritydi2
.visible .func (.param .u32 %value_out) __paritydi2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __paritydi2
.visible .func (.param .u32 %value_out) __paritydi2 (.param .u64 %in_ar0)
{
.reg .u32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r22;
.reg .u64 %r23;
.reg .u64 %r24;
.reg .u64 %r25;
.reg .u64 %r28;
.reg .u64 %r29;
.reg .u64 %r30;
.reg .u64 %r31;
.reg .u64 %r34;
.reg .u64 %r36;
.reg .u32 %r37;
.reg .u32 %r38;
.reg .u32 %r39;
mov.u64 %r34,%ar0;
.loc 1 902 10
shr.u64 %r22,%r34,32;
.loc 1 902 5
xor.b64 %r28,%r22,%r34;
.loc 1 905 10
shr.u64 %r23,%r28,16;
.loc 1 905 5
xor.b64 %r29,%r23,%r28;
.loc 1 907 10
shr.u64 %r24,%r29,8;
.loc 1 907 5
xor.b64 %r30,%r24,%r29;
.loc 1 908 10
shr.u64 %r25,%r30,4;
.loc 1 908 5
xor.b64 %r31,%r25,%r30;
.loc 1 909 5
and.b64 %r36,%r31,15;
.loc 1 910 18
mov.u32 %r38,27030;
cvt.u32.u64 %r39,%r36;
shr.s32 %r37,%r38,%r39;
.loc 1 910 24
and.b32 %value,%r37,1;
.loc 1 911 1
st.param.u32 [%value_out],%value;
ret;
}
_paritydi2.o/   1608280943  0     0     100666  1331      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __parityti2
.visible .func (.param .u32 %value_out) __parityti2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __parityti2
.visible .func (.param .u32 %value_out) __parityti2 (.param .u64 %in_ar0)
{
.reg .u32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r24;
.reg .u64 %r25;
.reg .u64 %r26;
.reg .u64 %r27;
.reg .u64 %r30;
.reg .u64 %r31;
.reg .u64 %r32;
.reg .u64 %r33;
.reg .u64 %r34;
.reg .u64 %r39;
.reg .u64 %r44;
.reg .u32 %r45;
.reg .u32 %r46;
.reg .u32 %r47;
.reg .u64 %r48;
.reg .u64 %r49;
mov.u64 %r39,%ar0;
ld.u64 %r48,[%r39];
ld.u64 %r49,[%r39+8];
.loc 1 920 24
xor.b64 %r30,%r48,%r49;
.loc 1 926 12
shr.u64 %r24,%r30,32;
.loc 1 926 6
xor.b64 %r31,%r24,%r30;
.loc 1 929 12
shr.u64 %r25,%r31,16;
.loc 1 929 6
xor.b64 %r32,%r25,%r31;
.loc 1 931 12
shr.u64 %r26,%r32,8;
.loc 1 931 6
xor.b64 %r33,%r26,%r32;
.loc 1 932 12
shr.u64 %r27,%r33,4;
.loc 1 932 6
xor.b64 %r34,%r27,%r33;
.loc 1 933 6
and.b64 %r44,%r34,15;
.loc 1 934 18
mov.u32 %r46,27030;
cvt.u32.u64 %r47,%r44;
shr.s32 %r45,%r46,%r47;
.loc 1 934 25
and.b32 %value,%r45,1;
.loc 1 935 1
st.param.u32 [%value_out],%value;
ret;
}

_powisf2.o/     1608280943  0     0     100666  1517      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __powisf2
.visible .func (.param .f32 %value_out) __powisf2 (.param .f32 %in_ar0, .param .u32 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __powisf2
.visible .func (.param .f32 %value_out) __powisf2 (.param .f32 %in_ar0, .param .u32 %in_ar1)
{
.reg .f32 %value;
.reg .f32 %ar0;
ld.param.f32 %ar0,[%in_ar0];
.reg .u32 %ar1;
ld.param.u32 %ar1,[%in_ar1];
.reg .u32 %r25;
.reg .u32 %r26;
.reg .f32 %r27;
.reg .f32 %r28;
.reg .u32 %r29;
.reg .u32 %r30;
.reg .pred %r31;
.reg .pred %r32;
.reg .u32 %r33;
.reg .pred %r34;
.reg .pred %r35;
.reg .pred %r36;
.reg .f32 %r37;
mov.f32 %r28,%ar0;
mov.u32 %r29,%ar1;
.loc 1 1879 31
abs.s32 %r25,%r29;
.loc 1 1880 14
and.b32 %r30,%r25,1;
.loc 1 1880 22
setp.ne.u32 %r31,%r30,0;
selp.f32 %r27,%r28,0f3f800000,%r31;
.loc 1 1881 12
shr.u32 %r26,%r25,1;
.loc 1 1881 9
setp.eq.u32 %r32,%r26,0;
@ %r32 bra $L3;
$L5:
.loc 1 1883 9
mul.f32 %r28,%r28,%r28;
.loc 1 1884 13
and.b32 %r33,%r26,1;
.loc 1 1884 10
setp.eq.u32 %r34,%r33,0;
@ %r34 bra $L4;
.loc 1 1885 4
mul.f32 %r27,%r27,%r28;
$L4:
.loc 1 1881 12
shr.u32 %r26,%r26,1;
.loc 1 1881 9
setp.ne.u32 %r35,%r26,0;
@ %r35 bra $L5;
$L3:
.loc 1 1887 22
setp.ge.s32 %r36,%r29,0;
@ %r36 bra $L1;
mov.f32 %r37,0f3f800000;
div.rn.f32 %r27,%r37,%r27;
$L1:
.loc 1 1888 1
mov.f32 %value,%r27;
st.param.f32 [%value_out],%value;
ret;
}

_powidf2.o/     1608280943  0     0     100666  1533      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __powidf2
.visible .func (.param .f64 %value_out) __powidf2 (.param .f64 %in_ar0, .param .u32 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __powidf2
.visible .func (.param .f64 %value_out) __powidf2 (.param .f64 %in_ar0, .param .u32 %in_ar1)
{
.reg .f64 %value;
.reg .f64 %ar0;
ld.param.f64 %ar0,[%in_ar0];
.reg .u32 %ar1;
ld.param.u32 %ar1,[%in_ar1];
.reg .u32 %r25;
.reg .u32 %r26;
.reg .f64 %r27;
.reg .f64 %r28;
.reg .u32 %r29;
.reg .u32 %r30;
.reg .pred %r31;
.reg .pred %r32;
.reg .u32 %r33;
.reg .pred %r34;
.reg .pred %r35;
.reg .pred %r36;
.reg .f64 %r37;
mov.f64 %r28,%ar0;
mov.u32 %r29,%ar1;
.loc 1 1879 31
abs.s32 %r25,%r29;
.loc 1 1880 14
and.b32 %r30,%r25,1;
.loc 1 1880 22
setp.ne.u32 %r31,%r30,0;
selp.f64 %r27,%r28,0d3ff0000000000000,%r31;
.loc 1 1881 12
shr.u32 %r26,%r25,1;
.loc 1 1881 9
setp.eq.u32 %r32,%r26,0;
@ %r32 bra $L3;
$L5:
.loc 1 1883 9
mul.f64 %r28,%r28,%r28;
.loc 1 1884 13
and.b32 %r33,%r26,1;
.loc 1 1884 10
setp.eq.u32 %r34,%r33,0;
@ %r34 bra $L4;
.loc 1 1885 4
mul.f64 %r27,%r27,%r28;
$L4:
.loc 1 1881 12
shr.u32 %r26,%r26,1;
.loc 1 1881 9
setp.ne.u32 %r35,%r26,0;
@ %r35 bra $L5;
$L3:
.loc 1 1887 22
setp.ge.s32 %r36,%r29,0;
@ %r36 bra $L1;
mov.f64 %r37,0d3ff0000000000000;
div.rn.f64 %r27,%r37,%r27;
$L1:
.loc 1 1888 1
mov.f64 %value,%r27;
st.param.f64 [%value_out],%value;
ret;
}

_powixf2.o/     1608280943  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_powitf2.o/     1608280943  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_mulhc3.o/      1608280943  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_mulsc3.o/      1608280943  0     0     100666  6445      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __mulsc3
.visible .func __mulsc3 (.param .u64 %in_ar0, .param .f32 %in_ar1, .param .f32 %in_ar2, .param .f32 %in_ar3, .param .f32 %in_ar4);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __mulsc3
.visible .func __mulsc3 (.param .u64 %in_ar0, .param .f32 %in_ar1, .param .f32 %in_ar2, .param .f32 %in_ar3, .param .f32 %in_ar4)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .f32 %ar1;
ld.param.f32 %ar1,[%in_ar1];
.reg .f32 %ar2;
ld.param.f32 %ar2,[%in_ar2];
.reg .f32 %ar3;
ld.param.f32 %ar3,[%in_ar3];
.reg .f32 %ar4;
ld.param.f32 %ar4,[%in_ar4];
.reg .u32 %r24;
.reg .f32 %r25;
.reg .u32 %r27;
.reg .f32 %r34;
.reg .u32 %r36;
.reg .f32 %r48;
.reg .f32 %r50;
.reg .f32 %r51;
.reg .f32 %r52;
.reg .f32 %r53;
.reg .f32 %r54;
.reg .f32 %r55;
.reg .f32 %r56;
.reg .f32 %r57;
.reg .f32 %r58;
.reg .u64 %r60;
.reg .f32 %r61;
.reg .f32 %r62;
.reg .f32 %r63;
.reg .f32 %r64;
.reg .u32 %r66;
.reg .u32 %r67;
.reg .u32 %r69;
.reg .u32 %r70;
.reg .u16 %r71;
.reg .u16 %r72;
.reg .u16 %r73;
.reg .u32 %r74;
.reg .pred %r75;
.reg .u32 %r77;
.reg .u32 %r78;
.reg .u16 %r79;
.reg .u16 %r80;
.reg .u32 %r81;
.reg .pred %r82;
.reg .pred %r83;
.reg .f32 %r84;
.reg .u32 %r86;
.reg .u32 %r87;
.reg .u16 %r88;
.reg .u16 %r89;
.reg .u32 %r90;
.reg .u32 %r91;
.reg .f32 %r92;
.reg .pred %r93;
.reg .f32 %r94;
.reg .pred %r95;
.reg .f32 %r96;
.reg .u32 %r98;
.reg .u32 %r99;
.reg .u16 %r100;
.reg .u16 %r101;
.reg .u32 %r102;
.reg .pred %r103;
.reg .pred %r104;
.reg .f32 %r105;
.reg .u32 %r107;
.reg .u32 %r108;
.reg .u16 %r109;
.reg .u16 %r110;
.reg .u32 %r111;
.reg .u32 %r112;
.reg .f32 %r113;
.reg .pred %r114;
.reg .f32 %r115;
.reg .pred %r116;
.reg .f32 %r117;
.reg .pred %r118;
.reg .f32 %r119;
.reg .pred %r120;
.reg .f32 %r121;
.reg .pred %r122;
.reg .f32 %r123;
.reg .pred %r124;
.reg .f32 %r125;
.reg .pred %r126;
.reg .pred %r127;
.reg .f32 %r128;
.reg .pred %r129;
.reg .f32 %r130;
.reg .pred %r131;
.reg .f32 %r132;
.reg .pred %r133;
.reg .f32 %r134;
.reg .f32 %r135;
.reg .f32 %r136;
.reg .f32 %r137;
mov.u64 %r60,%ar0;
mov.f32 %r61,%ar1;
mov.f32 %r62,%ar2;
mov.f32 %r63,%ar3;
mov.f32 %r64,%ar4;
.loc 1 1972 6
mul.f32 %r53,%r61,%r63;
.loc 1 1973 6
mul.f32 %r54,%r62,%r64;
.loc 1 1974 6
mul.f32 %r55,%r61,%r64;
.loc 1 1975 6
mul.f32 %r56,%r63,%r62;
.loc 1 1982 5
sub.f32 %r51,%r53,%r54;
.loc 1 1983 5
add.f32 %r52,%r55,%r56;
.loc 1 1985 7
set.u32.nan.f32 %r66,%r51,%r51;
neg.s32 %r67,%r66;
.loc 1 1985 20
set.u32.nan.f32 %r69,%r52,%r52;
neg.s32 %r70,%r69;
.loc 1 1985 17
cvt.u16.u32 %r72,%r67;
cvt.u16.u32 %r73,%r70;
and.b16 %r71,%r72,%r73;
cvt.u32.u16 %r74,%r71;
cvt.u32.u8 %r24,%r74;
.loc 1 1985 6
setp.eq.u32 %r75,%r24,0;
@ %r75 bra $L2;
.loc 1 1989 11
abs.f32 %r25,%r61;
.loc 1 1989 10
set.u32.leu.f32 %r77,%r25,0f7f7fffff;
neg.s32 %r78,%r77;
cvt.u16.u32 %r80,%r78;
xor.b16 %r79,%r80,1;
cvt.u32.u16 %r81,%r79;
cvt.u32.u8 %r27,%r81;
.loc 1 1989 24
abs.f32 %r58,%r62;
.loc 1 1989 10
setp.leu.f32 %r82,%r25,0f7f7fffff;
@ ! %r82 bra $L3;
.loc 1 1989 21
setp.leu.f32 %r83,%r58,0f7f7fffff;
@ %r83 bra $L19;
$L3:
.loc 1 1993 8
cvt.rn.f32.s32 %r84,%r27;
copysign.f32 %r61,%r61,%r84;
.loc 1 1994 32
set.u32.leu.f32 %r86,%r58,0f7f7fffff;
neg.s32 %r87,%r86;
cvt.u16.u32 %r89,%r87;
xor.b16 %r88,%r89,1;
cvt.u32.u16 %r91,%r88;
cvt.u32.u8 %r90,%r91;
.loc 1 1994 8
cvt.rn.f32.s32 %r92,%r90;
copysign.f32 %r62,%r62,%r92;
.loc 1 1995 7
setp.num.f32 %r93,%r63,%r63;
@ %r93 bra $L6;
.loc 1 1995 23
mov.f32 %r94,0f00000000;
copysign.f32 %r63,%r63,%r94;
$L6:
.loc 1 1996 7
setp.num.f32 %r95,%r64,%r64;
@ %r95 bra $L5;
.loc 1 1996 23
mov.f32 %r96,0f00000000;
copysign.f32 %r64,%r64,%r96;
bra $L5;
$L19:
.loc 1 1988 13
mov.u32 %r24,0;
$L5:
.loc 1 1999 10
abs.f32 %r34,%r63;
.loc 1 1999 9
set.u32.leu.f32 %r98,%r34,0f7f7fffff;
neg.s32 %r99,%r98;
cvt.u16.u32 %r101,%r99;
xor.b16 %r100,%r101,1;
cvt.u32.u16 %r102,%r100;
cvt.u32.u8 %r36,%r102;
.loc 1 1999 23
abs.f32 %r57,%r64;
.loc 1 1999 9
setp.leu.f32 %r103,%r34,0f7f7fffff;
@ ! %r103 bra $L7;
.loc 1 1999 20
setp.leu.f32 %r104,%r57,0f7f7fffff;
@ %r104 bra $L9;
$L7:
.loc 1 2003 8
cvt.rn.f32.s32 %r105,%r36;
copysign.f32 %r63,%r63,%r105;
.loc 1 2004 32
set.u32.leu.f32 %r107,%r57,0f7f7fffff;
neg.s32 %r108,%r107;
cvt.u16.u32 %r110,%r108;
xor.b16 %r109,%r110,1;
cvt.u32.u16 %r112,%r109;
cvt.u32.u8 %r111,%r112;
.loc 1 2004 8
cvt.rn.f32.s32 %r113,%r111;
copysign.f32 %r64,%r64,%r113;
.loc 1 2005 7
setp.num.f32 %r114,%r61,%r61;
@ %r114 bra $L10;
.loc 1 2005 23
mov.f32 %r115,0f00000000;
copysign.f32 %r61,%r61,%r115;
$L10:
.loc 1 2006 7
setp.num.f32 %r116,%r62,%r62;
@ %r116 bra $L11;
.loc 1 2006 23
mov.f32 %r117,0f00000000;
copysign.f32 %r62,%r62,%r117;
bra $L11;
$L9:
.loc 1 2009 9
setp.ne.u32 %r118,%r24,0;
@ %r118 bra $L11;
.loc 1 2010 8
abs.f32 %r119,%r53;
.loc 1 2010 4
setp.leu.f32 %r120,%r119,0f7f7fffff;
@ ! %r120 bra $L12;
.loc 1 2010 22
abs.f32 %r121,%r54;
.loc 1 2010 19
setp.leu.f32 %r122,%r121,0f7f7fffff;
@ ! %r122 bra $L12;
.loc 1 2011 11
abs.f32 %r123,%r55;
.loc 1 2011 8
setp.leu.f32 %r124,%r123,0f7f7fffff;
@ ! %r124 bra $L12;
.loc 1 2011 25
abs.f32 %r125,%r56;
.loc 1 2011 22
setp.leu.f32 %r126,%r125,0f7f7fffff;
@ %r126 bra $L2;
$L12:
.loc 1 2014 7
setp.num.f32 %r127,%r61,%r61;
@ %r127 bra $L16;
.loc 1 2014 23
mov.f32 %r128,0f00000000;
copysign.f32 %r61,%r61,%r128;
$L16:
.loc 1 2015 7
setp.num.f32 %r129,%r62,%r62;
@ %r129 bra $L17;
.loc 1 2015 23
mov.f32 %r130,0f00000000;
copysign.f32 %r62,%r62,%r130;
$L17:
.loc 1 2016 7
setp.num.f32 %r131,%r63,%r63;
@ %r131 bra $L18;
.loc 1 2016 23
mov.f32 %r132,0f00000000;
copysign.f32 %r63,%r63,%r132;
$L18:
.loc 1 2017 7
setp.num.f32 %r133,%r64,%r64;
@ %r133 bra $L11;
.loc 1 2017 23
mov.f32 %r134,0f00000000;
copysign.f32 %r64,%r64,%r134;
$L11:
.loc 1 2022 30
mul.f32 %r135,%r62,%r64;
.loc 1 2022 26
neg.f32 %r136,%r135;
fma.rn.f32 %r48,%r61,%r63,%r136;
.loc 1 2022 6
mul.f32 %r51,%r48,0f7f800000;
.loc 1 2023 30
mul.f32 %r137,%r62,%r63;
.loc 1 2023 26
fma.rn.f32 %r50,%r61,%r64,%r137;
.loc 1 2023 6
mul.f32 %r52,%r50,0f7f800000;
$L2:
.loc 1 2029 10
st.f32 [%r60],%r51;
st.f32 [%r60+4],%r52;
.loc 1 2030 1
ret;
}

_muldc3.o/      1608280944  0     0     100666  6621      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __muldc3
.visible .func __muldc3 (.param .u64 %in_ar0, .param .f64 %in_ar1, .param .f64 %in_ar2, .param .f64 %in_ar3, .param .f64 %in_ar4);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __muldc3
.visible .func __muldc3 (.param .u64 %in_ar0, .param .f64 %in_ar1, .param .f64 %in_ar2, .param .f64 %in_ar3, .param .f64 %in_ar4)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .f64 %ar1;
ld.param.f64 %ar1,[%in_ar1];
.reg .f64 %ar2;
ld.param.f64 %ar2,[%in_ar2];
.reg .f64 %ar3;
ld.param.f64 %ar3,[%in_ar3];
.reg .f64 %ar4;
ld.param.f64 %ar4,[%in_ar4];
.reg .u32 %r24;
.reg .f64 %r25;
.reg .u32 %r27;
.reg .f64 %r34;
.reg .u32 %r36;
.reg .f64 %r48;
.reg .f64 %r50;
.reg .f64 %r51;
.reg .f64 %r52;
.reg .f64 %r53;
.reg .f64 %r54;
.reg .f64 %r55;
.reg .f64 %r56;
.reg .f64 %r57;
.reg .f64 %r58;
.reg .u64 %r60;
.reg .f64 %r61;
.reg .f64 %r62;
.reg .f64 %r63;
.reg .f64 %r64;
.reg .u32 %r66;
.reg .u32 %r67;
.reg .u32 %r69;
.reg .u32 %r70;
.reg .u16 %r71;
.reg .u16 %r72;
.reg .u16 %r73;
.reg .u32 %r74;
.reg .pred %r75;
.reg .u32 %r77;
.reg .u32 %r78;
.reg .u16 %r79;
.reg .u16 %r80;
.reg .u32 %r81;
.reg .pred %r82;
.reg .pred %r83;
.reg .f64 %r84;
.reg .u32 %r86;
.reg .u32 %r87;
.reg .u16 %r88;
.reg .u16 %r89;
.reg .u32 %r90;
.reg .u32 %r91;
.reg .f64 %r92;
.reg .pred %r93;
.reg .f64 %r94;
.reg .pred %r95;
.reg .f64 %r96;
.reg .u32 %r98;
.reg .u32 %r99;
.reg .u16 %r100;
.reg .u16 %r101;
.reg .u32 %r102;
.reg .pred %r103;
.reg .pred %r104;
.reg .f64 %r105;
.reg .u32 %r107;
.reg .u32 %r108;
.reg .u16 %r109;
.reg .u16 %r110;
.reg .u32 %r111;
.reg .u32 %r112;
.reg .f64 %r113;
.reg .pred %r114;
.reg .f64 %r115;
.reg .pred %r116;
.reg .f64 %r117;
.reg .pred %r118;
.reg .f64 %r119;
.reg .pred %r120;
.reg .f64 %r121;
.reg .pred %r122;
.reg .f64 %r123;
.reg .pred %r124;
.reg .f64 %r125;
.reg .pred %r126;
.reg .pred %r127;
.reg .f64 %r128;
.reg .pred %r129;
.reg .f64 %r130;
.reg .pred %r131;
.reg .f64 %r132;
.reg .pred %r133;
.reg .f64 %r134;
.reg .f64 %r135;
.reg .f64 %r136;
.reg .f64 %r137;
mov.u64 %r60,%ar0;
mov.f64 %r61,%ar1;
mov.f64 %r62,%ar2;
mov.f64 %r63,%ar3;
mov.f64 %r64,%ar4;
.loc 1 1972 6
mul.f64 %r53,%r61,%r63;
.loc 1 1973 6
mul.f64 %r54,%r62,%r64;
.loc 1 1974 6
mul.f64 %r55,%r61,%r64;
.loc 1 1975 6
mul.f64 %r56,%r63,%r62;
.loc 1 1982 5
sub.f64 %r51,%r53,%r54;
.loc 1 1983 5
add.f64 %r52,%r55,%r56;
.loc 1 1985 7
set.u32.nan.f64 %r66,%r51,%r51;
neg.s32 %r67,%r66;
.loc 1 1985 20
set.u32.nan.f64 %r69,%r52,%r52;
neg.s32 %r70,%r69;
.loc 1 1985 17
cvt.u16.u32 %r72,%r67;
cvt.u16.u32 %r73,%r70;
and.b16 %r71,%r72,%r73;
cvt.u32.u16 %r74,%r71;
cvt.u32.u8 %r24,%r74;
.loc 1 1985 6
setp.eq.u32 %r75,%r24,0;
@ %r75 bra $L2;
.loc 1 1989 11
abs.f64 %r25,%r61;
.loc 1 1989 10
set.u32.leu.f64 %r77,%r25,0d7fefffffffffffff;
neg.s32 %r78,%r77;
cvt.u16.u32 %r80,%r78;
xor.b16 %r79,%r80,1;
cvt.u32.u16 %r81,%r79;
cvt.u32.u8 %r27,%r81;
.loc 1 1989 24
abs.f64 %r58,%r62;
.loc 1 1989 10
setp.leu.f64 %r82,%r25,0d7fefffffffffffff;
@ ! %r82 bra $L3;
.loc 1 1989 21
setp.leu.f64 %r83,%r58,0d7fefffffffffffff;
@ %r83 bra $L19;
$L3:
.loc 1 1993 8
cvt.rn.f64.s32 %r84,%r27;
copysign.f64 %r61,%r61,%r84;
.loc 1 1994 32
set.u32.leu.f64 %r86,%r58,0d7fefffffffffffff;
neg.s32 %r87,%r86;
cvt.u16.u32 %r89,%r87;
xor.b16 %r88,%r89,1;
cvt.u32.u16 %r91,%r88;
cvt.u32.u8 %r90,%r91;
.loc 1 1994 8
cvt.rn.f64.s32 %r92,%r90;
copysign.f64 %r62,%r62,%r92;
.loc 1 1995 7
setp.num.f64 %r93,%r63,%r63;
@ %r93 bra $L6;
.loc 1 1995 23
mov.f64 %r94,0d0000000000000000;
copysign.f64 %r63,%r63,%r94;
$L6:
.loc 1 1996 7
setp.num.f64 %r95,%r64,%r64;
@ %r95 bra $L5;
.loc 1 1996 23
mov.f64 %r96,0d0000000000000000;
copysign.f64 %r64,%r64,%r96;
bra $L5;
$L19:
.loc 1 1988 13
mov.u32 %r24,0;
$L5:
.loc 1 1999 10
abs.f64 %r34,%r63;
.loc 1 1999 9
set.u32.leu.f64 %r98,%r34,0d7fefffffffffffff;
neg.s32 %r99,%r98;
cvt.u16.u32 %r101,%r99;
xor.b16 %r100,%r101,1;
cvt.u32.u16 %r102,%r100;
cvt.u32.u8 %r36,%r102;
.loc 1 1999 23
abs.f64 %r57,%r64;
.loc 1 1999 9
setp.leu.f64 %r103,%r34,0d7fefffffffffffff;
@ ! %r103 bra $L7;
.loc 1 1999 20
setp.leu.f64 %r104,%r57,0d7fefffffffffffff;
@ %r104 bra $L9;
$L7:
.loc 1 2003 8
cvt.rn.f64.s32 %r105,%r36;
copysign.f64 %r63,%r63,%r105;
.loc 1 2004 32
set.u32.leu.f64 %r107,%r57,0d7fefffffffffffff;
neg.s32 %r108,%r107;
cvt.u16.u32 %r110,%r108;
xor.b16 %r109,%r110,1;
cvt.u32.u16 %r112,%r109;
cvt.u32.u8 %r111,%r112;
.loc 1 2004 8
cvt.rn.f64.s32 %r113,%r111;
copysign.f64 %r64,%r64,%r113;
.loc 1 2005 7
setp.num.f64 %r114,%r61,%r61;
@ %r114 bra $L10;
.loc 1 2005 23
mov.f64 %r115,0d0000000000000000;
copysign.f64 %r61,%r61,%r115;
$L10:
.loc 1 2006 7
setp.num.f64 %r116,%r62,%r62;
@ %r116 bra $L11;
.loc 1 2006 23
mov.f64 %r117,0d0000000000000000;
copysign.f64 %r62,%r62,%r117;
bra $L11;
$L9:
.loc 1 2009 9
setp.ne.u32 %r118,%r24,0;
@ %r118 bra $L11;
.loc 1 2010 8
abs.f64 %r119,%r53;
.loc 1 2010 4
setp.leu.f64 %r120,%r119,0d7fefffffffffffff;
@ ! %r120 bra $L12;
.loc 1 2010 22
abs.f64 %r121,%r54;
.loc 1 2010 19
setp.leu.f64 %r122,%r121,0d7fefffffffffffff;
@ ! %r122 bra $L12;
.loc 1 2011 11
abs.f64 %r123,%r55;
.loc 1 2011 8
setp.leu.f64 %r124,%r123,0d7fefffffffffffff;
@ ! %r124 bra $L12;
.loc 1 2011 25
abs.f64 %r125,%r56;
.loc 1 2011 22
setp.leu.f64 %r126,%r125,0d7fefffffffffffff;
@ %r126 bra $L2;
$L12:
.loc 1 2014 7
setp.num.f64 %r127,%r61,%r61;
@ %r127 bra $L16;
.loc 1 2014 23
mov.f64 %r128,0d0000000000000000;
copysign.f64 %r61,%r61,%r128;
$L16:
.loc 1 2015 7
setp.num.f64 %r129,%r62,%r62;
@ %r129 bra $L17;
.loc 1 2015 23
mov.f64 %r130,0d0000000000000000;
copysign.f64 %r62,%r62,%r130;
$L17:
.loc 1 2016 7
setp.num.f64 %r131,%r63,%r63;
@ %r131 bra $L18;
.loc 1 2016 23
mov.f64 %r132,0d0000000000000000;
copysign.f64 %r63,%r63,%r132;
$L18:
.loc 1 2017 7
setp.num.f64 %r133,%r64,%r64;
@ %r133 bra $L11;
.loc 1 2017 23
mov.f64 %r134,0d0000000000000000;
copysign.f64 %r64,%r64,%r134;
$L11:
.loc 1 2022 30
mul.f64 %r135,%r62,%r64;
.loc 1 2022 26
neg.f64 %r136,%r135;
fma.rn.f64 %r48,%r61,%r63,%r136;
.loc 1 2022 6
mul.f64 %r51,%r48,0d7ff0000000000000;
.loc 1 2023 30
mul.f64 %r137,%r62,%r63;
.loc 1 2023 26
fma.rn.f64 %r50,%r61,%r64,%r137;
.loc 1 2023 6
mul.f64 %r52,%r50,0d7ff0000000000000;
$L2:
.loc 1 2029 10
st.f64 [%r60],%r51;
st.f64 [%r60+8],%r52;
.loc 1 2030 1
ret;
}

_mulxc3.o/      1608280944  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_multc3.o/      1608280944  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_divhc3.o/      1608280944  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_divsc3.o/      1608280944  0     0     100666  7248      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __divsc3
.visible .func __divsc3 (.param .u64 %in_ar0, .param .f32 %in_ar1, .param .f32 %in_ar2, .param .f32 %in_ar3, .param .f32 %in_ar4);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __divsc3
.visible .func __divsc3 (.param .u64 %in_ar0, .param .f32 %in_ar1, .param .f32 %in_ar2, .param .f32 %in_ar3, .param .f32 %in_ar4)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .f32 %ar1;
ld.param.f32 %ar1,[%in_ar1];
.reg .f32 %ar2;
ld.param.f32 %ar2,[%in_ar2];
.reg .f32 %ar3;
ld.param.f32 %ar3,[%in_ar3];
.reg .f32 %ar4;
ld.param.f32 %ar4,[%in_ar4];
.reg .f32 %r22;
.reg .f32 %r23;
.reg .f32 %r24;
.reg .f32 %r25;
.reg .f32 %r26;
.reg .f32 %r27;
.reg .f32 %r34;
.reg .f32 %r35;
.reg .f32 %r45;
.reg .f32 %r47;
.reg .f32 %r49;
.reg .f32 %r60;
.reg .f32 %r62;
.reg .f32 %r63;
.reg .f32 %r64;
.reg .f32 %r65;
.reg .f32 %r66;
.reg .f32 %r67;
.reg .f32 %r68;
.reg .f32 %r69;
.reg .f32 %r70;
.reg .f32 %r71;
.reg .f32 %r72;
.reg .u64 %r81;
.reg .f32 %r82;
.reg .f32 %r83;
.reg .f32 %r84;
.reg .f32 %r85;
.reg .pred %r86;
.reg .f32 %r87;
.reg .f32 %r88;
.reg .u32 %r90;
.reg .u32 %r91;
.reg .u32 %r93;
.reg .u32 %r94;
.reg .u16 %r95;
.reg .u16 %r96;
.reg .u16 %r97;
.reg .u32 %r98;
.reg .u16 %r99;
.reg .pred %r100;
.reg .u32 %r102;
.reg .u32 %r103;
.reg .u32 %r105;
.reg .u32 %r106;
.reg .u16 %r107;
.reg .u16 %r108;
.reg .u16 %r109;
.reg .u32 %r110;
.reg .u16 %r111;
.reg .pred %r112;
.reg .u32 %r114;
.reg .u32 %r115;
.reg .u32 %r117;
.reg .u32 %r118;
.reg .u16 %r119;
.reg .u16 %r120;
.reg .u16 %r121;
.reg .u32 %r122;
.reg .u16 %r123;
.reg .pred %r124;
.reg .f32 %r125;
.reg .pred %r126;
.reg .f32 %r127;
.reg .pred %r128;
.reg .pred %r129;
.reg .pred %r130;
.reg .u32 %r132;
.reg .u32 %r133;
.reg .u16 %r134;
.reg .u16 %r135;
.reg .u32 %r136;
.reg .u32 %r137;
.reg .f32 %r138;
.reg .f32 %r139;
.reg .u32 %r141;
.reg .u32 %r142;
.reg .u16 %r143;
.reg .u16 %r144;
.reg .u32 %r145;
.reg .u32 %r146;
.reg .f32 %r147;
.reg .f32 %r148;
.reg .f32 %r149;
.reg .u32 %r150;
.reg .u32 %r151;
.reg .u32 %r152;
.reg .u32 %r153;
.reg .u32 %r154;
.reg .u32 %r155;
.reg .u16 %r156;
.reg .u16 %r157;
.reg .u16 %r158;
.reg .u32 %r159;
.reg .u16 %r160;
.reg .pred %r161;
.reg .pred %r162;
.reg .f32 %r163;
.reg .pred %r164;
.reg .u16 %r165;
.reg .u32 %r167;
.reg .u32 %r168;
.reg .f32 %r169;
.reg .u16 %r170;
.reg .u32 %r172;
.reg .u32 %r173;
.reg .f32 %r174;
.reg .f32 %r175;
.reg .f32 %r176;
.reg .f32 %r177;
mov.u64 %r81,%ar0;
mov.f32 %r82,%ar1;
mov.f32 %r83,%ar2;
mov.f32 %r84,%ar3;
mov.f32 %r85,%ar4;
.loc 1 2046 7
abs.f32 %r22,%r84;
.loc 1 2046 18
abs.f32 %r23,%r85;
.loc 1 2046 6
setp.lt.f32 %r86,%r22,%r23;
@ ! %r86 bra $L21;
.loc 1 2048 13
div.rn.f32 %r67,%r84,%r85;
.loc 1 2049 13
fma.rn.f32 %r68,%r84,%r67,%r85;
.loc 1 2050 24
fma.rn.f32 %r24,%r82,%r67,%r83;
.loc 1 2050 9
div.rn.f32 %r63,%r24,%r68;
.loc 1 2051 24
neg.f32 %r87,%r82;
fma.rn.f32 %r25,%r83,%r67,%r87;
.loc 1 2051 9
div.rn.f32 %r64,%r25,%r68;
bra $L4;
$L21:
.loc 1 2055 13
div.rn.f32 %r65,%r85,%r84;
.loc 1 2056 13
fma.rn.f32 %r66,%r85,%r65,%r84;
.loc 1 2057 24
fma.rn.f32 %r26,%r65,%r83,%r82;
.loc 1 2057 9
div.rn.f32 %r63,%r26,%r66;
.loc 1 2058 14
neg.f32 %r88,%r65;
fma.rn.f32 %r27,%r88,%r82,%r83;
.loc 1 2058 9
div.rn.f32 %r64,%r27,%r66;
$L4:
.loc 1 2063 7
set.u32.nan.f32 %r90,%r63,%r63;
neg.s32 %r91,%r90;
.loc 1 2063 20
set.u32.nan.f32 %r93,%r64,%r64;
neg.s32 %r94,%r93;
.loc 1 2063 17
cvt.u16.u32 %r96,%r91;
cvt.u16.u32 %r97,%r94;
and.b16 %r95,%r96,%r97;
.loc 1 2063 6
cvt.u32.u16 %r98,%r95;
cvt.u16.u8 %r99,%r98;
setp.eq.u16 %r100,%r99,0;
@ %r100 bra $L5;
.loc 1 2065 20
set.u32.eq.f32 %r102,%r85,0f00000000;
neg.s32 %r103,%r102;
.loc 1 2065 10
set.u32.eq.f32 %r105,%r84,0f00000000;
neg.s32 %r106,%r105;
.loc 1 2065 20
cvt.u16.u32 %r108,%r103;
cvt.u16.u32 %r109,%r106;
and.b16 %r107,%r108,%r109;
cvt.u32.u16 %r110,%r107;
cvt.u16.u8 %r111,%r110;
setp.eq.u16 %r112,%r111,0;
@ %r112 bra $L6;
.loc 1 2065 36
set.u32.num.f32 %r114,%r82,%r82;
neg.s32 %r115,%r114;
.loc 1 2065 50
set.u32.num.f32 %r117,%r83,%r83;
neg.s32 %r118,%r117;
.loc 1 2065 47
cvt.u16.u32 %r120,%r115;
cvt.u16.u32 %r121,%r118;
or.b16 %r119,%r120,%r121;
.loc 1 2065 32
cvt.u32.u16 %r122,%r119;
cvt.u16.u8 %r123,%r122;
setp.eq.u16 %r124,%r123,0;
@ %r124 bra $L6;
.loc 1 2067 8
mov.f32 %r125,0f7f800000;
copysign.f32 %r34,%r84,%r125;
.loc 1 2067 6
mul.f32 %r63,%r34,%r82;
.loc 1 2068 6
mul.f32 %r64,%r34,%r83;
bra $L5;
$L6:
.loc 1 2070 17
abs.f32 %r35,%r82;
.loc 1 2070 15
setp.leu.f32 %r126,%r35,0f7f7fffff;
@ ! %r126 bra $L7;
.loc 1 2070 30
abs.f32 %r127,%r83;
.loc 1 2070 27
setp.leu.f32 %r128,%r127,0f7f7fffff;
@ %r128 bra $L9;
$L7:
.loc 1 2070 41
setp.gtu.f32 %r129,%r22,0f7f7fffff;
@ %r129 bra $L9;
.loc 1 2070 57
setp.gtu.f32 %r130,%r23,0f7f7fffff;
@ %r130 bra $L9;
.loc 1 2070 15
set.u32.leu.f32 %r132,%r35,0f7f7fffff;
neg.s32 %r133,%r132;
cvt.u16.u32 %r135,%r133;
xor.b16 %r134,%r135,1;
.loc 1 2072 32
cvt.u32.u16 %r137,%r134;
cvt.u32.u8 %r136,%r137;
.loc 1 2072 8
cvt.rn.f32.s32 %r138,%r136;
copysign.f32 %r69,%r82,%r138;
.loc 1 2073 18
abs.f32 %r139,%r83;
.loc 1 2073 32
set.u32.leu.f32 %r141,%r139,0f7f7fffff;
neg.s32 %r142,%r141;
cvt.u16.u32 %r144,%r142;
xor.b16 %r143,%r144,1;
cvt.u32.u16 %r146,%r143;
cvt.u32.u8 %r145,%r146;
.loc 1 2073 8
cvt.rn.f32.s32 %r45,%r145;
copysign.f32 %r70,%r83,%r45;
.loc 1 2074 30
mul.f32 %r147,%r85,%r70;
.loc 1 2074 26
fma.rn.f32 %r47,%r84,%r69,%r147;
.loc 1 2074 6
mul.f32 %r63,%r47,0f7f800000;
.loc 1 2075 30
mul.f32 %r148,%r85,%r69;
.loc 1 2075 26
neg.f32 %r149,%r148;
fma.rn.f32 %r49,%r84,%r70,%r149;
.loc 1 2075 6
mul.f32 %r64,%r49,0f7f800000;
bra $L5;
$L9:
.loc 1 2077 15
set.u32.leu.f32 %r151,%r22,0f7f7fffff;
neg.s32 %r152,%r151;
cvt.u32.u32 %r150,%r152;
.loc 1 2077 27
set.u32.leu.f32 %r154,%r23,0f7f7fffff;
neg.s32 %r155,%r154;
cvt.u32.u32 %r153,%r155;
cvt.u16.u8 %r157,%r150;
cvt.u16.u8 %r158,%r153;
and.b16 %r156,%r157,%r158;
cvt.u32.u16 %r159,%r156;
cvt.u16.u8 %r160,%r159;
setp.ne.u16 %r161,%r160,0;
@ %r161 bra $L5;
.loc 1 2077 41
setp.gtu.f32 %r162,%r35,0f7f7fffff;
@ %r162 bra $L5;
.loc 1 2077 60
abs.f32 %r163,%r83;
.loc 1 2077 57
setp.gtu.f32 %r164,%r163,0f7f7fffff;
@ %r164 bra $L5;
.loc 1 2077 15
xor.b16 %r165,%r157,1;
.loc 1 2079 32
cvt.u32.u16 %r168,%r165;
cvt.u32.u8 %r167,%r168;
.loc 1 2079 8
cvt.rn.f32.s32 %r169,%r167;
copysign.f32 %r71,%r84,%r169;
.loc 1 2080 32
xor.b16 %r170,%r158,1;
cvt.u32.u16 %r173,%r170;
cvt.u32.u8 %r172,%r173;
.loc 1 2080 8
cvt.rn.f32.s32 %r174,%r172;
copysign.f32 %r72,%r85,%r174;
.loc 1 2081 25
mul.f32 %r175,%r83,%r72;
.loc 1 2081 21
fma.rn.f32 %r60,%r82,%r71,%r175;
.loc 1 2081 6
mul.f32 %r63,%r60,0f00000000;
.loc 1 2082 25
mul.f32 %r176,%r82,%r72;
.loc 1 2082 21
neg.f32 %r177,%r176;
fma.rn.f32 %r62,%r83,%r71,%r177;
.loc 1 2082 6
mul.f32 %r64,%r62,0f00000000;
$L5:
.loc 1 2088 10
st.f32 [%r81],%r63;
st.f32 [%r81+4],%r64;
.loc 1 2089 1
ret;
}
_divdc3.o/      1608280944  0     0     100666  7400      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __divdc3
.visible .func __divdc3 (.param .u64 %in_ar0, .param .f64 %in_ar1, .param .f64 %in_ar2, .param .f64 %in_ar3, .param .f64 %in_ar4);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __divdc3
.visible .func __divdc3 (.param .u64 %in_ar0, .param .f64 %in_ar1, .param .f64 %in_ar2, .param .f64 %in_ar3, .param .f64 %in_ar4)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .f64 %ar1;
ld.param.f64 %ar1,[%in_ar1];
.reg .f64 %ar2;
ld.param.f64 %ar2,[%in_ar2];
.reg .f64 %ar3;
ld.param.f64 %ar3,[%in_ar3];
.reg .f64 %ar4;
ld.param.f64 %ar4,[%in_ar4];
.reg .f64 %r22;
.reg .f64 %r23;
.reg .f64 %r24;
.reg .f64 %r25;
.reg .f64 %r26;
.reg .f64 %r27;
.reg .f64 %r37;
.reg .f64 %r38;
.reg .f64 %r48;
.reg .f64 %r50;
.reg .f64 %r52;
.reg .f64 %r63;
.reg .f64 %r65;
.reg .f64 %r66;
.reg .f64 %r67;
.reg .f64 %r68;
.reg .f64 %r69;
.reg .f64 %r70;
.reg .f64 %r71;
.reg .f64 %r72;
.reg .f64 %r73;
.reg .f64 %r74;
.reg .f64 %r75;
.reg .u64 %r81;
.reg .f64 %r82;
.reg .f64 %r83;
.reg .f64 %r84;
.reg .f64 %r85;
.reg .pred %r86;
.reg .f64 %r87;
.reg .f64 %r88;
.reg .u32 %r90;
.reg .u32 %r91;
.reg .u32 %r93;
.reg .u32 %r94;
.reg .u16 %r95;
.reg .u16 %r96;
.reg .u16 %r97;
.reg .u32 %r98;
.reg .u16 %r99;
.reg .pred %r100;
.reg .u32 %r102;
.reg .u32 %r103;
.reg .u32 %r105;
.reg .u32 %r106;
.reg .u16 %r107;
.reg .u16 %r108;
.reg .u16 %r109;
.reg .u32 %r110;
.reg .u16 %r111;
.reg .pred %r112;
.reg .u32 %r114;
.reg .u32 %r115;
.reg .u32 %r117;
.reg .u32 %r118;
.reg .u16 %r119;
.reg .u16 %r120;
.reg .u16 %r121;
.reg .u32 %r122;
.reg .u16 %r123;
.reg .pred %r124;
.reg .f64 %r125;
.reg .pred %r126;
.reg .f64 %r127;
.reg .pred %r128;
.reg .pred %r129;
.reg .pred %r130;
.reg .u32 %r132;
.reg .u32 %r133;
.reg .u16 %r134;
.reg .u16 %r135;
.reg .u32 %r136;
.reg .u32 %r137;
.reg .f64 %r138;
.reg .f64 %r139;
.reg .u32 %r141;
.reg .u32 %r142;
.reg .u16 %r143;
.reg .u16 %r144;
.reg .u32 %r145;
.reg .u32 %r146;
.reg .f64 %r147;
.reg .f64 %r148;
.reg .f64 %r149;
.reg .u32 %r150;
.reg .u32 %r151;
.reg .u32 %r152;
.reg .u32 %r153;
.reg .u32 %r154;
.reg .u32 %r155;
.reg .u16 %r156;
.reg .u16 %r157;
.reg .u16 %r158;
.reg .u32 %r159;
.reg .u16 %r160;
.reg .pred %r161;
.reg .pred %r162;
.reg .f64 %r163;
.reg .pred %r164;
.reg .u16 %r165;
.reg .u32 %r167;
.reg .u32 %r168;
.reg .f64 %r169;
.reg .u16 %r170;
.reg .u32 %r172;
.reg .u32 %r173;
.reg .f64 %r174;
.reg .f64 %r175;
.reg .f64 %r176;
.reg .f64 %r177;
mov.u64 %r81,%ar0;
mov.f64 %r82,%ar1;
mov.f64 %r83,%ar2;
mov.f64 %r84,%ar3;
mov.f64 %r85,%ar4;
.loc 1 2046 7
abs.f64 %r22,%r84;
.loc 1 2046 18
abs.f64 %r23,%r85;
.loc 1 2046 6
setp.lt.f64 %r86,%r22,%r23;
@ ! %r86 bra $L21;
.loc 1 2048 13
div.rn.f64 %r70,%r84,%r85;
.loc 1 2049 13
fma.rn.f64 %r71,%r84,%r70,%r85;
.loc 1 2050 24
fma.rn.f64 %r24,%r82,%r70,%r83;
.loc 1 2050 9
div.rn.f64 %r66,%r24,%r71;
.loc 1 2051 24
neg.f64 %r87,%r82;
fma.rn.f64 %r25,%r83,%r70,%r87;
.loc 1 2051 9
div.rn.f64 %r67,%r25,%r71;
bra $L4;
$L21:
.loc 1 2055 13
div.rn.f64 %r68,%r85,%r84;
.loc 1 2056 13
fma.rn.f64 %r69,%r85,%r68,%r84;
.loc 1 2057 24
fma.rn.f64 %r26,%r68,%r83,%r82;
.loc 1 2057 9
div.rn.f64 %r66,%r26,%r69;
.loc 1 2058 14
neg.f64 %r88,%r68;
fma.rn.f64 %r27,%r88,%r82,%r83;
.loc 1 2058 9
div.rn.f64 %r67,%r27,%r69;
$L4:
.loc 1 2063 7
set.u32.nan.f64 %r90,%r66,%r66;
neg.s32 %r91,%r90;
.loc 1 2063 20
set.u32.nan.f64 %r93,%r67,%r67;
neg.s32 %r94,%r93;
.loc 1 2063 17
cvt.u16.u32 %r96,%r91;
cvt.u16.u32 %r97,%r94;
and.b16 %r95,%r96,%r97;
.loc 1 2063 6
cvt.u32.u16 %r98,%r95;
cvt.u16.u8 %r99,%r98;
setp.eq.u16 %r100,%r99,0;
@ %r100 bra $L5;
.loc 1 2065 13
set.u32.eq.f64 %r102,%r84,0d0000000000000000;
neg.s32 %r103,%r102;
.loc 1 2065 25
set.u32.eq.f64 %r105,%r85,0d0000000000000000;
neg.s32 %r106,%r105;
.loc 1 2065 20
cvt.u16.u32 %r108,%r103;
cvt.u16.u32 %r109,%r106;
and.b16 %r107,%r108,%r109;
.loc 1 2065 10
cvt.u32.u16 %r110,%r107;
cvt.u16.u8 %r111,%r110;
setp.eq.u16 %r112,%r111,0;
@ %r112 bra $L6;
.loc 1 2065 36
set.u32.num.f64 %r114,%r82,%r82;
neg.s32 %r115,%r114;
.loc 1 2065 50
set.u32.num.f64 %r117,%r83,%r83;
neg.s32 %r118,%r117;
.loc 1 2065 47
cvt.u16.u32 %r120,%r115;
cvt.u16.u32 %r121,%r118;
or.b16 %r119,%r120,%r121;
.loc 1 2065 32
cvt.u32.u16 %r122,%r119;
cvt.u16.u8 %r123,%r122;
setp.eq.u16 %r124,%r123,0;
@ %r124 bra $L6;
.loc 1 2067 8
mov.f64 %r125,0d7ff0000000000000;
copysign.f64 %r37,%r84,%r125;
.loc 1 2067 6
mul.f64 %r66,%r37,%r82;
.loc 1 2068 6
mul.f64 %r67,%r37,%r83;
bra $L5;
$L6:
.loc 1 2070 17
abs.f64 %r38,%r82;
.loc 1 2070 15
setp.leu.f64 %r126,%r38,0d7fefffffffffffff;
@ ! %r126 bra $L7;
.loc 1 2070 30
abs.f64 %r127,%r83;
.loc 1 2070 27
setp.leu.f64 %r128,%r127,0d7fefffffffffffff;
@ %r128 bra $L9;
$L7:
.loc 1 2070 41
setp.gtu.f64 %r129,%r22,0d7fefffffffffffff;
@ %r129 bra $L9;
.loc 1 2070 57
setp.gtu.f64 %r130,%r23,0d7fefffffffffffff;
@ %r130 bra $L9;
.loc 1 2070 15
set.u32.leu.f64 %r132,%r38,0d7fefffffffffffff;
neg.s32 %r133,%r132;
cvt.u16.u32 %r135,%r133;
xor.b16 %r134,%r135,1;
.loc 1 2072 32
cvt.u32.u16 %r137,%r134;
cvt.u32.u8 %r136,%r137;
.loc 1 2072 8
cvt.rn.f64.s32 %r138,%r136;
copysign.f64 %r72,%r82,%r138;
.loc 1 2073 18
abs.f64 %r139,%r83;
.loc 1 2073 32
set.u32.leu.f64 %r141,%r139,0d7fefffffffffffff;
neg.s32 %r142,%r141;
cvt.u16.u32 %r144,%r142;
xor.b16 %r143,%r144,1;
cvt.u32.u16 %r146,%r143;
cvt.u32.u8 %r145,%r146;
.loc 1 2073 8
cvt.rn.f64.s32 %r48,%r145;
copysign.f64 %r73,%r83,%r48;
.loc 1 2074 30
mul.f64 %r147,%r85,%r73;
.loc 1 2074 26
fma.rn.f64 %r50,%r84,%r72,%r147;
.loc 1 2074 6
mul.f64 %r66,%r50,0d7ff0000000000000;
.loc 1 2075 30
mul.f64 %r148,%r85,%r72;
.loc 1 2075 26
neg.f64 %r149,%r148;
fma.rn.f64 %r52,%r84,%r73,%r149;
.loc 1 2075 6
mul.f64 %r67,%r52,0d7ff0000000000000;
bra $L5;
$L9:
.loc 1 2077 15
set.u32.leu.f64 %r151,%r22,0d7fefffffffffffff;
neg.s32 %r152,%r151;
cvt.u32.u32 %r150,%r152;
.loc 1 2077 27
set.u32.leu.f64 %r154,%r23,0d7fefffffffffffff;
neg.s32 %r155,%r154;
cvt.u32.u32 %r153,%r155;
cvt.u16.u8 %r157,%r150;
cvt.u16.u8 %r158,%r153;
and.b16 %r156,%r157,%r158;
cvt.u32.u16 %r159,%r156;
cvt.u16.u8 %r160,%r159;
setp.ne.u16 %r161,%r160,0;
@ %r161 bra $L5;
.loc 1 2077 41
setp.gtu.f64 %r162,%r38,0d7fefffffffffffff;
@ %r162 bra $L5;
.loc 1 2077 60
abs.f64 %r163,%r83;
.loc 1 2077 57
setp.gtu.f64 %r164,%r163,0d7fefffffffffffff;
@ %r164 bra $L5;
.loc 1 2077 15
xor.b16 %r165,%r157,1;
.loc 1 2079 32
cvt.u32.u16 %r168,%r165;
cvt.u32.u8 %r167,%r168;
.loc 1 2079 8
cvt.rn.f64.s32 %r169,%r167;
copysign.f64 %r74,%r84,%r169;
.loc 1 2080 32
xor.b16 %r170,%r158,1;
cvt.u32.u16 %r173,%r170;
cvt.u32.u8 %r172,%r173;
.loc 1 2080 8
cvt.rn.f64.s32 %r174,%r172;
copysign.f64 %r75,%r85,%r174;
.loc 1 2081 25
mul.f64 %r175,%r83,%r75;
.loc 1 2081 21
fma.rn.f64 %r63,%r82,%r74,%r175;
.loc 1 2081 6
mul.f64 %r66,%r63,0d0000000000000000;
.loc 1 2082 25
mul.f64 %r176,%r82,%r75;
.loc 1 2082 21
neg.f64 %r177,%r176;
fma.rn.f64 %r65,%r83,%r74,%r177;
.loc 1 2082 6
mul.f64 %r67,%r65,0d0000000000000000;
$L5:
.loc 1 2088 10
st.f64 [%r81],%r66;
st.f64 [%r81+8],%r67;
.loc 1 2089 1
ret;
}
_divxc3.o/      1608280944  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_divtc3.o/      1608280945  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_bswapsi2.o/    1608280945  0     0     100666  978       `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __bswapsi2
.visible .func (.param .u32 %value_out) __bswapsi2 (.param .u32 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __bswapsi2
.visible .func (.param .u32 %value_out) __bswapsi2 (.param .u32 %in_ar0)
{
.reg .u32 %value;
.reg .u32 %ar0;
ld.param.u32 %ar0,[%in_ar0];
.reg .u32 %r36;
.reg .u32 %r38;
.reg .u32 %r39;
.reg .u32 %r40;
.reg .u32 %r41;
.reg .u32 %r42;
.reg .u32 %r43;
.reg .u32 %r44;
.reg .u32 %r45;
mov.u32 %r36,%ar0;
.loc 1 491 31
shr.u32 %r38,%r36,24;
.loc 1 494 26
shl.b32 %r39,%r36,24;
.loc 1 494 4
or.b32 %r40,%r38,%r39;
.loc 1 492 26
shr.s32 %r41,%r36,8;
and.b32 %r42,%r41,65280;
.loc 1 494 4
or.b32 %r43,%r40,%r42;
.loc 1 493 26
shl.b32 %r44,%r36,8;
and.b32 %r45,%r44,16711680;
.loc 1 494 4
or.b32 %value,%r43,%r45;
.loc 1 495 1
st.param.u32 [%value_out],%value;
ret;
}
_bswapdi2.o/    1608280945  0     0     100666  1625      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __bswapdi2
.visible .func (.param .u64 %value_out) __bswapdi2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __bswapdi2
.visible .func (.param .u64 %value_out) __bswapdi2 (.param .u64 %in_ar0)
{
.reg .u64 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r45;
.reg .u64 %r47;
.reg .u64 %r48;
.reg .u64 %r49;
.reg .u64 %r50;
.reg .u64 %r51;
.reg .u64 %r52;
.reg .u64 %r53;
.reg .u64 %r54;
.reg .u64 %r55;
.reg .u64 %r56;
.reg .u64 %r57;
.reg .u64 %r58;
.reg .u64 %r59;
.reg .u64 %r60;
.reg .u64 %r61;
.reg .u64 %r62;
.reg .u64 %r63;
.reg .u64 %r64;
.reg .u64 %r65;
.reg .u64 %r66;
mov.u64 %r45,%ar0;
.loc 1 501 42
shr.u64 %r47,%r45,56;
.loc 1 508 37
shl.b64 %r48,%r45,56;
.loc 1 508 4
or.b64 %r49,%r47,%r48;
.loc 1 502 37
shr.u64 %r50,%r45,40;
and.b64 %r51,%r50,65280;
.loc 1 508 4
or.b64 %r52,%r49,%r51;
.loc 1 503 37
shr.u64 %r53,%r45,24;
and.b64 %r54,%r53,16711680;
.loc 1 508 4
or.b64 %r55,%r52,%r54;
.loc 1 504 37
shr.u64 %r56,%r45,8;
and.b64 %r57,%r56,4278190080;
.loc 1 508 4
or.b64 %r58,%r55,%r57;
.loc 1 505 37
shl.b64 %r59,%r45,8;
and.b64 %r60,%r59,1095216660480;
.loc 1 508 4
or.b64 %r61,%r58,%r60;
.loc 1 506 37
shl.b64 %r62,%r45,24;
and.b64 %r63,%r62,280375465082880;
.loc 1 508 4
or.b64 %r64,%r61,%r63;
.loc 1 507 37
shl.b64 %r65,%r45,40;
and.b64 %r66,%r65,71776119061217280;
.loc 1 508 4
or.b64 %value,%r64,%r66;
.loc 1 509 1
st.param.u64 [%value_out],%value;
ret;
}

_clrsbsi2.o/    1608280945  0     0     100666  1595      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __clrsbdi2
.visible .func (.param .u32 %value_out) __clrsbdi2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL FUNCTION DEF: __clrsbdi2
.visible .func (.param .u32 %value_out) __clrsbdi2 (.param .u64 %in_ar0)
{
.reg .u32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r22;
.reg .u64 %r29;
.reg .u64 %r30;
.reg .u64 %r32;
.reg .u32 %r33;
.reg .u64 %r34;
.reg .pred %r36;
.reg .u32 %r37;
.reg .u64 %r38;
.reg .pred %r39;
.reg .pred %r40;
.reg .u64 %r41;
.reg .u64 %r42;
.reg .u64 %r43;
.reg .u64 %r44;
.reg .u64 %r45;
.reg .u32 %r46;
.reg .u64 %r48;
mov.u64 %r34,%ar0;
.loc 1 775 7
not.b64 %r48,%r34;
max.s64 %r34,%r34,%r48;
.loc 1 776 6
setp.eq.u64 %r36,%r34,0;
@ %r36 bra $L7;
.loc 1 778 3
mov.u64 %r29,%r34;
mov.u64 %r30,56;
$L5:
cvt.u32.u64 %r37,%r30;
shr.u64 %r22,%r34,%r37;
and.b64 %r38,%r22,255;
setp.ne.u64 %r39,%r38,0;
@ %r39 bra $L4;
add.u64 %r30,%r30,-8;
setp.ne.u64 %r40,%r30,0;
@ %r40 bra $L5;
mov.u64 %r32,64;
bra $L6;
$L4:
mov.u64 %r41,64;
sub.u64 %r32,%r41,%r30;
mov.u64 %r29,%r22;
$L6:
cvta.const.u64 %r42,__clz_tab;
add.u64 %r43,%r42,%r29;
ld.u8 %r44,[%r43];
sub.u64 %r45,%r32,%r44;
.loc 1 779 14
cvt.u32.u64 %r46,%r45;
add.u32 %r33,%r46,-1;
bra $L1;
$L7:
.loc 1 777 12
mov.u32 %r33,63;
$L1:
.loc 1 780 1
mov.u32 %value,%r33;
st.param.u32 [%value_out],%value;
ret;
}

_clrsbdi2.o/    1608280945  0     0     100666  2131      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __clrsbti2
.visible .func (.param .u32 %value_out) __clrsbti2 (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL FUNCTION DEF: __clrsbti2
.visible .func (.param .u32 %value_out) __clrsbti2 (.param .u64 %in_ar0)
{
.reg .u32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r24;
.reg .u64 %r29;
.reg .u64 %r32;
.reg .u32 %r35;
.reg .u64 %r36;
.reg .u32 %r39;
.reg .u64 %r40;
.reg .pred %r42;
.reg .pred %r43;
.reg .pred %r45;
.reg .pred %r46;
.reg .u32 %r47;
.reg .u64 %r48;
.reg .pred %r49;
.reg .pred %r50;
.reg .u64 %r51;
.reg .u64 %r52;
.reg .u64 %r53;
.reg .u64 %r54;
.reg .u64 %r55;
.reg .u32 %r56;
.reg .u32 %r57;
.reg .u64 %r59;
.reg .u64 %r60;
mov.u64 %r40,%ar0;
ld.u64 %r59,[%r40];
ld.u64 %r60,[%r40+8];
.loc 1 792 6
setp.ne.u64 %r42,%r60,0;
@ %r42 bra $L2;
.loc 1 793 10
mov.u64 %r29,%r59;
bra $L3;
$L2:
.loc 1 794 11
setp.ne.u64 %r43,%r60,-1;
@ %r43 bra $L4;
.loc 1 795 12
not.b64 %r29,%r59;
bra $L3;
$L4:
.loc 1 796 11
setp.lt.s64 %r45,%r60,0;
@ %r45 bra $L5;
.loc 1 797 10
mov.u64 %r29,%r60;
mov.u32 %r35,0;
bra $L6;
$L5:
.loc 1 799 12
not.b64 %r29,%r60;
.loc 1 799 10
mov.u32 %r35,0;
bra $L6;
$L3:
.loc 1 801 6
setp.eq.u64 %r46,%r29,0;
@ %r46 bra $L11;
mov.u32 %r35,64;
$L6:
.loc 1 804 5
mov.u64 %r32,56;
$L9:
cvt.u32.u64 %r47,%r32;
shr.u64 %r24,%r29,%r47;
and.b64 %r48,%r24,255;
setp.ne.u64 %r49,%r48,0;
@ %r49 bra $L8;
add.u64 %r32,%r32,-8;
setp.ne.u64 %r50,%r32,0;
@ %r50 bra $L9;
mov.u64 %r36,64;
bra $L10;
$L8:
mov.u64 %r51,64;
sub.u64 %r36,%r51,%r32;
mov.u64 %r29,%r24;
$L10:
cvta.const.u64 %r52,__clz_tab;
add.u64 %r53,%r52,%r29;
ld.u8 %r54,[%r53];
sub.u64 %r55,%r36,%r54;
.loc 1 806 20
add.u32 %r56,%r35,-1;
cvt.u32.u64 %r57,%r55;
add.u32 %r39,%r56,%r57;
bra $L1;
$L11:
mov.u32 %r39,127;
$L1:
.loc 1 807 1
mov.u32 %value,%r39;
st.param.u32 [%value_out],%value;
ret;
}

_fixunssfsi.o/  1608280945  0     0     100666  941       `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __fixunssfdi
.visible .func (.param .u64 %value_out) __fixunssfdi (.param .f32 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __fixunssfdi
.visible .func (.param .u64 %value_out) __fixunssfdi (.param .f32 %in_ar0)
{
.reg .u64 %value;
.reg .f32 %ar0;
ld.param.f32 %ar0,[%in_ar0];
.reg .u64 %r26;
.reg .f32 %r27;
.reg .pred %r28;
.reg .f32 %r29;
.reg .f32 %r30;
.reg .u64 %r31;
mov.f32 %r27,%ar0;
.loc 1 1847 6
setp.ge.f32 %r28,%r27,0f5f000000;
@ ! %r28 bra $L6;
.loc 1 1848 23
mov.f32 %r30,0f5f000000;
sub.f32 %r29,%r27,%r30;
.loc 1 1848 12
cvt.rzi.s64.f32 %r31,%r29;
.loc 1 1848 36
add.u64 %r26,%r31,-9223372036854775808;
bra $L1;
$L6:
.loc 1 1849 10
cvt.rzi.s64.f32 %r26,%r27;
$L1:
.loc 1 1850 1
mov.u64 %value,%r26;
st.param.u64 [%value_out],%value;
ret;
}

_fixunsdfsi.o/  1608280945  0     0     100666  957       `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __fixunsdfdi
.visible .func (.param .u64 %value_out) __fixunsdfdi (.param .f64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __fixunsdfdi
.visible .func (.param .u64 %value_out) __fixunsdfdi (.param .f64 %in_ar0)
{
.reg .u64 %value;
.reg .f64 %ar0;
ld.param.f64 %ar0,[%in_ar0];
.reg .u64 %r26;
.reg .f64 %r27;
.reg .pred %r28;
.reg .f64 %r29;
.reg .f64 %r30;
.reg .u64 %r31;
mov.f64 %r27,%ar0;
.loc 1 1837 6
setp.ge.f64 %r28,%r27,0d43e0000000000000;
@ ! %r28 bra $L6;
.loc 1 1838 23
mov.f64 %r30,0d43e0000000000000;
sub.f64 %r29,%r27,%r30;
.loc 1 1838 12
cvt.rzi.s64.f64 %r31,%r29;
.loc 1 1838 36
add.u64 %r26,%r31,-9223372036854775808;
bra $L1;
$L6:
.loc 1 1839 10
cvt.rzi.s64.f64 %r26,%r27;
$L1:
.loc 1 1840 1
mov.u64 %value,%r26;
st.param.u64 [%value_out],%value;
ret;
}

_fixunsxfsi.o/  1608280946  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_fixsfdi.o/     1608280946  0     0     100666  2110      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __fixsfti
.visible .func __fixsfti (.param .u64 %in_ar0, .param .f32 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DECL: __fixunssfti
.extern .func __fixunssfti (.param .u64 %in_ar0, .param .f32 %in_ar1);
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __fixsfti
.visible .func __fixsfti (.param .u64 %in_ar0, .param .f32 %in_ar1)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .f32 %ar1;
ld.param.f32 %ar1,[%in_ar1];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,16;
sub.u64 %stack,%frame,0;
st.shared.u64 [%sspslot],%stack;
}
.reg .u64 %r28;
.reg .f32 %r29;
.reg .pred %r30;
.reg .f32 %r33;
.reg .u64 %r36;
.reg .u64 %r39;
.reg .u32 %r41;
.reg .u64 %r45;
.reg .u64 %r52;
.reg .u64 %r53;
.reg .u64 %r54;
.reg .u64 %r55;
mov.u64 %r28,%ar0;
mov.f32 %r29,%ar1;
.loc 1 1531 6
setp.lt.f32 %r30,%r29,0f00000000;
@ ! %r30 bra $L6;
.loc 1 1532 14
neg.f32 %r33,%r29;
{
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%frame;
.param .f32 %out_arg2;
st.param.f32 [%out_arg2],%r33;
call __fixunssfti,(%out_arg1,%out_arg2);
}
ld.u64 %r52,[%frame];
ld.u64 %r53,[%frame+8];
.loc 1 1532 12
neg.s64 %r36,%r52;
set.u32.ne.u64 %r41,%r52,0;
cvt.s64.s32 %r39,%r41;
sub.u64 %r45,%r39,%r53;
st.u64 [%r28],%r36;
st.u64 [%r28+8],%r45;
bra $L1;
$L6:
.loc 1 1533 10
{
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%frame;
.param .f32 %out_arg2;
st.param.f32 [%out_arg2],%r29;
call __fixunssfti,(%out_arg1,%out_arg2);
}
ld.u64 %r54,[%frame];
ld.u64 %r55,[%frame+8];
st.u64 [%r28],%r54;
st.u64 [%r28+8],%r55;
$L1:
.loc 1 1534 1
st.shared.u64 [%sspslot],%sspprev;
ret;
}
_fixdfdi.o/     1608280946  0     0     100666  2118      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __fixdfti
.visible .func __fixdfti (.param .u64 %in_ar0, .param .f64 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DECL: __fixunsdfti
.extern .func __fixunsdfti (.param .u64 %in_ar0, .param .f64 %in_ar1);
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __fixdfti
.visible .func __fixdfti (.param .u64 %in_ar0, .param .f64 %in_ar1)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .f64 %ar1;
ld.param.f64 %ar1,[%in_ar1];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,16;
sub.u64 %stack,%frame,0;
st.shared.u64 [%sspslot],%stack;
}
.reg .u64 %r28;
.reg .f64 %r29;
.reg .pred %r30;
.reg .f64 %r33;
.reg .u64 %r36;
.reg .u64 %r39;
.reg .u32 %r41;
.reg .u64 %r45;
.reg .u64 %r52;
.reg .u64 %r53;
.reg .u64 %r54;
.reg .u64 %r55;
mov.u64 %r28,%ar0;
mov.f64 %r29,%ar1;
.loc 1 1457 6
setp.lt.f64 %r30,%r29,0d0000000000000000;
@ ! %r30 bra $L6;
.loc 1 1458 14
neg.f64 %r33,%r29;
{
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%frame;
.param .f64 %out_arg2;
st.param.f64 [%out_arg2],%r33;
call __fixunsdfti,(%out_arg1,%out_arg2);
}
ld.u64 %r52,[%frame];
ld.u64 %r53,[%frame+8];
.loc 1 1458 12
neg.s64 %r36,%r52;
set.u32.ne.u64 %r41,%r52,0;
cvt.s64.s32 %r39,%r41;
sub.u64 %r45,%r39,%r53;
st.u64 [%r28],%r36;
st.u64 [%r28+8],%r45;
bra $L1;
$L6:
.loc 1 1459 10
{
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%frame;
.param .f64 %out_arg2;
st.param.f64 [%out_arg2],%r29;
call __fixunsdfti,(%out_arg1,%out_arg2);
}
ld.u64 %r54,[%frame];
ld.u64 %r55,[%frame+8];
st.u64 [%r28],%r54;
st.u64 [%r28+8],%r55;
$L1:
.loc 1 1460 1
st.shared.u64 [%sspslot],%sspprev;
ret;
}
_fixxfdi.o/     1608280946  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_fixtfdi.o/     1608280946  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_fixunssfdi.o/  1608280946  0     0     100666  1003      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __fixunssfti
.visible .func __fixunssfti (.param .u64 %in_ar0, .param .f32 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __fixunssfti
.visible .func __fixunssfti (.param .u64 %in_ar0, .param .f32 %in_ar1)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .f32 %ar1;
ld.param.f32 %ar1,[%in_ar1];
.reg .f64 %r24;
.reg .f64 %r29;
.reg .u64 %r30;
.reg .u64 %r33;
.reg .f32 %r34;
.reg .f64 %r35;
.reg .f64 %r36;
.reg .u64 %r42;
mov.u64 %r33,%ar0;
mov.f32 %r34,%ar1;
.loc 1 1471 16
cvt.f64.f32 %r29,%r34;
.loc 1 1476 25
mul.f64 %r35,%r29,0d3bf0000000000000;
.loc 1 1476 16
cvt.rzi.u64.f64 %r30,%r35;
.loc 1 1481 27
cvt.rn.f64.u64 %r36,%r30;
.loc 1 1481 25
fma.rn.f64 %r24,%r36,0dc3f0000000000000,%r29;
.loc 1 1481 16
cvt.rzi.u64.f64 %r42,%r24;
.loc 1 1484 40
st.u64 [%r33],%r42;
st.u64 [%r33+8],%r30;
.loc 1 1524 1
ret;
}

_fixunsdfdi.o/  1608280947  0     0     100666  946       `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __fixunsdfti
.visible .func __fixunsdfti (.param .u64 %in_ar0, .param .f64 %in_ar1);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __fixunsdfti
.visible .func __fixunsdfti (.param .u64 %in_ar0, .param .f64 %in_ar1)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .f64 %ar1;
ld.param.f64 %ar1,[%in_ar1];
.reg .f64 %r24;
.reg .u64 %r29;
.reg .u64 %r32;
.reg .f64 %r33;
.reg .f64 %r34;
.reg .f64 %r35;
.reg .u64 %r41;
mov.u64 %r32,%ar0;
mov.f64 %r33,%ar1;
.loc 1 1441 23
mul.f64 %r34,%r33,0d3bf0000000000000;
.loc 1 1441 16
cvt.rzi.u64.f64 %r29,%r34;
.loc 1 1446 25
cvt.rn.f64.u64 %r35,%r29;
.loc 1 1446 23
fma.rn.f64 %r24,%r35,0dc3f0000000000000,%r33;
.loc 1 1446 16
cvt.rzi.u64.f64 %r41,%r24;
.loc 1 1449 40
st.u64 [%r32],%r41;
st.u64 [%r32+8],%r29;
.loc 1 1450 1
ret;
}
_fixunsxfdi.o/  1608280947  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_fixunstfdi.o/  1608280947  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_floatdisf.o/   1608280947  0     0     100666  3552      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __floattisf
.visible .func (.param .f32 %value_out) __floattisf (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL FUNCTION DEF: __floattisf
.visible .func (.param .f32 %value_out) __floattisf (.param .u64 %in_ar0)
{
.reg .f32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r26;
.reg .u64 %r30;
.reg .u32 %r35;
.reg .u64 %r40;
.reg .u64 %r41;
.reg .f32 %r42;
.reg .u64 %r43;
.reg .u64 %r44;
.reg .f32 %r45;
.reg .u64 %r47;
.reg .f32 %r49;
.reg .u64 %r50;
.reg .u64 %r53;
.reg .pred %r59;
.reg .pred %r64;
.reg .u32 %r66;
.reg .u64 %r67;
.reg .pred %r68;
.reg .pred %r69;
.reg .u64 %r70;
.reg .u64 %r71;
.reg .u64 %r72;
.reg .pred %r73;
.reg .u64 %r74;
.reg .u32 %r75;
.reg .u64 %r76;
.reg .u64 %r77;
.reg .f32 %r78;
.reg .u32 %r80;
.reg .pred %r95;
.reg .u64 %r100;
.reg .u32 %r102;
.reg .u32 %r103;
.reg .u64 %r104;
.reg .u64 %r105;
.reg .u32 %r110;
.reg .u32 %r111;
.reg .u64 %r112;
.reg .pred %r113;
.reg .pred %r114;
.reg .pred %r115;
.reg .u64 %r116;
.reg .u64 %r117;
.reg .u64 %r121;
.reg .u64 %r122;
.reg .u64 %r125;
mov.u64 %r50,%ar0;
ld.u64 %r121,[%r50];
ld.u64 %r122,[%r50+8];
.loc 1 1669 7
shr.s64 %r53,%r121,63;
.loc 1 1669 6
setp.ne.u64 %r59,%r53,%r122;
@ %r59 bra $L2;
.loc 1 1670 12
cvt.rn.f32.s64 %r49,%r121;
bra $L1;
$L2:
.loc 1 1673 9
mov.u64 %r40,%r122;
.loc 1 1674 6
setp.lt.s64 %r64,%r122,0;
@ %r64 bra $L4;
.loc 1 1683 3
mov.u64 %r47,%r122;
bra $L5;
$L4:
.loc 1 1675 10
neg.s64 %r47,%r122;
.loc 1 1675 8
mov.u64 %r40,%r47;
$L5:
.loc 1 1683 3
mov.u64 %r43,56;
$L7:
cvt.u32.u64 %r66,%r43;
shr.u64 %r26,%r47,%r66;
and.b64 %r67,%r26,255;
setp.ne.u64 %r68,%r67,0;
@ %r68 bra $L13;
add.u64 %r43,%r43,-8;
setp.ne.u64 %r69,%r43,0;
@ %r69 bra $L7;
bra $L6;
$L13:
mov.u64 %r47,%r26;
$L6:
cvta.const.u64 %r70,__clz_tab;
add.u64 %r71,%r70,%r47;
ld.u8 %r72,[%r71];
add.u64 %r30,%r72,%r43;
.loc 1 1686 6
setp.ne.u64 %r73,%r30,64;
@ %r73 bra $L8;
.loc 1 1687 55
set.u32.ne.u64 %r75,%r121,0;
cvt.s64.s32 %r74,%r75;
neg.s64 %r76,%r74;
.loc 1 1687 41
or.b64 %r77,%r76,%r40;
.loc 1 1687 28
cvt.rn.f32.s64 %r78,%r77;
.loc 1 1687 26
mul.f32 %r49,%r78,0f5f800000;
bra $L1;
$L8:
.loc 1 1689 9
add.u64 %r44,%r30,1;
.loc 1 1692 10
cvt.u32.u64 %r35,%r44;
add.u32 %r80,%r35,-64;
setp.lt.s32 %r95,%r80,0;
@ %r95 bra $L9;
shr.s64 %r125,%r122,%r80;
bra $L10;
$L9:
shl.b64 %r100,%r122,1;
mov.u32 %r103,63;
sub.u32 %r102,%r103,%r35;
shl.b64 %r104,%r100,%r102;
shr.u64 %r105,%r121,%r35;
or.b64 %r125,%r105,%r104;
$L10:
.loc 1 1692 6
mov.u64 %r41,%r125;
.loc 1 1695 33
mov.u32 %r111,64;
sub.u32 %r110,%r111,%r35;
.loc 1 1695 17
shl.b64 %r112,%r121,%r110;
.loc 1 1695 6
setp.eq.u64 %r113,%r112,0;
@ %r113 bra $L11;
.loc 1 1696 8
or.b64 %r41,%r41,1;
$L11:
.loc 1 1699 10
cvt.rn.f32.s64 %r45,%r41;
.loc 1 1700 6
setp.eq.u64 %r114,%r44,64;
@ %r114 bra $L14;
.loc 1 1705 11
setp.eq.u64 %r115,%r44,63;
@ %r115 bra $L15;
.loc 1 1708 18
mov.u64 %r117,1;
shl.b64 %r116,%r117,%r35;
.loc 1 1708 7
cvt.rn.f32.s64 %r42,%r116;
bra $L12;
$L14:
.loc 1 1701 7
mov.f32 %r42,0f5f800000;
bra $L12;
$L15:
.loc 1 1706 7
mov.f32 %r42,0f5f000000;
$L12:
.loc 1 1709 12
mul.f32 %r49,%r42,%r45;
$L1:
.loc 1 1711 1
mov.f32 %value,%r49;
st.param.f32 [%value_out],%value;
ret;
}
_floatdidf.o/   1608280947  0     0     100666  3576      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __floattidf
.visible .func (.param .f64 %value_out) __floattidf (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL FUNCTION DEF: __floattidf
.visible .func (.param .f64 %value_out) __floattidf (.param .u64 %in_ar0)
{
.reg .f64 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r26;
.reg .u64 %r30;
.reg .u32 %r35;
.reg .u64 %r40;
.reg .u64 %r41;
.reg .f64 %r42;
.reg .u64 %r43;
.reg .u64 %r44;
.reg .f64 %r45;
.reg .u64 %r47;
.reg .f64 %r49;
.reg .u64 %r50;
.reg .u64 %r53;
.reg .pred %r59;
.reg .pred %r64;
.reg .u32 %r66;
.reg .u64 %r67;
.reg .pred %r68;
.reg .pred %r69;
.reg .u64 %r70;
.reg .u64 %r71;
.reg .u64 %r72;
.reg .pred %r73;
.reg .u64 %r74;
.reg .u32 %r75;
.reg .u64 %r76;
.reg .u64 %r77;
.reg .f64 %r78;
.reg .u32 %r80;
.reg .pred %r95;
.reg .u64 %r100;
.reg .u32 %r102;
.reg .u32 %r103;
.reg .u64 %r104;
.reg .u64 %r105;
.reg .u32 %r110;
.reg .u32 %r111;
.reg .u64 %r112;
.reg .pred %r113;
.reg .pred %r114;
.reg .pred %r115;
.reg .u64 %r116;
.reg .u64 %r117;
.reg .u64 %r121;
.reg .u64 %r122;
.reg .u64 %r125;
mov.u64 %r50,%ar0;
ld.u64 %r121,[%r50];
ld.u64 %r122,[%r50+8];
.loc 1 1669 7
shr.s64 %r53,%r121,63;
.loc 1 1669 6
setp.ne.u64 %r59,%r53,%r122;
@ %r59 bra $L2;
.loc 1 1670 12
cvt.rn.f64.s64 %r49,%r121;
bra $L1;
$L2:
.loc 1 1673 9
mov.u64 %r40,%r122;
.loc 1 1674 6
setp.lt.s64 %r64,%r122,0;
@ %r64 bra $L4;
.loc 1 1683 3
mov.u64 %r47,%r122;
bra $L5;
$L4:
.loc 1 1675 10
neg.s64 %r47,%r122;
.loc 1 1675 8
mov.u64 %r40,%r47;
$L5:
.loc 1 1683 3
mov.u64 %r43,56;
$L7:
cvt.u32.u64 %r66,%r43;
shr.u64 %r26,%r47,%r66;
and.b64 %r67,%r26,255;
setp.ne.u64 %r68,%r67,0;
@ %r68 bra $L13;
add.u64 %r43,%r43,-8;
setp.ne.u64 %r69,%r43,0;
@ %r69 bra $L7;
bra $L6;
$L13:
mov.u64 %r47,%r26;
$L6:
cvta.const.u64 %r70,__clz_tab;
add.u64 %r71,%r70,%r47;
ld.u8 %r72,[%r71];
add.u64 %r30,%r72,%r43;
.loc 1 1686 6
setp.ne.u64 %r73,%r30,64;
@ %r73 bra $L8;
.loc 1 1687 55
set.u32.ne.u64 %r75,%r121,0;
cvt.s64.s32 %r74,%r75;
neg.s64 %r76,%r74;
.loc 1 1687 41
or.b64 %r77,%r76,%r40;
.loc 1 1687 28
cvt.rn.f64.s64 %r78,%r77;
.loc 1 1687 26
mul.f64 %r49,%r78,0d43f0000000000000;
bra $L1;
$L8:
.loc 1 1689 9
add.u64 %r44,%r30,1;
.loc 1 1692 10
cvt.u32.u64 %r35,%r44;
add.u32 %r80,%r35,-64;
setp.lt.s32 %r95,%r80,0;
@ %r95 bra $L9;
shr.s64 %r125,%r122,%r80;
bra $L10;
$L9:
shl.b64 %r100,%r122,1;
mov.u32 %r103,63;
sub.u32 %r102,%r103,%r35;
shl.b64 %r104,%r100,%r102;
shr.u64 %r105,%r121,%r35;
or.b64 %r125,%r105,%r104;
$L10:
.loc 1 1692 6
mov.u64 %r41,%r125;
.loc 1 1695 33
mov.u32 %r111,64;
sub.u32 %r110,%r111,%r35;
.loc 1 1695 17
shl.b64 %r112,%r121,%r110;
.loc 1 1695 6
setp.eq.u64 %r113,%r112,0;
@ %r113 bra $L11;
.loc 1 1696 8
or.b64 %r41,%r41,1;
$L11:
.loc 1 1699 10
cvt.rn.f64.s64 %r45,%r41;
.loc 1 1700 6
setp.eq.u64 %r114,%r44,64;
@ %r114 bra $L14;
.loc 1 1705 11
setp.eq.u64 %r115,%r44,63;
@ %r115 bra $L15;
.loc 1 1708 18
mov.u64 %r117,1;
shl.b64 %r116,%r117,%r35;
.loc 1 1708 7
cvt.rn.f64.s64 %r42,%r116;
bra $L12;
$L14:
.loc 1 1701 7
mov.f64 %r42,0d43f0000000000000;
bra $L12;
$L15:
.loc 1 1706 7
mov.f64 %r42,0d43e0000000000000;
$L12:
.loc 1 1709 12
mul.f64 %r49,%r42,%r45;
$L1:
.loc 1 1711 1
mov.f64 %value,%r49;
st.param.f64 [%value_out],%value;
ret;
}
_floatdixf.o/   1608280947  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_floatditf.o/   1608280947  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_floatundisf.o/ 1608280947  0     0     100666  2784      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __floatuntisf
.visible .func (.param .f32 %value_out) __floatuntisf (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL FUNCTION DEF: __floatuntisf
.visible .func (.param .f32 %value_out) __floatuntisf (.param .u64 %in_ar0)
{
.reg .f32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r24;
.reg .u64 %r28;
.reg .u32 %r29;
.reg .u64 %r34;
.reg .f32 %r35;
.reg .u64 %r36;
.reg .u64 %r38;
.reg .f32 %r39;
.reg .f32 %r41;
.reg .u64 %r42;
.reg .pred %r54;
.reg .u32 %r58;
.reg .u64 %r59;
.reg .pred %r60;
.reg .pred %r61;
.reg .u64 %r62;
.reg .u64 %r63;
.reg .u64 %r64;
.reg .u32 %r66;
.reg .pred %r80;
.reg .u64 %r83;
.reg .u32 %r85;
.reg .u32 %r86;
.reg .u64 %r87;
.reg .u64 %r88;
.reg .u32 %r93;
.reg .u32 %r94;
.reg .u64 %r95;
.reg .pred %r96;
.reg .pred %r97;
.reg .pred %r98;
.reg .u64 %r99;
.reg .u64 %r100;
.reg .u64 %r102;
.reg .u64 %r103;
.reg .u64 %r108;
mov.u64 %r42,%ar0;
ld.u64 %r102,[%r42];
ld.u64 %r103,[%r42+8];
.loc 1 1789 6
setp.ne.u64 %r54,%r103,0;
@ %r54 bra $L2;
.loc 1 1790 12
cvt.rn.f32.u64 %r41,%r102;
bra $L1;
$L2:
.loc 1 1793 10
mov.u64 %r36,%r103;
.loc 1 1796 3
mov.u64 %r38,56;
$L5:
cvt.u32.u64 %r58,%r38;
shr.u64 %r24,%r103,%r58;
and.b64 %r59,%r24,255;
setp.ne.u64 %r60,%r59,0;
@ %r60 bra $L10;
add.u64 %r38,%r38,-8;
setp.ne.u64 %r61,%r38,0;
@ %r61 bra $L5;
bra $L4;
$L10:
mov.u64 %r36,%r24;
$L4:
cvta.const.u64 %r62,__clz_tab;
add.u64 %r63,%r62,%r36;
ld.u8 %r64,[%r63];
add.u64 %r28,%r64,%r38;
.loc 1 1801 10
cvt.u32.u64 %r29,%r28;
add.u32 %r66,%r29,-64;
setp.lt.s32 %r80,%r66,0;
@ %r80 bra $L6;
shr.u64 %r108,%r103,%r66;
bra $L7;
$L6:
shl.b64 %r83,%r103,1;
mov.u32 %r86,63;
sub.u32 %r85,%r86,%r29;
shl.b64 %r87,%r83,%r85;
shr.u64 %r88,%r102,%r29;
or.b64 %r108,%r88,%r87;
$L7:
.loc 1 1801 6
mov.u64 %r34,%r108;
.loc 1 1804 33
mov.u32 %r94,64;
sub.u32 %r93,%r94,%r29;
.loc 1 1804 17
shl.b64 %r95,%r102,%r93;
.loc 1 1804 6
setp.eq.u64 %r96,%r95,0;
@ %r96 bra $L8;
.loc 1 1805 8
or.b64 %r34,%r34,1;
$L8:
.loc 1 1808 10
cvt.rn.f32.u64 %r39,%r34;
.loc 1 1809 6
setp.eq.u64 %r97,%r28,64;
@ %r97 bra $L11;
.loc 1 1814 11
setp.eq.u64 %r98,%r28,63;
@ %r98 bra $L12;
.loc 1 1817 18
mov.u64 %r100,1;
shl.b64 %r99,%r100,%r29;
.loc 1 1817 7
cvt.rn.f32.s64 %r35,%r99;
bra $L9;
$L11:
.loc 1 1810 7
mov.f32 %r35,0f5f800000;
bra $L9;
$L12:
.loc 1 1815 7
mov.f32 %r35,0f5f000000;
$L9:
.loc 1 1818 12
mul.f32 %r41,%r35,%r39;
$L1:
.loc 1 1820 1
mov.f32 %value,%r41;
st.param.f32 [%value_out],%value;
ret;
}
_floatundidf.o/ 1608280948  0     0     100666  2800      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __floatuntidf
.visible .func (.param .f64 %value_out) __floatuntidf (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL FUNCTION DEF: __floatuntidf
.visible .func (.param .f64 %value_out) __floatuntidf (.param .u64 %in_ar0)
{
.reg .f64 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r24;
.reg .u64 %r28;
.reg .u32 %r29;
.reg .u64 %r34;
.reg .f64 %r35;
.reg .u64 %r36;
.reg .u64 %r38;
.reg .f64 %r39;
.reg .f64 %r41;
.reg .u64 %r42;
.reg .pred %r54;
.reg .u32 %r58;
.reg .u64 %r59;
.reg .pred %r60;
.reg .pred %r61;
.reg .u64 %r62;
.reg .u64 %r63;
.reg .u64 %r64;
.reg .u32 %r66;
.reg .pred %r80;
.reg .u64 %r83;
.reg .u32 %r85;
.reg .u32 %r86;
.reg .u64 %r87;
.reg .u64 %r88;
.reg .u32 %r93;
.reg .u32 %r94;
.reg .u64 %r95;
.reg .pred %r96;
.reg .pred %r97;
.reg .pred %r98;
.reg .u64 %r99;
.reg .u64 %r100;
.reg .u64 %r102;
.reg .u64 %r103;
.reg .u64 %r108;
mov.u64 %r42,%ar0;
ld.u64 %r102,[%r42];
ld.u64 %r103,[%r42+8];
.loc 1 1789 6
setp.ne.u64 %r54,%r103,0;
@ %r54 bra $L2;
.loc 1 1790 12
cvt.rn.f64.u64 %r41,%r102;
bra $L1;
$L2:
.loc 1 1793 10
mov.u64 %r36,%r103;
.loc 1 1796 3
mov.u64 %r38,56;
$L5:
cvt.u32.u64 %r58,%r38;
shr.u64 %r24,%r103,%r58;
and.b64 %r59,%r24,255;
setp.ne.u64 %r60,%r59,0;
@ %r60 bra $L10;
add.u64 %r38,%r38,-8;
setp.ne.u64 %r61,%r38,0;
@ %r61 bra $L5;
bra $L4;
$L10:
mov.u64 %r36,%r24;
$L4:
cvta.const.u64 %r62,__clz_tab;
add.u64 %r63,%r62,%r36;
ld.u8 %r64,[%r63];
add.u64 %r28,%r64,%r38;
.loc 1 1801 10
cvt.u32.u64 %r29,%r28;
add.u32 %r66,%r29,-64;
setp.lt.s32 %r80,%r66,0;
@ %r80 bra $L6;
shr.u64 %r108,%r103,%r66;
bra $L7;
$L6:
shl.b64 %r83,%r103,1;
mov.u32 %r86,63;
sub.u32 %r85,%r86,%r29;
shl.b64 %r87,%r83,%r85;
shr.u64 %r88,%r102,%r29;
or.b64 %r108,%r88,%r87;
$L7:
.loc 1 1801 6
mov.u64 %r34,%r108;
.loc 1 1804 33
mov.u32 %r94,64;
sub.u32 %r93,%r94,%r29;
.loc 1 1804 17
shl.b64 %r95,%r102,%r93;
.loc 1 1804 6
setp.eq.u64 %r96,%r95,0;
@ %r96 bra $L8;
.loc 1 1805 8
or.b64 %r34,%r34,1;
$L8:
.loc 1 1808 10
cvt.rn.f64.u64 %r39,%r34;
.loc 1 1809 6
setp.eq.u64 %r97,%r28,64;
@ %r97 bra $L11;
.loc 1 1814 11
setp.eq.u64 %r98,%r28,63;
@ %r98 bra $L12;
.loc 1 1817 18
mov.u64 %r100,1;
shl.b64 %r99,%r100,%r29;
.loc 1 1817 7
cvt.rn.f64.s64 %r35,%r99;
bra $L9;
$L11:
.loc 1 1810 7
mov.f64 %r35,0d43f0000000000000;
bra $L9;
$L12:
.loc 1 1815 7
mov.f64 %r35,0d43e0000000000000;
$L9:
.loc 1 1818 12
mul.f64 %r41,%r35,%r39;
$L1:
.loc 1 1820 1
mov.f64 %value,%r41;
st.param.f64 [%value_out],%value;
ret;
}
_floatundixf.o/ 1608280948  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_floatunditf.o/ 1608280948  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

_eprintf.o/     1608280948  0     0     100666  83        `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE

__gcc_bcmp.o/   1608280948  0     0     100666  1538      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __gcc_bcmp
.visible .func (.param .u32 %value_out) __gcc_bcmp (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __gcc_bcmp
.visible .func (.param .u32 %value_out) __gcc_bcmp (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2)
{
.reg .u32 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %r22;
.reg .u64 %r25;
.reg .u32 %r26;
.reg .u32 %r27;
.reg .u64 %r30;
.reg .u32 %r31;
.reg .u64 %r32;
.reg .u64 %r33;
.reg .u64 %r34;
.reg .pred %r35;
.reg .u16 %r36;
.reg .u16 %r37;
.reg .pred %r38;
.reg .pred %r39;
mov.u64 %r32,%ar0;
mov.u64 %r33,%ar1;
mov.u64 %r34,%ar2;
.loc 1 2126 9
setp.eq.u64 %r35,%r34,0;
@ %r35 bra $L5;
mov.u64 %r25,%r33;
mov.u64 %r22,%r32;
add.u64 %r30,%r25,%r34;
$L4:
.loc 1 2128 27
ld.u8 %r26,[%r22];
.loc 1 2128 39
ld.u8 %r27,[%r25];
.loc 1 2129 10
cvt.u16.u32 %r36,%r26;
cvt.u16.u32 %r37,%r27;
setp.eq.u16 %r38,%r36,%r37;
@ %r38 bra $L3;
.loc 1 2130 12
sub.u32 %r31,%r26,%r27;
bra $L1;
$L3:
.loc 1 2126 9
add.u64 %r25,%r25,1;
add.u64 %r22,%r22,1;
setp.ne.u64 %r39,%r25,%r30;
@ %r39 bra $L4;
.loc 1 2133 10
mov.u32 %r31,0;
bra $L1;
$L5:
cvt.u32.u64 %r31,%r34;
$L1:
.loc 1 2134 1
mov.u32 %value,%r31;
st.param.u32 [%value_out],%value;
ret;
}
_divdi3.o/      1608280949  0     0     100666  17693     `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __divti3
.visible .func __divti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __divti3
.visible .func __divti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,16;
sub.u64 %stack,%frame,0;
}
.reg .u64 %r22;
.reg .u64 %r24;
.reg .u64 %r25;
.reg .u64 %r27;
.reg .u64 %r28;
.reg .u64 %r30;
.reg .u64 %r32;
.reg .u64 %r33;
.reg .u64 %r36;
.reg .u32 %r37;
.reg .u64 %r38;
.reg .u64 %r41;
.reg .u64 %r42;
.reg .u64 %r43;
.reg .u64 %r44;
.reg .u64 %r45;
.reg .u64 %r48;
.reg .u64 %r49;
.reg .u64 %r50;
.reg .u64 %r51;
.reg .u64 %r52;
.reg .u64 %r53;
.reg .u64 %r56;
.reg .u64 %r57;
.reg .u64 %r58;
.reg .u64 %r62;
.reg .u64 %r64;
.reg .u64 %r67;
.reg .u64 %r68;
.reg .u64 %r69;
.reg .u32 %r70;
.reg .u32 %r71;
.reg .u64 %r72;
.reg .u64 %r73;
.reg .u64 %r75;
.reg .u64 %r76;
.reg .u64 %r77;
.reg .u64 %r78;
.reg .u64 %r81;
.reg .u64 %r82;
.reg .u64 %r83;
.reg .u64 %r84;
.reg .u64 %r85;
.reg .u64 %r86;
.reg .u64 %r89;
.reg .u64 %r90;
.reg .u64 %r93;
.reg .u64 %r94;
.reg .u64 %r95;
.reg .u64 %r98;
.reg .u64 %r99;
.reg .u64 %r100;
.reg .u64 %r101;
.reg .u64 %r102;
.reg .u64 %r103;
.reg .u64 %r106;
.reg .u64 %r107;
.reg .u64 %r108;
.reg .u64 %r112;
.reg .u64 %r114;
.reg .u64 %r117;
.reg .u64 %r118;
.reg .u32 %r122;
.reg .u64 %r123;
.reg .u32 %r124;
.reg .u64 %r126;
.reg .u64 %r127;
.reg .u64 %r128;
.reg .u64 %r129;
.reg .u64 %r131;
.reg .u64 %r133;
.reg .u64 %r134;
.reg .u64 %r135;
.reg .u64 %r136;
.reg .u64 %r137;
.reg .u64 %r140;
.reg .u64 %r141;
.reg .u64 %r142;
.reg .u64 %r143;
.reg .u64 %r144;
.reg .u64 %r145;
.reg .u64 %r148;
.reg .u64 %r149;
.reg .u64 %r150;
.reg .u64 %r152;
.reg .u64 %r153;
.reg .u64 %r154;
.reg .u64 %r155;
.reg .u64 %r156;
.reg .u64 %r157;
.reg .u64 %r159;
.reg .u64 %r160;
.reg .u64 %r162;
.reg .u64 %r164;
.reg .u64 %r173;
.reg .u64 %r174;
.reg .u64 %r175;
.reg .u64 %r176;
.reg .u64 %r177;
.reg .u64 %r182;
.reg .u64 %r203;
.reg .u64 %r204;
.reg .u64 %r206;
.reg .pred %r208;
.reg .u64 %r214;
.reg .u32 %r216;
.reg .pred %r221;
.reg .u64 %r227;
.reg .u32 %r229;
.reg .pred %r234;
.reg .pred %r235;
.reg .u32 %r236;
.reg .u64 %r237;
.reg .pred %r238;
.reg .pred %r239;
.reg .u64 %r240;
.reg .u64 %r241;
.reg .u64 %r242;
.reg .u64 %r243;
.reg .pred %r245;
.reg .u32 %r246;
.reg .u32 %r247;
.reg .u64 %r248;
.reg .u64 %r249;
.reg .u64 %r250;
.reg .pred %r251;
.reg .u32 %r253;
.reg .u32 %r254;
.reg .u32 %r256;
.reg .u32 %r257;
.reg .u16 %r258;
.reg .u16 %r259;
.reg .u16 %r260;
.reg .u32 %r261;
.reg .u16 %r262;
.reg .pred %r263;
.reg .u64 %r264;
.reg .u64 %r265;
.reg .pred %r266;
.reg .u32 %r268;
.reg .u32 %r269;
.reg .u32 %r271;
.reg .u32 %r272;
.reg .u16 %r273;
.reg .u16 %r274;
.reg .u16 %r275;
.reg .u32 %r276;
.reg .u16 %r277;
.reg .pred %r278;
.reg .u64 %r279;
.reg .pred %r280;
.reg .u64 %r281;
.reg .u32 %r283;
.reg .u64 %r284;
.reg .pred %r285;
.reg .pred %r286;
.reg .u64 %r287;
.reg .u64 %r288;
.reg .u64 %r289;
.reg .u64 %r291;
.reg .pred %r292;
.reg .u64 %r293;
.reg .u64 %r294;
.reg .u64 %r295;
.reg .pred %r296;
.reg .u32 %r298;
.reg .u32 %r299;
.reg .u32 %r301;
.reg .u32 %r302;
.reg .u16 %r303;
.reg .u16 %r304;
.reg .u16 %r305;
.reg .u32 %r306;
.reg .u16 %r307;
.reg .pred %r308;
.reg .u64 %r309;
.reg .u64 %r310;
.reg .pred %r311;
.reg .u32 %r313;
.reg .u32 %r314;
.reg .u32 %r316;
.reg .u32 %r317;
.reg .u16 %r318;
.reg .u16 %r319;
.reg .u16 %r320;
.reg .u32 %r321;
.reg .u16 %r322;
.reg .pred %r323;
.reg .u64 %r324;
.reg .u64 %r325;
.reg .u64 %r326;
.reg .pred %r327;
.reg .u32 %r329;
.reg .u32 %r330;
.reg .u32 %r332;
.reg .u32 %r333;
.reg .u16 %r334;
.reg .u16 %r335;
.reg .u16 %r336;
.reg .u32 %r337;
.reg .u16 %r338;
.reg .pred %r339;
.reg .u64 %r340;
.reg .u64 %r341;
.reg .pred %r342;
.reg .u32 %r344;
.reg .u32 %r345;
.reg .u32 %r347;
.reg .u32 %r348;
.reg .u16 %r349;
.reg .u16 %r350;
.reg .u16 %r351;
.reg .u32 %r352;
.reg .u16 %r353;
.reg .pred %r354;
.reg .u64 %r355;
.reg .pred %r356;
.reg .u32 %r357;
.reg .u64 %r358;
.reg .pred %r359;
.reg .pred %r360;
.reg .u64 %r361;
.reg .u64 %r362;
.reg .u64 %r363;
.reg .u64 %r365;
.reg .pred %r366;
.reg .u32 %r368;
.reg .u32 %r369;
.reg .u32 %r371;
.reg .u32 %r372;
.reg .u16 %r373;
.reg .u16 %r374;
.reg .u16 %r375;
.reg .u32 %r376;
.reg .u64 %r377;
.reg .u64 %r378;
.reg .u64 %r379;
.reg .u64 %r380;
.reg .pred %r381;
.reg .u32 %r383;
.reg .u32 %r384;
.reg .u32 %r386;
.reg .u32 %r387;
.reg .u16 %r388;
.reg .u16 %r389;
.reg .u16 %r390;
.reg .u32 %r391;
.reg .u16 %r392;
.reg .pred %r393;
.reg .u64 %r394;
.reg .u64 %r395;
.reg .pred %r396;
.reg .u32 %r398;
.reg .u32 %r399;
.reg .u32 %r401;
.reg .u32 %r402;
.reg .u16 %r403;
.reg .u16 %r404;
.reg .u16 %r405;
.reg .u32 %r406;
.reg .u16 %r407;
.reg .pred %r408;
.reg .u64 %r409;
.reg .u64 %r411;
.reg .pred %r412;
.reg .u64 %r413;
.reg .pred %r414;
.reg .u64 %r415;
.reg .u64 %r417;
.reg .u64 %r418;
.reg .u64 %r419;
.reg .u32 %r421;
.reg .u32 %r422;
.reg .u32 %r424;
.reg .u32 %r425;
.reg .u16 %r426;
.reg .u16 %r427;
.reg .u16 %r428;
.reg .u32 %r429;
.reg .u16 %r430;
.reg .pred %r431;
.reg .pred %r432;
.reg .u64 %r438;
.reg .u32 %r440;
.reg .u64 %r447;
.reg .u64 %r448;
.reg .u64 %r449;
.reg .u64 %r451;
.reg .u64 %r452;
mov.u64 %r203,%ar0;
mov.u64 %r204,%ar1;
ld.u64 %r449,[%r204];
mov.u64 %r206,%ar2;
ld.u64 %r451,[%r206];
ld.u64 %r452,[%r206+8];
ld.u64 %r33,[%r204+8];
.loc 1 1238 6
setp.ge.s64 %r208,%r33,0;
@ %r208 bra $L30;
.loc 1 1240 13
set.u32.ne.u64 %r216,%r449,0;
cvt.s64.s32 %r214,%r216;
neg.s64 %r449,%r449;
sub.u64 %r33,%r214,%r33;
.loc 1 1239 7
mov.u64 %r22,-1;
bra $L2;
$L30:
.loc 1 1233 9
mov.u64 %r22,0;
$L2:
mov.u64 %r24,%r452;
.loc 1 1241 6
setp.ge.s64 %r221,%r24,0;
@ %r221 bra $L3;
.loc 1 1242 7
not.b64 %r22,%r22;
.loc 1 1243 13
set.u32.ne.u64 %r229,%r451,0;
cvt.s64.s32 %r227,%r229;
neg.s64 %r451,%r451;
sub.u64 %r24,%r227,%r24;
$L3:
.loc 1 1024 6
mov.u64 %r25,%r451;
.loc 1 1026 6
mov.u64 %r27,%r449;
.loc 1 1027 6
mov.u64 %r28,%r33;
.loc 1 1064 6
setp.ne.u64 %r234,%r24,0;
@ %r234 bra $L4;
.loc 1 1066 10
setp.le.u64 %r235,%r451,%r33;
@ %r235 bra $L5;
.loc 1 1070 4
mov.u64 %r32,56;
$L7:
cvt.u32.u64 %r236,%r32;
shr.u64 %r30,%r451,%r236;
and.b64 %r237,%r30,255;
setp.ne.u64 %r238,%r237,0;
@ %r238 bra $L6;
add.u64 %r32,%r32,-8;
setp.ne.u64 %r239,%r32,0;
@ %r239 bra $L7;
mov.u64 %r30,%r451;
mov.u64 %r176,64;
bra $L8;
$L6:
mov.u64 %r240,64;
sub.u64 %r176,%r240,%r32;
$L8:
cvta.const.u64 %r241,__clz_tab;
add.u64 %r242,%r241,%r30;
ld.u8 %r243,[%r242];
sub.u64 %r36,%r176,%r243;
.loc 1 1072 7
setp.eq.u64 %r245,%r176,%r243;
@ %r245 bra $L9;
.loc 1 1077 16
cvt.u32.u64 %r37,%r36;
.loc 1 1077 11
shl.b64 %r25,%r451,%r37;
.loc 1 1078 17
shl.b64 %r38,%r33,%r37;
.loc 1 1078 46
mov.u32 %r247,64;
sub.u32 %r246,%r247,%r37;
.loc 1 1078 30
shr.u64 %r248,%r449,%r246;
.loc 1 1078 11
or.b64 %r28,%r248,%r38;
.loc 1 1079 11
shl.b64 %r27,%r449,%r37;
$L9:
.loc 1 1082 4
shr.u64 %r41,%r25,32;
and.b64 %r42,%r25,4294967295;
rem.u64 %r43,%r28,%r41;
div.u64 %r44,%r28,%r41;
mul.lo.u64 %r45,%r42,%r44;
shl.b64 %r249,%r43,32;
shr.u64 %r250,%r27,32;
or.b64 %r48,%r249,%r250;
setp.le.u64 %r251,%r45,%r48;
@ %r251 bra $L10;
add.u64 %r49,%r44,-1;
add.u64 %r48,%r48,%r25;
set.u32.le.u64 %r253,%r25,%r48;
neg.s32 %r254,%r253;
set.u32.gt.u64 %r256,%r45,%r48;
neg.s32 %r257,%r256;
cvt.u16.u32 %r259,%r254;
cvt.u16.u32 %r260,%r257;
and.b16 %r258,%r259,%r260;
cvt.u32.u16 %r261,%r258;
cvt.u16.u8 %r262,%r261;
setp.eq.u16 %r263,%r262,0;
@ %r263 bra $L31;
add.u64 %r44,%r44,-2;
add.u64 %r48,%r48,%r25;
bra $L10;
$L31:
mov.u64 %r44,%r49;
$L10:
sub.u64 %r50,%r48,%r45;
rem.u64 %r51,%r50,%r41;
div.u64 %r52,%r50,%r41;
mul.lo.u64 %r53,%r42,%r52;
shl.b64 %r264,%r51,32;
and.b64 %r265,%r27,4294967295;
or.b64 %r56,%r264,%r265;
setp.le.u64 %r266,%r53,%r56;
@ %r266 bra $L11;
add.u64 %r57,%r52,-1;
add.u64 %r58,%r25,%r56;
set.u32.gt.u64 %r268,%r53,%r58;
neg.s32 %r269,%r268;
set.u32.le.u64 %r271,%r25,%r58;
neg.s32 %r272,%r271;
cvt.u16.u32 %r274,%r269;
cvt.u16.u32 %r275,%r272;
and.b16 %r273,%r274,%r275;
cvt.u32.u16 %r276,%r273;
cvt.u16.u8 %r277,%r276;
setp.eq.u16 %r278,%r277,0;
@ %r278 bra $L32;
add.u64 %r52,%r52,-2;
bra $L11;
$L32:
mov.u64 %r52,%r57;
$L11:
shl.b64 %r279,%r44,32;
or.b64 %r173,%r279,%r52;
mov.u64 %r175,0;
bra $L12;
$L5:
.loc 1 1091 7
setp.ne.u64 %r280,%r25,0;
@ %r280 bra $L13;
.loc 1 1092 9
mov.u64 %r281,1;
div.u64 %r25,%r281,0;
$L13:
.loc 1 1094 4
mov.u64 %r64,56;
$L15:
cvt.u32.u64 %r283,%r64;
shr.u64 %r62,%r25,%r283;
and.b64 %r284,%r62,255;
setp.ne.u64 %r285,%r284,0;
@ %r285 bra $L14;
add.u64 %r64,%r64,-8;
setp.ne.u64 %r286,%r64,0;
@ %r286 bra $L15;
mov.u64 %r62,%r25;
$L14:
cvta.const.u64 %r287,__clz_tab;
add.u64 %r288,%r287,%r62;
ld.u8 %r289,[%r288];
add.u64 %r67,%r289,%r64;
mov.u64 %r291,64;
sub.u64 %r68,%r291,%r67;
.loc 1 1096 7
setp.ne.u64 %r292,%r291,%r67;
@ %r292 bra $L16;
.loc 1 1105 11
sub.u64 %r69,%r33,%r25;
.loc 1 1124 4
shr.u64 %r177,%r25,32;
and.b64 %r174,%r25,4294967295;
mov.u64 %r175,1;
bra $L17;
$L16:
.loc 1 1114 16
cvt.u32.u64 %r70,%r68;
.loc 1 1114 11
shl.b64 %r25,%r25,%r70;
.loc 1 1115 16
cvt.u32.u64 %r71,%r67;
.loc 1 1115 11
shr.u64 %r72,%r33,%r71;
.loc 1 1116 17
shl.b64 %r73,%r33,%r70;
.loc 1 1116 30
shr.u64 %r293,%r449,%r71;
.loc 1 1116 11
or.b64 %r75,%r293,%r73;
.loc 1 1117 11
shl.b64 %r27,%r449,%r70;
.loc 1 1119 8
shr.u64 %r177,%r25,32;
and.b64 %r174,%r25,4294967295;
rem.u64 %r76,%r72,%r177;
div.u64 %r77,%r72,%r177;
mul.lo.u64 %r78,%r174,%r77;
shl.b64 %r294,%r76,32;
shr.u64 %r295,%r75,32;
or.b64 %r81,%r294,%r295;
setp.le.u64 %r296,%r78,%r81;
@ %r296 bra $L18;
add.u64 %r82,%r77,-1;
add.u64 %r81,%r81,%r25;
set.u32.le.u64 %r298,%r25,%r81;
neg.s32 %r299,%r298;
set.u32.gt.u64 %r301,%r78,%r81;
neg.s32 %r302,%r301;
cvt.u16.u32 %r304,%r299;
cvt.u16.u32 %r305,%r302;
and.b16 %r303,%r304,%r305;
cvt.u32.u16 %r306,%r303;
cvt.u16.u8 %r307,%r306;
setp.eq.u16 %r308,%r307,0;
@ %r308 bra $L33;
add.u64 %r77,%r77,-2;
add.u64 %r81,%r81,%r25;
bra $L18;
$L33:
mov.u64 %r77,%r82;
$L18:
sub.u64 %r83,%r81,%r78;
rem.u64 %r84,%r83,%r177;
div.u64 %r85,%r83,%r177;
mul.lo.u64 %r86,%r174,%r85;
shl.b64 %r309,%r84,32;
and.b64 %r310,%r75,4294967295;
or.b64 %r89,%r309,%r310;
setp.le.u64 %r311,%r86,%r89;
@ %r311 bra $L19;
add.u64 %r90,%r85,-1;
add.u64 %r89,%r89,%r25;
set.u32.le.u64 %r313,%r25,%r89;
neg.s32 %r314,%r313;
set.u32.gt.u64 %r316,%r86,%r89;
neg.s32 %r317,%r316;
cvt.u16.u32 %r319,%r314;
cvt.u16.u32 %r320,%r317;
and.b16 %r318,%r319,%r320;
cvt.u32.u16 %r321,%r318;
cvt.u16.u8 %r322,%r321;
setp.eq.u16 %r323,%r322,0;
@ %r323 bra $L34;
add.u64 %r85,%r85,-2;
add.u64 %r89,%r89,%r25;
bra $L19;
$L34:
mov.u64 %r85,%r90;
$L19:
sub.u64 %r69,%r89,%r86;
shl.b64 %r324,%r77,32;
or.b64 %r175,%r324,%r85;
$L17:
.loc 1 1124 4
rem.u64 %r93,%r69,%r177;
div.u64 %r94,%r69,%r177;
mul.lo.u64 %r95,%r94,%r174;
shl.b64 %r325,%r93,32;
shr.u64 %r326,%r27,32;
or.b64 %r98,%r325,%r326;
setp.le.u64 %r327,%r95,%r98;
@ %r327 bra $L20;
add.u64 %r99,%r94,-1;
add.u64 %r98,%r98,%r25;
set.u32.le.u64 %r329,%r25,%r98;
neg.s32 %r330,%r329;
set.u32.gt.u64 %r332,%r95,%r98;
neg.s32 %r333,%r332;
cvt.u16.u32 %r335,%r330;
cvt.u16.u32 %r336,%r333;
and.b16 %r334,%r335,%r336;
cvt.u32.u16 %r337,%r334;
cvt.u16.u8 %r338,%r337;
setp.eq.u16 %r339,%r338,0;
@ %r339 bra $L35;
add.u64 %r94,%r94,-2;
add.u64 %r98,%r98,%r25;
bra $L20;
$L35:
mov.u64 %r94,%r99;
$L20:
sub.u64 %r100,%r98,%r95;
rem.u64 %r101,%r100,%r177;
div.u64 %r102,%r100,%r177;
mul.lo.u64 %r103,%r102,%r174;
shl.b64 %r340,%r101,32;
and.b64 %r341,%r27,4294967295;
or.b64 %r106,%r340,%r341;
setp.le.u64 %r342,%r103,%r106;
@ %r342 bra $L21;
add.u64 %r107,%r102,-1;
add.u64 %r108,%r25,%r106;
set.u32.gt.u64 %r344,%r103,%r108;
neg.s32 %r345,%r344;
set.u32.le.u64 %r347,%r25,%r108;
neg.s32 %r348,%r347;
cvt.u16.u32 %r350,%r345;
cvt.u16.u32 %r351,%r348;
and.b16 %r349,%r350,%r351;
cvt.u32.u16 %r352,%r349;
cvt.u16.u8 %r353,%r352;
setp.eq.u16 %r354,%r353,0;
@ %r354 bra $L36;
add.u64 %r102,%r102,-2;
bra $L21;
$L36:
mov.u64 %r102,%r107;
$L21:
shl.b64 %r355,%r94,32;
or.b64 %r173,%r355,%r102;
bra $L12;
$L4:
.loc 1 1140 10
setp.gt.u64 %r356,%r24,%r33;
@ %r356 bra $L37;
.loc 1 1159 4
mov.u64 %r114,56;
$L23:
cvt.u32.u64 %r357,%r114;
shr.u64 %r112,%r24,%r357;
and.b64 %r358,%r112,255;
setp.ne.u64 %r359,%r358,0;
@ %r359 bra $L22;
add.u64 %r114,%r114,-8;
setp.ne.u64 %r360,%r114,0;
@ %r360 bra $L23;
mov.u64 %r112,%r24;
$L22:
cvta.const.u64 %r361,__clz_tab;
add.u64 %r362,%r361,%r112;
ld.u8 %r363,[%r362];
add.u64 %r117,%r363,%r114;
mov.u64 %r365,64;
sub.u64 %r118,%r365,%r117;
.loc 1 1160 7
setp.ne.u64 %r366,%r365,%r117;
@ %r366 bra $L24;
.loc 1 1170 15
set.u32.lt.u64 %r368,%r24,%r33;
neg.s32 %r369,%r368;
.loc 1 1170 26
set.u32.le.u64 %r371,%r451,%r449;
neg.s32 %r372,%r371;
.loc 1 1170 20
cvt.u16.u32 %r374,%r369;
cvt.u16.u32 %r375,%r372;
or.b16 %r373,%r374,%r375;
.loc 1 1223 17
cvt.u32.u16 %r376,%r373;
cvt.u64.u8 %r173,%r376;
mov.u64 %r175,%r118;
bra $L12;
$L24:
.loc 1 1194 17
cvt.u32.u64 %r122,%r118;
shl.b64 %r123,%r24,%r122;
.loc 1 1194 30
cvt.u32.u64 %r124,%r117;
shr.u64 %r377,%r451,%r124;
.loc 1 1194 11
or.b64 %r126,%r377,%r123;
.loc 1 1195 11
shl.b64 %r127,%r451,%r122;
.loc 1 1196 11
shr.u64 %r128,%r33,%r124;
.loc 1 1197 17
shl.b64 %r129,%r33,%r122;
.loc 1 1197 30
shr.u64 %r378,%r449,%r124;
.loc 1 1197 11
or.b64 %r131,%r378,%r129;
.loc 1 1200 8
shr.u64 %r133,%r126,32;
and.b64 %r134,%r126,4294967295;
rem.u64 %r135,%r128,%r133;
div.u64 %r136,%r128,%r133;
mul.lo.u64 %r137,%r134,%r136;
shl.b64 %r379,%r135,32;
shr.u64 %r380,%r131,32;
or.b64 %r140,%r379,%r380;
setp.le.u64 %r381,%r137,%r140;
@ %r381 bra $L25;
add.u64 %r141,%r136,-1;
add.u64 %r140,%r140,%r126;
set.u32.gt.u64 %r383,%r137,%r140;
neg.s32 %r384,%r383;
set.u32.le.u64 %r386,%r126,%r140;
neg.s32 %r387,%r386;
cvt.u16.u32 %r389,%r384;
cvt.u16.u32 %r390,%r387;
and.b16 %r388,%r389,%r390;
cvt.u32.u16 %r391,%r388;
cvt.u16.u8 %r392,%r391;
setp.eq.u16 %r393,%r392,0;
@ %r393 bra $L38;
add.u64 %r136,%r136,-2;
add.u64 %r140,%r140,%r126;
bra $L25;
$L38:
mov.u64 %r136,%r141;
$L25:
sub.u64 %r142,%r140,%r137;
rem.u64 %r143,%r142,%r133;
div.u64 %r144,%r142,%r133;
mul.lo.u64 %r145,%r134,%r144;
shl.b64 %r394,%r143,32;
and.b64 %r395,%r131,4294967295;
or.b64 %r148,%r394,%r395;
setp.le.u64 %r396,%r145,%r148;
@ %r396 bra $L26;
add.u64 %r149,%r144,-1;
add.u64 %r148,%r148,%r126;
set.u32.le.u64 %r398,%r126,%r148;
neg.s32 %r399,%r398;
set.u32.gt.u64 %r401,%r145,%r148;
neg.s32 %r402,%r401;
cvt.u16.u32 %r404,%r399;
cvt.u16.u32 %r405,%r402;
and.b16 %r403,%r404,%r405;
cvt.u32.u16 %r406,%r403;
cvt.u16.u8 %r407,%r406;
setp.eq.u16 %r408,%r407,0;
@ %r408 bra $L39;
add.u64 %r144,%r144,-2;
add.u64 %r148,%r148,%r126;
bra $L26;
$L39:
mov.u64 %r144,%r149;
$L26:
sub.u64 %r150,%r148,%r145;
shl.b64 %r409,%r136,32;
or.b64 %r152,%r409,%r144;
.loc 1 1201 8
and.b64 %r153,%r144,4294967295;
shr.u64 %r154,%r152,32;
and.b64 %r155,%r127,4294967295;
shr.u64 %r156,%r127,32;
mul.lo.u64 %r157,%r153,%r155;
mul.lo.u64 %r159,%r154,%r155;
mul.lo.u64 %r160,%r154,%r156;
mad.lo.u64 %r182,%r153,%r156,%r159;
shr.u64 %r411,%r157,32;
add.u64 %r162,%r411,%r182;
setp.le.u64 %r412,%r159,%r162;
@ %r412 bra $L27;
add.u64 %r160,%r160,4294967296;
$L27:
shr.u64 %r413,%r162,32;
add.u64 %r164,%r413,%r160;
.loc 1 1203 11
setp.lt.u64 %r414,%r150,%r164;
@ %r414 bra $L28;
.loc 1 1198 11
shl.b64 %r415,%r449,%r122;
.loc 1 1201 8
shl.b64 %r417,%r162,32;
and.b64 %r418,%r157,4294967295;
add.u64 %r419,%r417,%r418;
.loc 1 1203 39
set.u32.lt.u64 %r421,%r415,%r419;
neg.s32 %r422,%r421;
.loc 1 1203 27
set.u32.eq.u64 %r424,%r150,%r164;
neg.s32 %r425,%r424;
.loc 1 1203 33
cvt.u16.u32 %r427,%r422;
cvt.u16.u32 %r428,%r425;
and.b16 %r426,%r427,%r428;
.loc 1 1203 20
cvt.u32.u16 %r429,%r426;
cvt.u16.u8 %r430,%r429;
setp.ne.u16 %r431,%r430,0;
@ %r431 bra $L28;
.loc 1 1223 17
mov.u64 %r173,%r152;
mov.u64 %r175,0;
bra $L12;
$L28:
.loc 1 1205 7
add.u64 %r173,%r152,-1;
.loc 1 1223 17
mov.u64 %r175,0;
bra $L12;
$L37:
mov.u64 %r175,0;
mov.u64 %r173,%r175;
$L12:
.loc 1 1224 12
mov.u64 %r447,%r173;
mov.u64 %r448,%r175;
.loc 1 1246 6
setp.eq.u64 %r432,%r22,0;
@ %r432 bra $L29;
.loc 1 1247 7
set.u32.ne.u64 %r440,%r447,0;
cvt.s64.s32 %r438,%r440;
neg.s64 %r447,%r447;
sub.u64 %r448,%r438,%r448;
$L29:
.loc 1 1249 10
st.u64 [%r203],%r447;
st.u64 [%r203+8],%r448;
.loc 1 1250 1
ret;
}

_moddi3.o/      1608280949  0     0     100666  17902     `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __modti3
.visible .func __modti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __modti3
.visible .func __modti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,16;
sub.u64 %stack,%frame,0;
}
.reg .u64 %r22;
.reg .u64 %r23;
.reg .u64 %r24;
.reg .u64 %r25;
.reg .u64 %r27;
.reg .u64 %r28;
.reg .u64 %r29;
.reg .u64 %r31;
.reg .u64 %r33;
.reg .u64 %r34;
.reg .u64 %r37;
.reg .u64 %r38;
.reg .u64 %r41;
.reg .u64 %r42;
.reg .u64 %r43;
.reg .u64 %r44;
.reg .u64 %r45;
.reg .u64 %r48;
.reg .u64 %r49;
.reg .u64 %r50;
.reg .u64 %r51;
.reg .u64 %r52;
.reg .u64 %r55;
.reg .u64 %r56;
.reg .u64 %r58;
.reg .u64 %r60;
.reg .u64 %r63;
.reg .u64 %r64;
.reg .u64 %r65;
.reg .u32 %r66;
.reg .u64 %r67;
.reg .u64 %r68;
.reg .u64 %r70;
.reg .u64 %r71;
.reg .u64 %r72;
.reg .u64 %r73;
.reg .u64 %r76;
.reg .u64 %r77;
.reg .u64 %r78;
.reg .u64 %r79;
.reg .u64 %r80;
.reg .u64 %r83;
.reg .u64 %r84;
.reg .u64 %r85;
.reg .u64 %r86;
.reg .u64 %r89;
.reg .u64 %r90;
.reg .u64 %r91;
.reg .u64 %r92;
.reg .u64 %r93;
.reg .u64 %r96;
.reg .u64 %r100;
.reg .u64 %r102;
.reg .u64 %r105;
.reg .u64 %r106;
.reg .u64 %r111;
.reg .u32 %r115;
.reg .u64 %r116;
.reg .u32 %r117;
.reg .u64 %r119;
.reg .u64 %r120;
.reg .u64 %r121;
.reg .u64 %r122;
.reg .u64 %r124;
.reg .u64 %r125;
.reg .u64 %r126;
.reg .u64 %r127;
.reg .u64 %r128;
.reg .u64 %r129;
.reg .u64 %r130;
.reg .u64 %r133;
.reg .u64 %r134;
.reg .u64 %r135;
.reg .u64 %r136;
.reg .u64 %r137;
.reg .u64 %r138;
.reg .u64 %r141;
.reg .u64 %r142;
.reg .u64 %r143;
.reg .u64 %r145;
.reg .u64 %r146;
.reg .u64 %r147;
.reg .u64 %r148;
.reg .u64 %r149;
.reg .u64 %r150;
.reg .u64 %r152;
.reg .u64 %r153;
.reg .u64 %r155;
.reg .u64 %r160;
.reg .u64 %r164;
.reg .u64 %r167;
.reg .u64 %r168;
.reg .u64 %r172;
.reg .u32 %r180;
.reg .u64 %r181;
.reg .u64 %r182;
.reg .u64 %r183;
.reg .u64 %r209;
.reg .u64 %r210;
.reg .u64 %r212;
.reg .pred %r214;
.reg .u64 %r220;
.reg .u32 %r222;
.reg .pred %r227;
.reg .u64 %r233;
.reg .u32 %r235;
.reg .pred %r240;
.reg .pred %r241;
.reg .u32 %r242;
.reg .u64 %r243;
.reg .pred %r244;
.reg .pred %r245;
.reg .u64 %r246;
.reg .u64 %r247;
.reg .u64 %r248;
.reg .u64 %r249;
.reg .pred %r251;
.reg .u32 %r252;
.reg .u32 %r253;
.reg .u64 %r254;
.reg .u64 %r255;
.reg .u64 %r256;
.reg .pred %r257;
.reg .u32 %r259;
.reg .u32 %r260;
.reg .u32 %r262;
.reg .u32 %r263;
.reg .u16 %r264;
.reg .u16 %r265;
.reg .u16 %r266;
.reg .u32 %r267;
.reg .u16 %r268;
.reg .pred %r269;
.reg .u64 %r270;
.reg .u64 %r271;
.reg .pred %r272;
.reg .u32 %r274;
.reg .u32 %r275;
.reg .u32 %r277;
.reg .u32 %r278;
.reg .u16 %r279;
.reg .u16 %r280;
.reg .u16 %r281;
.reg .u32 %r282;
.reg .u16 %r283;
.reg .pred %r284;
.reg .pred %r285;
.reg .u64 %r286;
.reg .u32 %r288;
.reg .u64 %r289;
.reg .pred %r290;
.reg .pred %r291;
.reg .u64 %r292;
.reg .u64 %r293;
.reg .u64 %r294;
.reg .u64 %r296;
.reg .pred %r297;
.reg .u64 %r298;
.reg .u64 %r299;
.reg .u64 %r300;
.reg .pred %r301;
.reg .u32 %r303;
.reg .u32 %r304;
.reg .u32 %r306;
.reg .u32 %r307;
.reg .u16 %r308;
.reg .u16 %r309;
.reg .u16 %r310;
.reg .u32 %r311;
.reg .u16 %r312;
.reg .pred %r313;
.reg .u64 %r314;
.reg .u64 %r315;
.reg .pred %r316;
.reg .u32 %r318;
.reg .u32 %r319;
.reg .u32 %r321;
.reg .u32 %r322;
.reg .u16 %r323;
.reg .u16 %r324;
.reg .u16 %r325;
.reg .u32 %r326;
.reg .u16 %r327;
.reg .pred %r328;
.reg .u64 %r329;
.reg .u64 %r330;
.reg .pred %r331;
.reg .u32 %r333;
.reg .u32 %r334;
.reg .u32 %r336;
.reg .u32 %r337;
.reg .u16 %r338;
.reg .u16 %r339;
.reg .u16 %r340;
.reg .u32 %r341;
.reg .u16 %r342;
.reg .pred %r343;
.reg .u64 %r344;
.reg .u64 %r345;
.reg .pred %r346;
.reg .u32 %r348;
.reg .u32 %r349;
.reg .u32 %r351;
.reg .u32 %r352;
.reg .u16 %r353;
.reg .u16 %r354;
.reg .u16 %r355;
.reg .u32 %r356;
.reg .u16 %r357;
.reg .pred %r358;
.reg .pred %r361;
.reg .u32 %r362;
.reg .u64 %r363;
.reg .pred %r364;
.reg .pred %r365;
.reg .u64 %r366;
.reg .u64 %r367;
.reg .u64 %r368;
.reg .u64 %r370;
.reg .pred %r371;
.reg .u32 %r373;
.reg .u32 %r374;
.reg .u32 %r376;
.reg .u32 %r377;
.reg .u16 %r378;
.reg .u16 %r379;
.reg .u16 %r380;
.reg .u32 %r381;
.reg .u16 %r382;
.reg .pred %r383;
.reg .u64 %r384;
.reg .u32 %r385;
.reg .u64 %r387;
.reg .u64 %r388;
.reg .u64 %r389;
.reg .u64 %r390;
.reg .pred %r391;
.reg .u32 %r393;
.reg .u32 %r394;
.reg .u32 %r396;
.reg .u32 %r397;
.reg .u16 %r398;
.reg .u16 %r399;
.reg .u16 %r400;
.reg .u32 %r401;
.reg .u16 %r402;
.reg .pred %r403;
.reg .u64 %r404;
.reg .u64 %r405;
.reg .pred %r406;
.reg .u32 %r408;
.reg .u32 %r409;
.reg .u32 %r411;
.reg .u32 %r412;
.reg .u16 %r413;
.reg .u16 %r414;
.reg .u16 %r415;
.reg .u32 %r416;
.reg .u16 %r417;
.reg .pred %r418;
.reg .u64 %r419;
.reg .u64 %r421;
.reg .pred %r422;
.reg .u64 %r423;
.reg .u64 %r425;
.reg .u64 %r426;
.reg .pred %r427;
.reg .u32 %r429;
.reg .u32 %r430;
.reg .u32 %r432;
.reg .u32 %r433;
.reg .u16 %r434;
.reg .u16 %r435;
.reg .u16 %r436;
.reg .u32 %r437;
.reg .u16 %r438;
.reg .pred %r439;
.reg .u64 %r440;
.reg .u32 %r441;
.reg .u64 %r443;
.reg .u64 %r444;
.reg .u64 %r445;
.reg .u32 %r446;
.reg .u64 %r448;
.reg .u64 %r449;
.reg .pred %r452;
.reg .u64 %r458;
.reg .u32 %r460;
.reg .u64 %r467;
.reg .u64 %r468;
.reg .u64 %r469;
.reg .u64 %r471;
.reg .u64 %r472;
mov.u64 %r209,%ar0;
mov.u64 %r210,%ar1;
ld.u64 %r469,[%r210];
mov.u64 %r212,%ar2;
ld.u64 %r471,[%r212];
ld.u64 %r472,[%r212+8];
ld.u64 %r34,[%r210+8];
.loc 1 1262 6
setp.ge.s64 %r214,%r34,0;
@ %r214 bra $L33;
.loc 1 1264 13
set.u32.ne.u64 %r222,%r469,0;
cvt.s64.s32 %r220,%r222;
neg.s64 %r469,%r469;
sub.u64 %r34,%r220,%r34;
.loc 1 1263 7
mov.u64 %r22,-1;
bra $L2;
$L33:
.loc 1 1257 9
mov.u64 %r22,0;
$L2:
mov.u64 %r23,%r472;
.loc 1 1265 6
setp.ge.s64 %r227,%r23,0;
@ %r227 bra $L3;
.loc 1 1266 13
set.u32.ne.u64 %r235,%r471,0;
cvt.s64.s32 %r233,%r235;
neg.s64 %r471,%r471;
sub.u64 %r23,%r233,%r23;
$L3:
.loc 1 1024 6
mov.u64 %r25,%r471;
.loc 1 1026 6
mov.u64 %r28,%r469;
.loc 1 1027 6
mov.u64 %r29,%r34;
.loc 1 1064 6
setp.ne.u64 %r240,%r23,0;
@ %r240 bra $L4;
.loc 1 1066 10
setp.le.u64 %r241,%r471,%r34;
@ %r241 bra $L5;
.loc 1 1070 4
mov.u64 %r33,56;
$L7:
cvt.u32.u64 %r242,%r33;
shr.u64 %r31,%r471,%r242;
and.b64 %r243,%r31,255;
setp.ne.u64 %r244,%r243,0;
@ %r244 bra $L6;
add.u64 %r33,%r33,-8;
setp.ne.u64 %r245,%r33,0;
@ %r245 bra $L7;
mov.u64 %r31,%r471;
mov.u64 %r181,64;
bra $L8;
$L6:
mov.u64 %r246,64;
sub.u64 %r181,%r246,%r33;
$L8:
cvta.const.u64 %r247,__clz_tab;
add.u64 %r248,%r247,%r31;
ld.u8 %r249,[%r248];
sub.u64 %r37,%r181,%r249;
.loc 1 1072 7
setp.eq.u64 %r251,%r181,%r249;
@ %r251 bra $L34;
.loc 1 1077 16
cvt.u32.u64 %r180,%r37;
.loc 1 1077 11
shl.b64 %r25,%r471,%r180;
.loc 1 1078 17
shl.b64 %r38,%r34,%r180;
.loc 1 1078 46
mov.u32 %r253,64;
sub.u32 %r252,%r253,%r180;
.loc 1 1078 30
shr.u64 %r254,%r469,%r252;
.loc 1 1078 11
or.b64 %r29,%r254,%r38;
.loc 1 1079 11
shl.b64 %r28,%r469,%r180;
bra $L9;
$L34:
cvt.u32.u64 %r180,%r37;
$L9:
.loc 1 1082 4
shr.u64 %r41,%r25,32;
and.b64 %r42,%r25,4294967295;
rem.u64 %r43,%r29,%r41;
div.u64 %r44,%r29,%r41;
mul.lo.u64 %r45,%r42,%r44;
shl.b64 %r255,%r43,32;
shr.u64 %r256,%r28,32;
or.b64 %r48,%r255,%r256;
setp.le.u64 %r257,%r45,%r48;
@ %r257 bra $L10;
add.u64 %r48,%r48,%r25;
set.u32.le.u64 %r259,%r25,%r48;
neg.s32 %r260,%r259;
set.u32.gt.u64 %r262,%r45,%r48;
neg.s32 %r263,%r262;
cvt.u16.u32 %r265,%r260;
cvt.u16.u32 %r266,%r263;
and.b16 %r264,%r265,%r266;
cvt.u32.u16 %r267,%r264;
cvt.u16.u8 %r268,%r267;
setp.eq.u16 %r269,%r268,0;
@ %r269 bra $L10;
add.u64 %r48,%r48,%r25;
$L10:
sub.u64 %r49,%r48,%r45;
rem.u64 %r50,%r49,%r41;
div.u64 %r51,%r49,%r41;
mul.lo.u64 %r52,%r42,%r51;
shl.b64 %r270,%r50,32;
and.b64 %r271,%r28,4294967295;
or.b64 %r55,%r270,%r271;
setp.le.u64 %r272,%r52,%r55;
@ %r272 bra $L11;
add.u64 %r55,%r55,%r25;
set.u32.gt.u64 %r274,%r52,%r55;
neg.s32 %r275,%r274;
set.u32.le.u64 %r277,%r25,%r55;
neg.s32 %r278,%r277;
cvt.u16.u32 %r280,%r275;
cvt.u16.u32 %r281,%r278;
and.b16 %r279,%r280,%r281;
cvt.u32.u16 %r282,%r279;
cvt.u16.u8 %r283,%r282;
setp.eq.u16 %r284,%r283,0;
@ %r284 bra $L11;
add.u64 %r55,%r55,%r25;
$L11:
sub.u64 %r56,%r55,%r52;
bra $L12;
$L5:
.loc 1 1091 7
setp.ne.u64 %r285,%r25,0;
@ %r285 bra $L13;
.loc 1 1092 9
mov.u64 %r286,1;
div.u64 %r25,%r286,0;
$L13:
.loc 1 1094 4
mov.u64 %r60,56;
$L15:
cvt.u32.u64 %r288,%r60;
shr.u64 %r58,%r25,%r288;
and.b64 %r289,%r58,255;
setp.ne.u64 %r290,%r289,0;
@ %r290 bra $L14;
add.u64 %r60,%r60,-8;
setp.ne.u64 %r291,%r60,0;
@ %r291 bra $L15;
mov.u64 %r58,%r25;
$L14:
cvta.const.u64 %r292,__clz_tab;
add.u64 %r293,%r292,%r58;
ld.u8 %r294,[%r293];
add.u64 %r63,%r294,%r60;
mov.u64 %r296,64;
sub.u64 %r64,%r296,%r63;
.loc 1 1096 7
setp.ne.u64 %r297,%r296,%r63;
@ %r297 bra $L16;
.loc 1 1105 11
sub.u64 %r65,%r34,%r25;
.loc 1 1124 4
shr.u64 %r182,%r25,32;
and.b64 %r183,%r25,4294967295;
cvt.u32.u64 %r180,%r64;
bra $L17;
$L16:
.loc 1 1114 16
cvt.u32.u64 %r180,%r64;
.loc 1 1114 11
shl.b64 %r25,%r25,%r180;
.loc 1 1115 16
cvt.u32.u64 %r66,%r63;
.loc 1 1115 11
shr.u64 %r67,%r34,%r66;
.loc 1 1116 17
shl.b64 %r68,%r34,%r180;
.loc 1 1116 30
shr.u64 %r298,%r469,%r66;
.loc 1 1116 11
or.b64 %r70,%r298,%r68;
.loc 1 1117 11
shl.b64 %r28,%r469,%r180;
.loc 1 1119 8
shr.u64 %r182,%r25,32;
and.b64 %r183,%r25,4294967295;
rem.u64 %r71,%r67,%r182;
div.u64 %r72,%r67,%r182;
mul.lo.u64 %r73,%r183,%r72;
shl.b64 %r299,%r71,32;
shr.u64 %r300,%r70,32;
or.b64 %r76,%r299,%r300;
setp.le.u64 %r301,%r73,%r76;
@ %r301 bra $L18;
add.u64 %r76,%r76,%r25;
set.u32.le.u64 %r303,%r25,%r76;
neg.s32 %r304,%r303;
set.u32.gt.u64 %r306,%r73,%r76;
neg.s32 %r307,%r306;
cvt.u16.u32 %r309,%r304;
cvt.u16.u32 %r310,%r307;
and.b16 %r308,%r309,%r310;
cvt.u32.u16 %r311,%r308;
cvt.u16.u8 %r312,%r311;
setp.eq.u16 %r313,%r312,0;
@ %r313 bra $L18;
add.u64 %r76,%r76,%r25;
$L18:
sub.u64 %r77,%r76,%r73;
rem.u64 %r78,%r77,%r182;
div.u64 %r79,%r77,%r182;
mul.lo.u64 %r80,%r183,%r79;
shl.b64 %r314,%r78,32;
and.b64 %r315,%r70,4294967295;
or.b64 %r83,%r314,%r315;
setp.le.u64 %r316,%r80,%r83;
@ %r316 bra $L19;
add.u64 %r83,%r83,%r25;
set.u32.gt.u64 %r318,%r80,%r83;
neg.s32 %r319,%r318;
set.u32.le.u64 %r321,%r25,%r83;
neg.s32 %r322,%r321;
cvt.u16.u32 %r324,%r319;
cvt.u16.u32 %r325,%r322;
and.b16 %r323,%r324,%r325;
cvt.u32.u16 %r326,%r323;
cvt.u16.u8 %r327,%r326;
setp.eq.u16 %r328,%r327,0;
@ %r328 bra $L19;
add.u64 %r83,%r83,%r25;
$L19:
sub.u64 %r65,%r83,%r80;
$L17:
.loc 1 1124 4
rem.u64 %r84,%r65,%r182;
div.u64 %r85,%r65,%r182;
mul.lo.u64 %r86,%r85,%r183;
shl.b64 %r329,%r84,32;
shr.u64 %r330,%r28,32;
or.b64 %r89,%r329,%r330;
setp.le.u64 %r331,%r86,%r89;
@ %r331 bra $L20;
add.u64 %r89,%r89,%r25;
set.u32.le.u64 %r333,%r25,%r89;
neg.s32 %r334,%r333;
set.u32.gt.u64 %r336,%r86,%r89;
neg.s32 %r337,%r336;
cvt.u16.u32 %r339,%r334;
cvt.u16.u32 %r340,%r337;
and.b16 %r338,%r339,%r340;
cvt.u32.u16 %r341,%r338;
cvt.u16.u8 %r342,%r341;
setp.eq.u16 %r343,%r342,0;
@ %r343 bra $L20;
add.u64 %r89,%r89,%r25;
$L20:
sub.u64 %r90,%r89,%r86;
rem.u64 %r91,%r90,%r182;
div.u64 %r92,%r90,%r182;
mul.lo.u64 %r93,%r92,%r183;
shl.b64 %r344,%r91,32;
and.b64 %r345,%r28,4294967295;
or.b64 %r96,%r344,%r345;
setp.le.u64 %r346,%r93,%r96;
@ %r346 bra $L21;
add.u64 %r96,%r96,%r25;
set.u32.le.u64 %r348,%r25,%r96;
neg.s32 %r349,%r348;
set.u32.gt.u64 %r351,%r93,%r96;
neg.s32 %r352,%r351;
cvt.u16.u32 %r354,%r349;
cvt.u16.u32 %r355,%r352;
and.b16 %r353,%r354,%r355;
cvt.u32.u16 %r356,%r353;
cvt.u16.u8 %r357,%r356;
setp.eq.u16 %r358,%r357,0;
@ %r358 bra $L21;
add.u64 %r96,%r96,%r25;
$L21:
sub.u64 %r56,%r96,%r93;
$L12:
.loc 1 1133 12
shr.u64 %r467,%r56,%r180;
mov.u64 %r468,0;
bra $L22;
$L4:
mov.u64 %r27,%r469;
.loc 1 1140 10
setp.le.u64 %r361,%r23,%r34;
@ %r361 bra $L35;
.loc 1 1152 16
mov.u64 %r467,%r469;
mov.u64 %r468,%r34;
bra $L22;
$L35:
.loc 1 1159 4
mov.u64 %r102,56;
$L23:
cvt.u32.u64 %r362,%r102;
shr.u64 %r100,%r23,%r362;
and.b64 %r363,%r100,255;
setp.ne.u64 %r364,%r363,0;
@ %r364 bra $L24;
add.u64 %r102,%r102,-8;
setp.ne.u64 %r365,%r102,0;
@ %r365 bra $L23;
mov.u64 %r100,%r23;
$L24:
cvta.const.u64 %r366,__clz_tab;
add.u64 %r367,%r366,%r100;
ld.u8 %r368,[%r367];
add.u64 %r105,%r368,%r102;
mov.u64 %r370,64;
sub.u64 %r106,%r370,%r105;
.loc 1 1160 7
setp.ne.u64 %r371,%r370,%r105;
@ %r371 bra $L25;
.loc 1 1170 15
set.u32.lt.u64 %r373,%r23,%r34;
neg.s32 %r374,%r373;
.loc 1 1170 26
set.u32.le.u64 %r376,%r471,%r469;
neg.s32 %r377,%r376;
.loc 1 1170 20
cvt.u16.u32 %r379,%r374;
cvt.u16.u32 %r380,%r377;
or.b16 %r378,%r379,%r380;
.loc 1 1170 11
cvt.u32.u16 %r381,%r378;
cvt.u16.u8 %r382,%r381;
setp.eq.u16 %r383,%r382,0;
@ %r383 bra $L26;
.loc 1 1173 5
sub.u64 %r111,%r34,%r23;
.loc 1 1182 14
sub.u64 %r27,%r469,%r471;
.loc 1 1173 5
set.u32.lt.u64 %r385,%r469,%r27;
cvt.s64.s32 %r384,%r385;
add.u64 %r34,%r111,%r384;
$L26:
.loc 1 1184 13
mov.u64 %r467,%r27;
mov.u64 %r468,%r34;
bra $L22;
$L25:
.loc 1 1194 17
cvt.u32.u64 %r115,%r106;
shl.b64 %r116,%r23,%r115;
.loc 1 1194 30
cvt.u32.u64 %r117,%r105;
shr.u64 %r387,%r471,%r117;
.loc 1 1194 11
or.b64 %r119,%r387,%r116;
.loc 1 1195 11
shl.b64 %r120,%r471,%r115;
.loc 1 1196 11
shr.u64 %r121,%r34,%r117;
.loc 1 1197 17
shl.b64 %r122,%r34,%r115;
.loc 1 1197 30
shr.u64 %r388,%r469,%r117;
.loc 1 1197 11
or.b64 %r124,%r388,%r122;
.loc 1 1198 11
shl.b64 %r125,%r469,%r115;
.loc 1 1200 8
shr.u64 %r126,%r119,32;
and.b64 %r127,%r119,4294967295;
rem.u64 %r128,%r121,%r126;
div.u64 %r129,%r121,%r126;
mul.lo.u64 %r130,%r127,%r129;
shl.b64 %r389,%r128,32;
shr.u64 %r390,%r124,32;
or.b64 %r133,%r389,%r390;
setp.le.u64 %r391,%r130,%r133;
@ %r391 bra $L27;
add.u64 %r134,%r129,-1;
add.u64 %r133,%r133,%r119;
set.u32.le.u64 %r393,%r119,%r133;
neg.s32 %r394,%r393;
set.u32.gt.u64 %r396,%r130,%r133;
neg.s32 %r397,%r396;
cvt.u16.u32 %r399,%r394;
cvt.u16.u32 %r400,%r397;
and.b16 %r398,%r399,%r400;
cvt.u32.u16 %r401,%r398;
cvt.u16.u8 %r402,%r401;
setp.eq.u16 %r403,%r402,0;
@ %r403 bra $L36;
add.u64 %r129,%r129,-2;
add.u64 %r133,%r133,%r119;
bra $L27;
$L36:
mov.u64 %r129,%r134;
$L27:
sub.u64 %r135,%r133,%r130;
rem.u64 %r136,%r135,%r126;
div.u64 %r137,%r135,%r126;
mul.lo.u64 %r138,%r127,%r137;
shl.b64 %r404,%r136,32;
and.b64 %r405,%r124,4294967295;
or.b64 %r141,%r404,%r405;
setp.le.u64 %r406,%r138,%r141;
@ %r406 bra $L28;
add.u64 %r142,%r137,-1;
add.u64 %r141,%r141,%r119;
set.u32.gt.u64 %r408,%r138,%r141;
neg.s32 %r409,%r408;
set.u32.le.u64 %r411,%r119,%r141;
neg.s32 %r412,%r411;
cvt.u16.u32 %r414,%r409;
cvt.u16.u32 %r415,%r412;
and.b16 %r413,%r414,%r415;
cvt.u32.u16 %r416,%r413;
cvt.u16.u8 %r417,%r416;
setp.eq.u16 %r418,%r417,0;
@ %r418 bra $L37;
add.u64 %r137,%r137,-2;
add.u64 %r141,%r141,%r119;
bra $L28;
$L37:
mov.u64 %r137,%r142;
$L28:
sub.u64 %r143,%r141,%r138;
shl.b64 %r419,%r129,32;
or.b64 %r145,%r419,%r137;
.loc 1 1201 8
and.b64 %r146,%r137,4294967295;
shr.u64 %r147,%r145,32;
and.b64 %r148,%r120,4294967295;
shr.u64 %r149,%r120,32;
mul.lo.u64 %r150,%r146,%r148;
mul.lo.u64 %r152,%r147,%r148;
mul.lo.u64 %r153,%r147,%r149;
mad.lo.u64 %r24,%r146,%r149,%r152;
shr.u64 %r421,%r150,32;
add.u64 %r155,%r421,%r24;
setp.le.u64 %r422,%r152,%r155;
@ %r422 bra $L29;
add.u64 %r153,%r153,4294967296;
$L29:
shr.u64 %r423,%r155,32;
add.u64 %r167,%r423,%r153;
shl.b64 %r425,%r155,32;
and.b64 %r426,%r150,4294967295;
add.u64 %r160,%r425,%r426;
.loc 1 1203 11
setp.lt.u64 %r427,%r143,%r167;
@ %r427 bra $L30;
.loc 1 1203 27
set.u32.eq.u64 %r429,%r143,%r167;
neg.s32 %r430,%r429;
.loc 1 1203 39
set.u32.lt.u64 %r432,%r125,%r160;
neg.s32 %r433,%r432;
.loc 1 1203 33
cvt.u16.u32 %r435,%r430;
cvt.u16.u32 %r436,%r433;
and.b16 %r434,%r435,%r436;
.loc 1 1203 20
cvt.u32.u16 %r437,%r434;
cvt.u16.u8 %r438,%r437;
setp.eq.u16 %r439,%r438,0;
@ %r439 bra $L38;
$L30:
.loc 1 1206 5
sub.u64 %r164,%r160,%r120;
set.u32.lt.u64 %r441,%r160,%r164;
cvt.s64.s32 %r440,%r441;
sub.u64 %r443,%r119,%r440;
sub.u64 %r167,%r167,%r443;
bra $L31;
$L38:
.loc 1 1201 8
mov.u64 %r164,%r160;
$L31:
.loc 1 1214 5
sub.u64 %r168,%r125,%r164;
sub.u64 %r444,%r143,%r167;
set.u32.lt.u64 %r446,%r125,%r168;
cvt.s64.s32 %r445,%r446;
add.u64 %r172,%r444,%r445;
.loc 1 1215 20
shl.b64 %r448,%r172,%r117;
.loc 1 1215 32
shr.u64 %r449,%r168,%r115;
.loc 1 1217 13
or.b64 %r467,%r448,%r449;
shr.u64 %r468,%r172,%r115;
$L22:
.loc 1 1269 6
setp.eq.u64 %r452,%r22,0;
@ %r452 bra $L32;
.loc 1 1270 9
set.u32.ne.u64 %r460,%r467,0;
cvt.s64.s32 %r458,%r460;
neg.s64 %r467,%r467;
sub.u64 %r468,%r458,%r468;
$L32:
.loc 1 1272 10
st.u64 [%r209],%r467;
st.u64 [%r209+8],%r468;
.loc 1 1273 1
ret;
}
_divmoddi4.o/   1608280948  0     0     100666  19718     `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __divmodti4
.visible .func __divmodti4 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2, .param .u64 %in_ar3);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __divmodti4
.visible .func __divmodti4 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2, .param .u64 %in_ar3)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %ar3;
ld.param.u64 %ar3,[%in_ar3];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,32;
sub.u64 %stack,%frame,0;
}
.reg .u64 %r22;
.reg .u64 %r23;
.reg .u64 %r25;
.reg .u64 %r26;
.reg .u64 %r27;
.reg .u64 %r29;
.reg .u64 %r30;
.reg .u64 %r31;
.reg .u64 %r33;
.reg .u64 %r35;
.reg .u64 %r36;
.reg .u64 %r39;
.reg .u64 %r40;
.reg .u64 %r43;
.reg .u64 %r44;
.reg .u64 %r45;
.reg .u64 %r46;
.reg .u64 %r47;
.reg .u64 %r50;
.reg .u64 %r51;
.reg .u64 %r52;
.reg .u64 %r53;
.reg .u64 %r54;
.reg .u64 %r55;
.reg .u64 %r58;
.reg .u64 %r59;
.reg .u64 %r60;
.reg .u64 %r62;
.reg .u64 %r64;
.reg .u64 %r66;
.reg .u64 %r69;
.reg .u64 %r70;
.reg .u64 %r71;
.reg .u32 %r72;
.reg .u64 %r73;
.reg .u64 %r74;
.reg .u64 %r76;
.reg .u64 %r77;
.reg .u64 %r78;
.reg .u64 %r79;
.reg .u64 %r82;
.reg .u64 %r83;
.reg .u64 %r84;
.reg .u64 %r85;
.reg .u64 %r86;
.reg .u64 %r87;
.reg .u64 %r90;
.reg .u64 %r91;
.reg .u64 %r94;
.reg .u64 %r95;
.reg .u64 %r96;
.reg .u64 %r99;
.reg .u64 %r100;
.reg .u64 %r101;
.reg .u64 %r102;
.reg .u64 %r103;
.reg .u64 %r104;
.reg .u64 %r107;
.reg .u64 %r108;
.reg .u64 %r113;
.reg .u64 %r115;
.reg .u64 %r118;
.reg .u64 %r119;
.reg .u64 %r124;
.reg .u32 %r128;
.reg .u64 %r129;
.reg .u32 %r130;
.reg .u64 %r132;
.reg .u64 %r133;
.reg .u64 %r134;
.reg .u64 %r135;
.reg .u64 %r137;
.reg .u64 %r138;
.reg .u64 %r139;
.reg .u64 %r140;
.reg .u64 %r141;
.reg .u64 %r142;
.reg .u64 %r143;
.reg .u64 %r146;
.reg .u64 %r147;
.reg .u64 %r148;
.reg .u64 %r149;
.reg .u64 %r150;
.reg .u64 %r151;
.reg .u64 %r154;
.reg .u64 %r155;
.reg .u64 %r156;
.reg .u64 %r158;
.reg .u64 %r159;
.reg .u64 %r160;
.reg .u64 %r161;
.reg .u64 %r162;
.reg .u64 %r164;
.reg .u64 %r165;
.reg .u64 %r167;
.reg .u64 %r172;
.reg .u64 %r176;
.reg .u64 %r177;
.reg .u64 %r180;
.reg .u64 %r181;
.reg .u64 %r185;
.reg .u64 %r194;
.reg .u64 %r219;
.reg .u64 %r220;
.reg .u32 %r221;
.reg .u64 %r222;
.reg .u64 %r223;
.reg .u64 %r224;
.reg .u64 %r225;
.reg .u64 %r227;
.reg .u64 %r229;
.reg .pred %r230;
.reg .u64 %r236;
.reg .u32 %r238;
.reg .pred %r243;
.reg .u64 %r249;
.reg .u32 %r251;
.reg .pred %r256;
.reg .pred %r257;
.reg .u32 %r258;
.reg .u64 %r259;
.reg .pred %r260;
.reg .pred %r261;
.reg .u64 %r262;
.reg .u64 %r263;
.reg .u64 %r264;
.reg .u64 %r265;
.reg .pred %r267;
.reg .u32 %r268;
.reg .u32 %r269;
.reg .u64 %r270;
.reg .u64 %r271;
.reg .u64 %r272;
.reg .pred %r273;
.reg .u32 %r275;
.reg .u32 %r276;
.reg .u32 %r278;
.reg .u32 %r279;
.reg .u16 %r280;
.reg .u16 %r281;
.reg .u16 %r282;
.reg .u32 %r283;
.reg .u16 %r284;
.reg .pred %r285;
.reg .u64 %r286;
.reg .u64 %r287;
.reg .pred %r288;
.reg .u32 %r290;
.reg .u32 %r291;
.reg .u32 %r293;
.reg .u32 %r294;
.reg .u16 %r295;
.reg .u16 %r296;
.reg .u16 %r297;
.reg .u32 %r298;
.reg .u16 %r299;
.reg .pred %r300;
.reg .u64 %r301;
.reg .pred %r302;
.reg .u64 %r303;
.reg .u32 %r305;
.reg .u64 %r306;
.reg .pred %r307;
.reg .pred %r308;
.reg .u64 %r309;
.reg .u64 %r310;
.reg .u64 %r311;
.reg .u64 %r313;
.reg .pred %r314;
.reg .u64 %r315;
.reg .u64 %r316;
.reg .u64 %r317;
.reg .pred %r318;
.reg .u32 %r320;
.reg .u32 %r321;
.reg .u32 %r323;
.reg .u32 %r324;
.reg .u16 %r325;
.reg .u16 %r326;
.reg .u16 %r327;
.reg .u32 %r328;
.reg .u16 %r329;
.reg .pred %r330;
.reg .u64 %r331;
.reg .u64 %r332;
.reg .pred %r333;
.reg .u32 %r335;
.reg .u32 %r336;
.reg .u32 %r338;
.reg .u32 %r339;
.reg .u16 %r340;
.reg .u16 %r341;
.reg .u16 %r342;
.reg .u32 %r343;
.reg .u16 %r344;
.reg .pred %r345;
.reg .u64 %r346;
.reg .u64 %r347;
.reg .u64 %r348;
.reg .pred %r349;
.reg .u32 %r351;
.reg .u32 %r352;
.reg .u32 %r354;
.reg .u32 %r355;
.reg .u16 %r356;
.reg .u16 %r357;
.reg .u16 %r358;
.reg .u32 %r359;
.reg .u16 %r360;
.reg .pred %r361;
.reg .u64 %r362;
.reg .u64 %r363;
.reg .pred %r364;
.reg .u32 %r366;
.reg .u32 %r367;
.reg .u32 %r369;
.reg .u32 %r370;
.reg .u16 %r371;
.reg .u16 %r372;
.reg .u16 %r373;
.reg .u32 %r374;
.reg .u16 %r375;
.reg .pred %r376;
.reg .u64 %r377;
.reg .pred %r380;
.reg .u32 %r381;
.reg .u64 %r382;
.reg .pred %r383;
.reg .pred %r384;
.reg .u64 %r385;
.reg .u64 %r386;
.reg .u64 %r387;
.reg .u64 %r389;
.reg .pred %r390;
.reg .u32 %r392;
.reg .u32 %r393;
.reg .u32 %r395;
.reg .u32 %r396;
.reg .u16 %r397;
.reg .u16 %r398;
.reg .u16 %r399;
.reg .u32 %r400;
.reg .u16 %r401;
.reg .pred %r402;
.reg .u64 %r403;
.reg .u32 %r404;
.reg .u64 %r406;
.reg .u64 %r407;
.reg .u64 %r408;
.reg .u64 %r409;
.reg .pred %r410;
.reg .u32 %r412;
.reg .u32 %r413;
.reg .u32 %r415;
.reg .u32 %r416;
.reg .u16 %r417;
.reg .u16 %r418;
.reg .u16 %r419;
.reg .u32 %r420;
.reg .u16 %r421;
.reg .pred %r422;
.reg .u64 %r423;
.reg .u64 %r424;
.reg .pred %r425;
.reg .u32 %r427;
.reg .u32 %r428;
.reg .u32 %r430;
.reg .u32 %r431;
.reg .u16 %r432;
.reg .u16 %r433;
.reg .u16 %r434;
.reg .u32 %r435;
.reg .u16 %r436;
.reg .pred %r437;
.reg .u64 %r438;
.reg .u64 %r440;
.reg .pred %r441;
.reg .u64 %r442;
.reg .u64 %r444;
.reg .u64 %r445;
.reg .pred %r446;
.reg .u32 %r448;
.reg .u32 %r449;
.reg .u32 %r451;
.reg .u32 %r452;
.reg .u16 %r453;
.reg .u16 %r454;
.reg .u16 %r455;
.reg .u32 %r456;
.reg .u16 %r457;
.reg .pred %r458;
.reg .u64 %r459;
.reg .u32 %r460;
.reg .u64 %r462;
.reg .u64 %r463;
.reg .u64 %r464;
.reg .u32 %r465;
.reg .u64 %r467;
.reg .u64 %r468;
.reg .pred %r471;
.reg .u64 %r477;
.reg .u32 %r479;
.reg .pred %r484;
.reg .u64 %r490;
.reg .u32 %r492;
.reg .u64 %r501;
.reg .u64 %r502;
.reg .u64 %r503;
.reg .u64 %r504;
.reg .u64 %r505;
.reg .u64 %r507;
.reg .u64 %r508;
mov.u64 %r224,%ar0;
mov.u64 %r225,%ar1;
ld.u64 %r505,[%r225];
mov.u64 %r227,%ar2;
ld.u64 %r507,[%r227];
ld.u64 %r508,[%r227+8];
mov.u64 %r229,%ar3;
ld.u64 %r36,[%r225+8];
.loc 1 1286 6
setp.ge.s64 %r230,%r36,0;
@ %r230 bra $L34;
.loc 1 1288 13
set.u32.ne.u64 %r238,%r505,0;
cvt.s64.s32 %r236,%r238;
neg.s64 %r505,%r505;
sub.u64 %r36,%r236,%r36;
.loc 1 1287 8
mov.u64 %r22,-1;
bra $L2;
$L34:
.loc 1 1280 9
mov.u64 %r22,0;
$L2:
mov.u64 %r25,%r508;
.loc 1 1289 6
setp.ge.s64 %r243,%r25,0;
@ %r243 bra $L35;
.loc 1 1290 8
not.b64 %r23,%r22;
.loc 1 1291 13
set.u32.ne.u64 %r251,%r507,0;
cvt.s64.s32 %r249,%r251;
neg.s64 %r507,%r507;
sub.u64 %r25,%r249,%r25;
bra $L3;
$L35:
mov.u64 %r23,%r22;
$L3:
.loc 1 1024 6
mov.u64 %r27,%r507;
.loc 1 1026 6
mov.u64 %r30,%r505;
.loc 1 1027 6
mov.u64 %r31,%r36;
.loc 1 1064 6
setp.ne.u64 %r256,%r25,0;
@ %r256 bra $L4;
.loc 1 1066 10
setp.le.u64 %r257,%r507,%r36;
@ %r257 bra $L5;
.loc 1 1070 4
mov.u64 %r35,56;
$L7:
cvt.u32.u64 %r258,%r35;
shr.u64 %r33,%r507,%r258;
and.b64 %r259,%r33,255;
setp.ne.u64 %r260,%r259,0;
@ %r260 bra $L6;
add.u64 %r35,%r35,-8;
setp.ne.u64 %r261,%r35,0;
@ %r261 bra $L7;
mov.u64 %r33,%r507;
mov.u64 %r220,64;
bra $L8;
$L6:
mov.u64 %r262,64;
sub.u64 %r220,%r262,%r35;
$L8:
cvta.const.u64 %r263,__clz_tab;
add.u64 %r264,%r263,%r33;
ld.u8 %r265,[%r264];
sub.u64 %r39,%r220,%r265;
.loc 1 1072 7
setp.eq.u64 %r267,%r220,%r265;
@ %r267 bra $L36;
.loc 1 1077 16
cvt.u32.u64 %r221,%r39;
.loc 1 1077 11
shl.b64 %r27,%r507,%r221;
.loc 1 1078 17
shl.b64 %r40,%r36,%r221;
.loc 1 1078 46
mov.u32 %r269,64;
sub.u32 %r268,%r269,%r221;
.loc 1 1078 30
shr.u64 %r270,%r505,%r268;
.loc 1 1078 11
or.b64 %r31,%r270,%r40;
.loc 1 1079 11
shl.b64 %r30,%r505,%r221;
bra $L9;
$L36:
cvt.u32.u64 %r221,%r39;
$L9:
.loc 1 1082 4
shr.u64 %r43,%r27,32;
and.b64 %r44,%r27,4294967295;
rem.u64 %r45,%r31,%r43;
div.u64 %r46,%r31,%r43;
mul.lo.u64 %r47,%r44,%r46;
shl.b64 %r271,%r45,32;
shr.u64 %r272,%r30,32;
or.b64 %r50,%r271,%r272;
setp.le.u64 %r273,%r47,%r50;
@ %r273 bra $L10;
add.u64 %r51,%r46,-1;
add.u64 %r50,%r50,%r27;
set.u32.le.u64 %r275,%r27,%r50;
neg.s32 %r276,%r275;
set.u32.gt.u64 %r278,%r47,%r50;
neg.s32 %r279,%r278;
cvt.u16.u32 %r281,%r276;
cvt.u16.u32 %r282,%r279;
and.b16 %r280,%r281,%r282;
cvt.u32.u16 %r283,%r280;
cvt.u16.u8 %r284,%r283;
setp.eq.u16 %r285,%r284,0;
@ %r285 bra $L37;
add.u64 %r46,%r46,-2;
add.u64 %r50,%r50,%r27;
bra $L10;
$L37:
mov.u64 %r46,%r51;
$L10:
sub.u64 %r52,%r50,%r47;
rem.u64 %r53,%r52,%r43;
div.u64 %r54,%r52,%r43;
mul.lo.u64 %r55,%r44,%r54;
shl.b64 %r286,%r53,32;
and.b64 %r287,%r30,4294967295;
or.b64 %r58,%r286,%r287;
setp.le.u64 %r288,%r55,%r58;
@ %r288 bra $L11;
add.u64 %r59,%r54,-1;
add.u64 %r58,%r58,%r27;
set.u32.gt.u64 %r290,%r55,%r58;
neg.s32 %r291,%r290;
set.u32.le.u64 %r293,%r27,%r58;
neg.s32 %r294,%r293;
cvt.u16.u32 %r296,%r291;
cvt.u16.u32 %r297,%r294;
and.b16 %r295,%r296,%r297;
cvt.u32.u16 %r298,%r295;
cvt.u16.u8 %r299,%r298;
setp.eq.u16 %r300,%r299,0;
@ %r300 bra $L38;
add.u64 %r54,%r54,-2;
add.u64 %r58,%r58,%r27;
bra $L11;
$L38:
mov.u64 %r54,%r59;
$L11:
sub.u64 %r60,%r58,%r55;
shl.b64 %r301,%r46,32;
or.b64 %r62,%r301,%r54;
mov.u64 %r222,0;
bra $L12;
$L5:
.loc 1 1091 7
setp.ne.u64 %r302,%r27,0;
@ %r302 bra $L13;
.loc 1 1092 9
mov.u64 %r303,1;
div.u64 %r27,%r303,0;
$L13:
.loc 1 1094 4
mov.u64 %r66,56;
$L15:
cvt.u32.u64 %r305,%r66;
shr.u64 %r64,%r27,%r305;
and.b64 %r306,%r64,255;
setp.ne.u64 %r307,%r306,0;
@ %r307 bra $L14;
add.u64 %r66,%r66,-8;
setp.ne.u64 %r308,%r66,0;
@ %r308 bra $L15;
mov.u64 %r64,%r27;
$L14:
cvta.const.u64 %r309,__clz_tab;
add.u64 %r310,%r309,%r64;
ld.u8 %r311,[%r310];
add.u64 %r69,%r311,%r66;
mov.u64 %r313,64;
sub.u64 %r70,%r313,%r69;
.loc 1 1096 7
setp.ne.u64 %r314,%r313,%r69;
@ %r314 bra $L16;
.loc 1 1105 11
sub.u64 %r71,%r36,%r27;
.loc 1 1124 4
shr.u64 %r194,%r27,32;
and.b64 %r219,%r27,4294967295;
mov.u64 %r222,1;
cvt.u32.u64 %r221,%r70;
bra $L17;
$L16:
.loc 1 1114 16
cvt.u32.u64 %r221,%r70;
.loc 1 1114 11
shl.b64 %r27,%r27,%r221;
.loc 1 1115 16
cvt.u32.u64 %r72,%r69;
.loc 1 1115 11
shr.u64 %r73,%r36,%r72;
.loc 1 1116 17
shl.b64 %r74,%r36,%r221;
.loc 1 1116 30
shr.u64 %r315,%r505,%r72;
.loc 1 1116 11
or.b64 %r76,%r315,%r74;
.loc 1 1117 11
shl.b64 %r30,%r505,%r221;
.loc 1 1119 8
shr.u64 %r194,%r27,32;
and.b64 %r219,%r27,4294967295;
rem.u64 %r77,%r73,%r194;
div.u64 %r78,%r73,%r194;
mul.lo.u64 %r79,%r219,%r78;
shl.b64 %r316,%r77,32;
shr.u64 %r317,%r76,32;
or.b64 %r82,%r316,%r317;
setp.le.u64 %r318,%r79,%r82;
@ %r318 bra $L18;
add.u64 %r83,%r78,-1;
add.u64 %r82,%r82,%r27;
set.u32.le.u64 %r320,%r27,%r82;
neg.s32 %r321,%r320;
set.u32.gt.u64 %r323,%r79,%r82;
neg.s32 %r324,%r323;
cvt.u16.u32 %r326,%r321;
cvt.u16.u32 %r327,%r324;
and.b16 %r325,%r326,%r327;
cvt.u32.u16 %r328,%r325;
cvt.u16.u8 %r329,%r328;
setp.eq.u16 %r330,%r329,0;
@ %r330 bra $L39;
add.u64 %r78,%r78,-2;
add.u64 %r82,%r82,%r27;
bra $L18;
$L39:
mov.u64 %r78,%r83;
$L18:
sub.u64 %r84,%r82,%r79;
rem.u64 %r85,%r84,%r194;
div.u64 %r86,%r84,%r194;
mul.lo.u64 %r87,%r219,%r86;
shl.b64 %r331,%r85,32;
and.b64 %r332,%r76,4294967295;
or.b64 %r90,%r331,%r332;
setp.le.u64 %r333,%r87,%r90;
@ %r333 bra $L19;
add.u64 %r91,%r86,-1;
add.u64 %r90,%r90,%r27;
set.u32.gt.u64 %r335,%r87,%r90;
neg.s32 %r336,%r335;
set.u32.le.u64 %r338,%r27,%r90;
neg.s32 %r339,%r338;
cvt.u16.u32 %r341,%r336;
cvt.u16.u32 %r342,%r339;
and.b16 %r340,%r341,%r342;
cvt.u32.u16 %r343,%r340;
cvt.u16.u8 %r344,%r343;
setp.eq.u16 %r345,%r344,0;
@ %r345 bra $L40;
add.u64 %r86,%r86,-2;
add.u64 %r90,%r90,%r27;
bra $L19;
$L40:
mov.u64 %r86,%r91;
$L19:
sub.u64 %r71,%r90,%r87;
shl.b64 %r346,%r78,32;
or.b64 %r222,%r346,%r86;
$L17:
.loc 1 1124 4
rem.u64 %r94,%r71,%r194;
div.u64 %r95,%r71,%r194;
mul.lo.u64 %r96,%r95,%r219;
shl.b64 %r347,%r94,32;
shr.u64 %r348,%r30,32;
or.b64 %r99,%r347,%r348;
setp.le.u64 %r349,%r96,%r99;
@ %r349 bra $L20;
add.u64 %r100,%r95,-1;
add.u64 %r99,%r99,%r27;
set.u32.le.u64 %r351,%r27,%r99;
neg.s32 %r352,%r351;
set.u32.gt.u64 %r354,%r96,%r99;
neg.s32 %r355,%r354;
cvt.u16.u32 %r357,%r352;
cvt.u16.u32 %r358,%r355;
and.b16 %r356,%r357,%r358;
cvt.u32.u16 %r359,%r356;
cvt.u16.u8 %r360,%r359;
setp.eq.u16 %r361,%r360,0;
@ %r361 bra $L41;
add.u64 %r95,%r95,-2;
add.u64 %r99,%r99,%r27;
bra $L20;
$L41:
mov.u64 %r95,%r100;
$L20:
sub.u64 %r101,%r99,%r96;
rem.u64 %r102,%r101,%r194;
div.u64 %r103,%r101,%r194;
mul.lo.u64 %r104,%r103,%r219;
shl.b64 %r362,%r102,32;
and.b64 %r363,%r30,4294967295;
or.b64 %r107,%r362,%r363;
setp.le.u64 %r364,%r104,%r107;
@ %r364 bra $L21;
add.u64 %r108,%r103,-1;
add.u64 %r107,%r107,%r27;
set.u32.le.u64 %r366,%r27,%r107;
neg.s32 %r367,%r366;
set.u32.gt.u64 %r369,%r104,%r107;
neg.s32 %r370,%r369;
cvt.u16.u32 %r372,%r367;
cvt.u16.u32 %r373,%r370;
and.b16 %r371,%r372,%r373;
cvt.u32.u16 %r374,%r371;
cvt.u16.u8 %r375,%r374;
setp.eq.u16 %r376,%r375,0;
@ %r376 bra $L42;
add.u64 %r103,%r103,-2;
add.u64 %r107,%r107,%r27;
bra $L21;
$L42:
mov.u64 %r103,%r108;
$L21:
sub.u64 %r60,%r107,%r104;
shl.b64 %r377,%r95,32;
or.b64 %r62,%r377,%r103;
$L12:
.loc 1 1133 12
shr.u64 %r503,%r60,%r221;
mov.u64 %r504,0;
.loc 1 1223 17
mov.u64 %r223,%r62;
bra $L22;
$L4:
mov.u64 %r29,%r505;
.loc 1 1140 10
setp.le.u64 %r380,%r25,%r36;
@ %r380 bra $L43;
.loc 1 1152 16
mov.u64 %r503,%r505;
mov.u64 %r504,%r36;
mov.u64 %r222,0;
mov.u64 %r223,%r222;
bra $L22;
$L43:
.loc 1 1159 4
mov.u64 %r115,56;
$L23:
cvt.u32.u64 %r381,%r115;
shr.u64 %r113,%r25,%r381;
and.b64 %r382,%r113,255;
setp.ne.u64 %r383,%r382,0;
@ %r383 bra $L24;
add.u64 %r115,%r115,-8;
setp.ne.u64 %r384,%r115,0;
@ %r384 bra $L23;
mov.u64 %r113,%r25;
$L24:
cvta.const.u64 %r385,__clz_tab;
add.u64 %r386,%r385,%r113;
ld.u8 %r387,[%r386];
add.u64 %r118,%r387,%r115;
mov.u64 %r389,64;
sub.u64 %r119,%r389,%r118;
.loc 1 1160 7
setp.ne.u64 %r390,%r389,%r118;
@ %r390 bra $L25;
.loc 1 1170 15
set.u32.lt.u64 %r392,%r25,%r36;
neg.s32 %r393,%r392;
.loc 1 1170 26
set.u32.le.u64 %r395,%r507,%r505;
neg.s32 %r396,%r395;
.loc 1 1170 20
cvt.u16.u32 %r398,%r393;
cvt.u16.u32 %r399,%r396;
or.b16 %r397,%r398,%r399;
.loc 1 1170 11
cvt.u32.u16 %r400,%r397;
cvt.u16.u8 %r401,%r400;
setp.eq.u16 %r402,%r401,0;
@ %r402 bra $L44;
.loc 1 1173 5
sub.u64 %r124,%r36,%r25;
.loc 1 1182 14
sub.u64 %r29,%r505,%r507;
.loc 1 1173 5
set.u32.lt.u64 %r404,%r505,%r29;
cvt.s64.s32 %r403,%r404;
add.u64 %r36,%r124,%r403;
mov.u64 %r223,1;
bra $L26;
$L44:
mov.u64 %r223,%r119;
$L26:
.loc 1 1184 13
mov.u64 %r503,%r29;
mov.u64 %r504,%r36;
mov.u64 %r222,0;
bra $L22;
$L25:
.loc 1 1194 17
cvt.u32.u64 %r128,%r119;
shl.b64 %r129,%r25,%r128;
.loc 1 1194 30
cvt.u32.u64 %r130,%r118;
shr.u64 %r406,%r507,%r130;
.loc 1 1194 11
or.b64 %r132,%r406,%r129;
.loc 1 1195 11
shl.b64 %r133,%r507,%r128;
.loc 1 1196 11
shr.u64 %r134,%r36,%r130;
.loc 1 1197 17
shl.b64 %r135,%r36,%r128;
.loc 1 1197 30
shr.u64 %r407,%r505,%r130;
.loc 1 1197 11
or.b64 %r137,%r407,%r135;
.loc 1 1198 11
shl.b64 %r138,%r505,%r128;
.loc 1 1200 8
shr.u64 %r139,%r132,32;
and.b64 %r140,%r132,4294967295;
rem.u64 %r141,%r134,%r139;
div.u64 %r142,%r134,%r139;
mul.lo.u64 %r143,%r140,%r142;
shl.b64 %r408,%r141,32;
shr.u64 %r409,%r137,32;
or.b64 %r146,%r408,%r409;
setp.le.u64 %r410,%r143,%r146;
@ %r410 bra $L27;
add.u64 %r147,%r142,-1;
add.u64 %r146,%r146,%r132;
set.u32.le.u64 %r412,%r132,%r146;
neg.s32 %r413,%r412;
set.u32.gt.u64 %r415,%r143,%r146;
neg.s32 %r416,%r415;
cvt.u16.u32 %r418,%r413;
cvt.u16.u32 %r419,%r416;
and.b16 %r417,%r418,%r419;
cvt.u32.u16 %r420,%r417;
cvt.u16.u8 %r421,%r420;
setp.eq.u16 %r422,%r421,0;
@ %r422 bra $L45;
add.u64 %r142,%r142,-2;
add.u64 %r146,%r146,%r132;
bra $L27;
$L45:
mov.u64 %r142,%r147;
$L27:
sub.u64 %r148,%r146,%r143;
rem.u64 %r149,%r148,%r139;
div.u64 %r150,%r148,%r139;
mul.lo.u64 %r151,%r140,%r150;
shl.b64 %r423,%r149,32;
and.b64 %r424,%r137,4294967295;
or.b64 %r154,%r423,%r424;
setp.le.u64 %r425,%r151,%r154;
@ %r425 bra $L28;
add.u64 %r155,%r150,-1;
add.u64 %r154,%r154,%r132;
set.u32.gt.u64 %r427,%r151,%r154;
neg.s32 %r428,%r427;
set.u32.le.u64 %r430,%r132,%r154;
neg.s32 %r431,%r430;
cvt.u16.u32 %r433,%r428;
cvt.u16.u32 %r434,%r431;
and.b16 %r432,%r433,%r434;
cvt.u32.u16 %r435,%r432;
cvt.u16.u8 %r436,%r435;
setp.eq.u16 %r437,%r436,0;
@ %r437 bra $L46;
add.u64 %r150,%r150,-2;
add.u64 %r154,%r154,%r132;
bra $L28;
$L46:
mov.u64 %r150,%r155;
$L28:
sub.u64 %r156,%r154,%r151;
shl.b64 %r438,%r142,32;
or.b64 %r176,%r438,%r150;
.loc 1 1201 8
and.b64 %r158,%r150,4294967295;
shr.u64 %r159,%r176,32;
and.b64 %r160,%r133,4294967295;
shr.u64 %r161,%r133,32;
mul.lo.u64 %r162,%r158,%r160;
mul.lo.u64 %r164,%r159,%r160;
mul.lo.u64 %r165,%r159,%r161;
mad.lo.u64 %r26,%r158,%r161,%r164;
shr.u64 %r440,%r162,32;
add.u64 %r167,%r440,%r26;
setp.le.u64 %r441,%r164,%r167;
@ %r441 bra $L29;
add.u64 %r165,%r165,4294967296;
$L29:
shr.u64 %r442,%r167,32;
add.u64 %r180,%r442,%r165;
shl.b64 %r444,%r167,32;
and.b64 %r445,%r162,4294967295;
add.u64 %r172,%r444,%r445;
.loc 1 1203 11
setp.lt.u64 %r446,%r156,%r180;
@ %r446 bra $L30;
.loc 1 1203 27
set.u32.eq.u64 %r448,%r156,%r180;
neg.s32 %r449,%r448;
.loc 1 1203 39
set.u32.lt.u64 %r451,%r138,%r172;
neg.s32 %r452,%r451;
.loc 1 1203 33
cvt.u16.u32 %r454,%r449;
cvt.u16.u32 %r455,%r452;
and.b16 %r453,%r454,%r455;
.loc 1 1203 20
cvt.u32.u16 %r456,%r453;
cvt.u16.u8 %r457,%r456;
setp.eq.u16 %r458,%r457,0;
@ %r458 bra $L47;
$L30:
.loc 1 1205 7
add.u64 %r176,%r176,-1;
.loc 1 1206 5
sub.u64 %r177,%r172,%r133;
set.u32.lt.u64 %r460,%r172,%r177;
cvt.s64.s32 %r459,%r460;
sub.u64 %r462,%r132,%r459;
sub.u64 %r180,%r180,%r462;
bra $L31;
$L47:
.loc 1 1201 8
mov.u64 %r177,%r172;
$L31:
.loc 1 1214 5
sub.u64 %r181,%r138,%r177;
sub.u64 %r463,%r156,%r180;
set.u32.lt.u64 %r465,%r138,%r181;
cvt.s64.s32 %r464,%r465;
add.u64 %r185,%r463,%r464;
.loc 1 1215 20
shl.b64 %r467,%r185,%r130;
.loc 1 1215 32
shr.u64 %r468,%r181,%r128;
.loc 1 1217 13
or.b64 %r503,%r467,%r468;
shr.u64 %r504,%r185,%r128;
.loc 1 1223 17
mov.u64 %r223,%r176;
mov.u64 %r222,0;
$L22:
.loc 1 1224 12
mov.u64 %r501,%r223;
mov.u64 %r502,%r222;
.loc 1 1294 6
setp.eq.u64 %r471,%r23,0;
@ %r471 bra $L32;
.loc 1 1295 7
set.u32.ne.u64 %r479,%r501,0;
cvt.s64.s32 %r477,%r479;
neg.s64 %r501,%r501;
sub.u64 %r502,%r477,%r502;
$L32:
.loc 1 1296 6
setp.eq.u64 %r484,%r22,0;
@ %r484 bra $L33;
.loc 1 1297 9
set.u32.ne.u64 %r492,%r503,0;
cvt.s64.s32 %r490,%r492;
neg.s64 %r503,%r503;
sub.u64 %r504,%r490,%r504;
$L33:
.loc 1 1299 7
st.u64 [%r229],%r503;
st.u64 [%r229+8],%r504;
.loc 1 1300 10
st.u64 [%r224],%r501;
st.u64 [%r224+8],%r502;
.loc 1 1301 1
ret;
}
_udivdi3.o/     1608280949  0     0     100666  16711     `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __udivti3
.visible .func __udivti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __udivti3
.visible .func __udivti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,16;
sub.u64 %stack,%frame,0;
}
.reg .u64 %r24;
.reg .u64 %r27;
.reg .u64 %r29;
.reg .u64 %r31;
.reg .u64 %r33;
.reg .u64 %r36;
.reg .u32 %r37;
.reg .u64 %r38;
.reg .u64 %r41;
.reg .u64 %r42;
.reg .u64 %r43;
.reg .u64 %r44;
.reg .u64 %r45;
.reg .u64 %r48;
.reg .u64 %r49;
.reg .u64 %r50;
.reg .u64 %r51;
.reg .u64 %r52;
.reg .u64 %r53;
.reg .u64 %r56;
.reg .u64 %r57;
.reg .u64 %r58;
.reg .u64 %r62;
.reg .u64 %r64;
.reg .u64 %r67;
.reg .u64 %r68;
.reg .u64 %r69;
.reg .u32 %r70;
.reg .u32 %r71;
.reg .u64 %r72;
.reg .u64 %r73;
.reg .u64 %r75;
.reg .u64 %r76;
.reg .u64 %r77;
.reg .u64 %r78;
.reg .u64 %r81;
.reg .u64 %r82;
.reg .u64 %r83;
.reg .u64 %r84;
.reg .u64 %r85;
.reg .u64 %r86;
.reg .u64 %r89;
.reg .u64 %r90;
.reg .u64 %r93;
.reg .u64 %r94;
.reg .u64 %r95;
.reg .u64 %r98;
.reg .u64 %r99;
.reg .u64 %r100;
.reg .u64 %r101;
.reg .u64 %r102;
.reg .u64 %r103;
.reg .u64 %r106;
.reg .u64 %r107;
.reg .u64 %r108;
.reg .u64 %r112;
.reg .u64 %r114;
.reg .u64 %r117;
.reg .u64 %r118;
.reg .u32 %r122;
.reg .u64 %r123;
.reg .u32 %r124;
.reg .u64 %r126;
.reg .u64 %r127;
.reg .u64 %r128;
.reg .u64 %r129;
.reg .u64 %r131;
.reg .u64 %r133;
.reg .u64 %r134;
.reg .u64 %r135;
.reg .u64 %r136;
.reg .u64 %r137;
.reg .u64 %r140;
.reg .u64 %r141;
.reg .u64 %r142;
.reg .u64 %r143;
.reg .u64 %r144;
.reg .u64 %r145;
.reg .u64 %r148;
.reg .u64 %r149;
.reg .u64 %r150;
.reg .u64 %r152;
.reg .u64 %r153;
.reg .u64 %r154;
.reg .u64 %r155;
.reg .u64 %r156;
.reg .u64 %r157;
.reg .u64 %r159;
.reg .u64 %r160;
.reg .u64 %r162;
.reg .u64 %r164;
.reg .u64 %r175;
.reg .u64 %r176;
.reg .u64 %r177;
.reg .u64 %r178;
.reg .u64 %r179;
.reg .u64 %r182;
.reg .u64 %r205;
.reg .u64 %r206;
.reg .u64 %r208;
.reg .pred %r210;
.reg .pred %r211;
.reg .u32 %r212;
.reg .u64 %r213;
.reg .pred %r214;
.reg .pred %r215;
.reg .u64 %r216;
.reg .u64 %r217;
.reg .u64 %r218;
.reg .u64 %r219;
.reg .pred %r221;
.reg .u32 %r222;
.reg .u32 %r223;
.reg .u64 %r224;
.reg .u64 %r225;
.reg .u64 %r226;
.reg .pred %r227;
.reg .u32 %r229;
.reg .u32 %r230;
.reg .u32 %r232;
.reg .u32 %r233;
.reg .u16 %r234;
.reg .u16 %r235;
.reg .u16 %r236;
.reg .u32 %r237;
.reg .u16 %r238;
.reg .pred %r239;
.reg .u64 %r240;
.reg .u64 %r241;
.reg .pred %r242;
.reg .u32 %r244;
.reg .u32 %r245;
.reg .u32 %r247;
.reg .u32 %r248;
.reg .u16 %r249;
.reg .u16 %r250;
.reg .u16 %r251;
.reg .u32 %r252;
.reg .u16 %r253;
.reg .pred %r254;
.reg .u64 %r255;
.reg .pred %r256;
.reg .u64 %r257;
.reg .u32 %r259;
.reg .u64 %r260;
.reg .pred %r261;
.reg .pred %r262;
.reg .u64 %r263;
.reg .u64 %r264;
.reg .u64 %r265;
.reg .u64 %r267;
.reg .pred %r268;
.reg .u64 %r269;
.reg .u64 %r270;
.reg .u64 %r271;
.reg .pred %r272;
.reg .u32 %r274;
.reg .u32 %r275;
.reg .u32 %r277;
.reg .u32 %r278;
.reg .u16 %r279;
.reg .u16 %r280;
.reg .u16 %r281;
.reg .u32 %r282;
.reg .u16 %r283;
.reg .pred %r284;
.reg .u64 %r285;
.reg .u64 %r286;
.reg .pred %r287;
.reg .u32 %r289;
.reg .u32 %r290;
.reg .u32 %r292;
.reg .u32 %r293;
.reg .u16 %r294;
.reg .u16 %r295;
.reg .u16 %r296;
.reg .u32 %r297;
.reg .u16 %r298;
.reg .pred %r299;
.reg .u64 %r300;
.reg .u64 %r301;
.reg .u64 %r302;
.reg .pred %r303;
.reg .u32 %r305;
.reg .u32 %r306;
.reg .u32 %r308;
.reg .u32 %r309;
.reg .u16 %r310;
.reg .u16 %r311;
.reg .u16 %r312;
.reg .u32 %r313;
.reg .u16 %r314;
.reg .pred %r315;
.reg .u64 %r316;
.reg .u64 %r317;
.reg .pred %r318;
.reg .u32 %r320;
.reg .u32 %r321;
.reg .u32 %r323;
.reg .u32 %r324;
.reg .u16 %r325;
.reg .u16 %r326;
.reg .u16 %r327;
.reg .u32 %r328;
.reg .u16 %r329;
.reg .pred %r330;
.reg .u64 %r331;
.reg .pred %r332;
.reg .u32 %r333;
.reg .u64 %r334;
.reg .pred %r335;
.reg .pred %r336;
.reg .u64 %r337;
.reg .u64 %r338;
.reg .u64 %r339;
.reg .u64 %r341;
.reg .pred %r342;
.reg .u32 %r344;
.reg .u32 %r345;
.reg .u32 %r347;
.reg .u32 %r348;
.reg .u16 %r349;
.reg .u16 %r350;
.reg .u16 %r351;
.reg .u32 %r352;
.reg .u64 %r353;
.reg .u64 %r354;
.reg .u64 %r355;
.reg .u64 %r356;
.reg .pred %r357;
.reg .u32 %r359;
.reg .u32 %r360;
.reg .u32 %r362;
.reg .u32 %r363;
.reg .u16 %r364;
.reg .u16 %r365;
.reg .u16 %r366;
.reg .u32 %r367;
.reg .u16 %r368;
.reg .pred %r369;
.reg .u64 %r370;
.reg .u64 %r371;
.reg .pred %r372;
.reg .u32 %r374;
.reg .u32 %r375;
.reg .u32 %r377;
.reg .u32 %r378;
.reg .u16 %r379;
.reg .u16 %r380;
.reg .u16 %r381;
.reg .u32 %r382;
.reg .u16 %r383;
.reg .pred %r384;
.reg .u64 %r385;
.reg .u64 %r387;
.reg .pred %r388;
.reg .u64 %r389;
.reg .pred %r390;
.reg .u64 %r391;
.reg .u64 %r393;
.reg .u64 %r394;
.reg .u64 %r395;
.reg .u32 %r397;
.reg .u32 %r398;
.reg .u32 %r400;
.reg .u32 %r401;
.reg .u16 %r402;
.reg .u16 %r403;
.reg .u16 %r404;
.reg .u32 %r405;
.reg .u16 %r406;
.reg .pred %r407;
.reg .u64 %r412;
.reg .u64 %r413;
.reg .u64 %r414;
.reg .u64 %r415;
mov.u64 %r205,%ar0;
mov.u64 %r206,%ar1;
ld.u64 %r412,[%r206];
ld.u64 %r413,[%r206+8];
mov.u64 %r208,%ar2;
ld.u64 %r414,[%r208];
ld.u64 %r415,[%r208+8];
.loc 1 1024 6
mov.u64 %r24,%r414;
.loc 1 1026 6
mov.u64 %r27,%r412;
.loc 1 1027 6
mov.u64 %r29,%r413;
.loc 1 1064 6
setp.ne.u64 %r210,%r415,0;
@ %r210 bra $L2;
.loc 1 1066 10
setp.le.u64 %r211,%r414,%r413;
@ %r211 bra $L3;
.loc 1 1070 4
mov.u64 %r33,56;
$L5:
cvt.u32.u64 %r212,%r33;
shr.u64 %r31,%r414,%r212;
and.b64 %r213,%r31,255;
setp.ne.u64 %r214,%r213,0;
@ %r214 bra $L4;
add.u64 %r33,%r33,-8;
setp.ne.u64 %r215,%r33,0;
@ %r215 bra $L5;
mov.u64 %r31,%r414;
mov.u64 %r176,64;
bra $L6;
$L4:
mov.u64 %r216,64;
sub.u64 %r176,%r216,%r33;
$L6:
cvta.const.u64 %r217,__clz_tab;
add.u64 %r218,%r217,%r31;
ld.u8 %r219,[%r218];
sub.u64 %r36,%r176,%r219;
.loc 1 1072 7
setp.eq.u64 %r221,%r176,%r219;
@ %r221 bra $L7;
.loc 1 1077 16
cvt.u32.u64 %r37,%r36;
.loc 1 1077 11
shl.b64 %r24,%r414,%r37;
.loc 1 1078 17
shl.b64 %r38,%r413,%r37;
.loc 1 1078 46
mov.u32 %r223,64;
sub.u32 %r222,%r223,%r37;
.loc 1 1078 30
shr.u64 %r224,%r412,%r222;
.loc 1 1078 11
or.b64 %r29,%r224,%r38;
.loc 1 1079 11
shl.b64 %r27,%r412,%r37;
$L7:
.loc 1 1082 4
shr.u64 %r41,%r24,32;
and.b64 %r42,%r24,4294967295;
rem.u64 %r43,%r29,%r41;
div.u64 %r44,%r29,%r41;
mul.lo.u64 %r45,%r42,%r44;
shl.b64 %r225,%r43,32;
shr.u64 %r226,%r27,32;
or.b64 %r48,%r225,%r226;
setp.le.u64 %r227,%r45,%r48;
@ %r227 bra $L8;
add.u64 %r49,%r44,-1;
add.u64 %r48,%r48,%r24;
set.u32.le.u64 %r229,%r24,%r48;
neg.s32 %r230,%r229;
set.u32.gt.u64 %r232,%r45,%r48;
neg.s32 %r233,%r232;
cvt.u16.u32 %r235,%r230;
cvt.u16.u32 %r236,%r233;
and.b16 %r234,%r235,%r236;
cvt.u32.u16 %r237,%r234;
cvt.u16.u8 %r238,%r237;
setp.eq.u16 %r239,%r238,0;
@ %r239 bra $L27;
add.u64 %r44,%r44,-2;
add.u64 %r48,%r48,%r24;
bra $L8;
$L27:
mov.u64 %r44,%r49;
$L8:
sub.u64 %r50,%r48,%r45;
rem.u64 %r51,%r50,%r41;
div.u64 %r52,%r50,%r41;
mul.lo.u64 %r53,%r42,%r52;
shl.b64 %r240,%r51,32;
and.b64 %r241,%r27,4294967295;
or.b64 %r56,%r240,%r241;
setp.le.u64 %r242,%r53,%r56;
@ %r242 bra $L9;
add.u64 %r57,%r52,-1;
add.u64 %r58,%r24,%r56;
set.u32.gt.u64 %r244,%r53,%r58;
neg.s32 %r245,%r244;
set.u32.le.u64 %r247,%r24,%r58;
neg.s32 %r248,%r247;
cvt.u16.u32 %r250,%r245;
cvt.u16.u32 %r251,%r248;
and.b16 %r249,%r250,%r251;
cvt.u32.u16 %r252,%r249;
cvt.u16.u8 %r253,%r252;
setp.eq.u16 %r254,%r253,0;
@ %r254 bra $L28;
add.u64 %r52,%r52,-2;
bra $L9;
$L28:
mov.u64 %r52,%r57;
$L9:
shl.b64 %r255,%r44,32;
or.b64 %r175,%r255,%r52;
mov.u64 %r178,0;
bra $L10;
$L3:
.loc 1 1091 7
setp.ne.u64 %r256,%r24,0;
@ %r256 bra $L11;
.loc 1 1092 9
mov.u64 %r257,1;
div.u64 %r24,%r257,0;
$L11:
.loc 1 1094 4
mov.u64 %r64,56;
$L13:
cvt.u32.u64 %r259,%r64;
shr.u64 %r62,%r24,%r259;
and.b64 %r260,%r62,255;
setp.ne.u64 %r261,%r260,0;
@ %r261 bra $L12;
add.u64 %r64,%r64,-8;
setp.ne.u64 %r262,%r64,0;
@ %r262 bra $L13;
mov.u64 %r62,%r24;
$L12:
cvta.const.u64 %r263,__clz_tab;
add.u64 %r264,%r263,%r62;
ld.u8 %r265,[%r264];
add.u64 %r67,%r265,%r64;
mov.u64 %r267,64;
sub.u64 %r68,%r267,%r67;
.loc 1 1096 7
setp.ne.u64 %r268,%r267,%r67;
@ %r268 bra $L14;
.loc 1 1105 11
sub.u64 %r69,%r413,%r24;
.loc 1 1124 4
shr.u64 %r179,%r24,32;
and.b64 %r177,%r24,4294967295;
mov.u64 %r178,1;
bra $L15;
$L14:
.loc 1 1114 16
cvt.u32.u64 %r70,%r68;
.loc 1 1114 11
shl.b64 %r24,%r24,%r70;
.loc 1 1115 16
cvt.u32.u64 %r71,%r67;
.loc 1 1115 11
shr.u64 %r72,%r413,%r71;
.loc 1 1116 17
shl.b64 %r73,%r413,%r70;
.loc 1 1116 30
shr.u64 %r269,%r412,%r71;
.loc 1 1116 11
or.b64 %r75,%r269,%r73;
.loc 1 1117 11
shl.b64 %r27,%r412,%r70;
.loc 1 1119 8
shr.u64 %r179,%r24,32;
and.b64 %r177,%r24,4294967295;
rem.u64 %r76,%r72,%r179;
div.u64 %r77,%r72,%r179;
mul.lo.u64 %r78,%r177,%r77;
shl.b64 %r270,%r76,32;
shr.u64 %r271,%r75,32;
or.b64 %r81,%r270,%r271;
setp.le.u64 %r272,%r78,%r81;
@ %r272 bra $L16;
add.u64 %r82,%r77,-1;
add.u64 %r81,%r81,%r24;
set.u32.le.u64 %r274,%r24,%r81;
neg.s32 %r275,%r274;
set.u32.gt.u64 %r277,%r78,%r81;
neg.s32 %r278,%r277;
cvt.u16.u32 %r280,%r275;
cvt.u16.u32 %r281,%r278;
and.b16 %r279,%r280,%r281;
cvt.u32.u16 %r282,%r279;
cvt.u16.u8 %r283,%r282;
setp.eq.u16 %r284,%r283,0;
@ %r284 bra $L29;
add.u64 %r77,%r77,-2;
add.u64 %r81,%r81,%r24;
bra $L16;
$L29:
mov.u64 %r77,%r82;
$L16:
sub.u64 %r83,%r81,%r78;
rem.u64 %r84,%r83,%r179;
div.u64 %r85,%r83,%r179;
mul.lo.u64 %r86,%r177,%r85;
shl.b64 %r285,%r84,32;
and.b64 %r286,%r75,4294967295;
or.b64 %r89,%r285,%r286;
setp.le.u64 %r287,%r86,%r89;
@ %r287 bra $L17;
add.u64 %r90,%r85,-1;
add.u64 %r89,%r89,%r24;
set.u32.le.u64 %r289,%r24,%r89;
neg.s32 %r290,%r289;
set.u32.gt.u64 %r292,%r86,%r89;
neg.s32 %r293,%r292;
cvt.u16.u32 %r295,%r290;
cvt.u16.u32 %r296,%r293;
and.b16 %r294,%r295,%r296;
cvt.u32.u16 %r297,%r294;
cvt.u16.u8 %r298,%r297;
setp.eq.u16 %r299,%r298,0;
@ %r299 bra $L30;
add.u64 %r85,%r85,-2;
add.u64 %r89,%r89,%r24;
bra $L17;
$L30:
mov.u64 %r85,%r90;
$L17:
sub.u64 %r69,%r89,%r86;
shl.b64 %r300,%r77,32;
or.b64 %r178,%r300,%r85;
$L15:
.loc 1 1124 4
rem.u64 %r93,%r69,%r179;
div.u64 %r94,%r69,%r179;
mul.lo.u64 %r95,%r94,%r177;
shl.b64 %r301,%r93,32;
shr.u64 %r302,%r27,32;
or.b64 %r98,%r301,%r302;
setp.le.u64 %r303,%r95,%r98;
@ %r303 bra $L18;
add.u64 %r99,%r94,-1;
add.u64 %r98,%r98,%r24;
set.u32.le.u64 %r305,%r24,%r98;
neg.s32 %r306,%r305;
set.u32.gt.u64 %r308,%r95,%r98;
neg.s32 %r309,%r308;
cvt.u16.u32 %r311,%r306;
cvt.u16.u32 %r312,%r309;
and.b16 %r310,%r311,%r312;
cvt.u32.u16 %r313,%r310;
cvt.u16.u8 %r314,%r313;
setp.eq.u16 %r315,%r314,0;
@ %r315 bra $L31;
add.u64 %r94,%r94,-2;
add.u64 %r98,%r98,%r24;
bra $L18;
$L31:
mov.u64 %r94,%r99;
$L18:
sub.u64 %r100,%r98,%r95;
rem.u64 %r101,%r100,%r179;
div.u64 %r102,%r100,%r179;
mul.lo.u64 %r103,%r102,%r177;
shl.b64 %r316,%r101,32;
and.b64 %r317,%r27,4294967295;
or.b64 %r106,%r316,%r317;
setp.le.u64 %r318,%r103,%r106;
@ %r318 bra $L19;
add.u64 %r107,%r102,-1;
add.u64 %r108,%r24,%r106;
set.u32.gt.u64 %r320,%r103,%r108;
neg.s32 %r321,%r320;
set.u32.le.u64 %r323,%r24,%r108;
neg.s32 %r324,%r323;
cvt.u16.u32 %r326,%r321;
cvt.u16.u32 %r327,%r324;
and.b16 %r325,%r326,%r327;
cvt.u32.u16 %r328,%r325;
cvt.u16.u8 %r329,%r328;
setp.eq.u16 %r330,%r329,0;
@ %r330 bra $L32;
add.u64 %r102,%r102,-2;
bra $L19;
$L32:
mov.u64 %r102,%r107;
$L19:
shl.b64 %r331,%r94,32;
or.b64 %r175,%r331,%r102;
bra $L10;
$L2:
.loc 1 1140 10
setp.gt.u64 %r332,%r415,%r413;
@ %r332 bra $L33;
.loc 1 1159 4
mov.u64 %r114,56;
$L21:
cvt.u32.u64 %r333,%r114;
shr.u64 %r112,%r415,%r333;
and.b64 %r334,%r112,255;
setp.ne.u64 %r335,%r334,0;
@ %r335 bra $L20;
add.u64 %r114,%r114,-8;
setp.ne.u64 %r336,%r114,0;
@ %r336 bra $L21;
mov.u64 %r112,%r415;
$L20:
cvta.const.u64 %r337,__clz_tab;
add.u64 %r338,%r337,%r112;
ld.u8 %r339,[%r338];
add.u64 %r117,%r339,%r114;
mov.u64 %r341,64;
sub.u64 %r118,%r341,%r117;
.loc 1 1160 7
setp.ne.u64 %r342,%r341,%r117;
@ %r342 bra $L22;
.loc 1 1170 15
set.u32.lt.u64 %r344,%r415,%r413;
neg.s32 %r345,%r344;
.loc 1 1170 26
set.u32.le.u64 %r347,%r414,%r412;
neg.s32 %r348,%r347;
.loc 1 1170 20
cvt.u16.u32 %r350,%r345;
cvt.u16.u32 %r351,%r348;
or.b16 %r349,%r350,%r351;
.loc 1 1223 17
cvt.u32.u16 %r352,%r349;
cvt.u64.u8 %r175,%r352;
mov.u64 %r178,%r118;
bra $L10;
$L22:
.loc 1 1194 17
cvt.u32.u64 %r122,%r118;
shl.b64 %r123,%r415,%r122;
.loc 1 1194 30
cvt.u32.u64 %r124,%r117;
shr.u64 %r353,%r414,%r124;
.loc 1 1194 11
or.b64 %r126,%r353,%r123;
.loc 1 1195 11
shl.b64 %r127,%r414,%r122;
.loc 1 1196 11
shr.u64 %r128,%r413,%r124;
.loc 1 1197 17
shl.b64 %r129,%r413,%r122;
.loc 1 1197 30
shr.u64 %r354,%r412,%r124;
.loc 1 1197 11
or.b64 %r131,%r354,%r129;
.loc 1 1200 8
shr.u64 %r133,%r126,32;
and.b64 %r134,%r126,4294967295;
rem.u64 %r135,%r128,%r133;
div.u64 %r136,%r128,%r133;
mul.lo.u64 %r137,%r134,%r136;
shl.b64 %r355,%r135,32;
shr.u64 %r356,%r131,32;
or.b64 %r140,%r355,%r356;
setp.le.u64 %r357,%r137,%r140;
@ %r357 bra $L23;
add.u64 %r141,%r136,-1;
add.u64 %r140,%r140,%r126;
set.u32.gt.u64 %r359,%r137,%r140;
neg.s32 %r360,%r359;
set.u32.le.u64 %r362,%r126,%r140;
neg.s32 %r363,%r362;
cvt.u16.u32 %r365,%r360;
cvt.u16.u32 %r366,%r363;
and.b16 %r364,%r365,%r366;
cvt.u32.u16 %r367,%r364;
cvt.u16.u8 %r368,%r367;
setp.eq.u16 %r369,%r368,0;
@ %r369 bra $L34;
add.u64 %r136,%r136,-2;
add.u64 %r140,%r140,%r126;
bra $L23;
$L34:
mov.u64 %r136,%r141;
$L23:
sub.u64 %r142,%r140,%r137;
rem.u64 %r143,%r142,%r133;
div.u64 %r144,%r142,%r133;
mul.lo.u64 %r145,%r134,%r144;
shl.b64 %r370,%r143,32;
and.b64 %r371,%r131,4294967295;
or.b64 %r148,%r370,%r371;
setp.le.u64 %r372,%r145,%r148;
@ %r372 bra $L24;
add.u64 %r149,%r144,-1;
add.u64 %r148,%r148,%r126;
set.u32.le.u64 %r374,%r126,%r148;
neg.s32 %r375,%r374;
set.u32.gt.u64 %r377,%r145,%r148;
neg.s32 %r378,%r377;
cvt.u16.u32 %r380,%r375;
cvt.u16.u32 %r381,%r378;
and.b16 %r379,%r380,%r381;
cvt.u32.u16 %r382,%r379;
cvt.u16.u8 %r383,%r382;
setp.eq.u16 %r384,%r383,0;
@ %r384 bra $L35;
add.u64 %r144,%r144,-2;
add.u64 %r148,%r148,%r126;
bra $L24;
$L35:
mov.u64 %r144,%r149;
$L24:
sub.u64 %r150,%r148,%r145;
shl.b64 %r385,%r136,32;
or.b64 %r152,%r385,%r144;
.loc 1 1201 8
and.b64 %r153,%r144,4294967295;
shr.u64 %r154,%r152,32;
and.b64 %r155,%r127,4294967295;
shr.u64 %r156,%r127,32;
mul.lo.u64 %r157,%r153,%r155;
mul.lo.u64 %r159,%r154,%r155;
mul.lo.u64 %r160,%r154,%r156;
mad.lo.u64 %r182,%r153,%r156,%r159;
shr.u64 %r387,%r157,32;
add.u64 %r162,%r387,%r182;
setp.le.u64 %r388,%r159,%r162;
@ %r388 bra $L25;
add.u64 %r160,%r160,4294967296;
$L25:
shr.u64 %r389,%r162,32;
add.u64 %r164,%r389,%r160;
.loc 1 1203 11
setp.lt.u64 %r390,%r150,%r164;
@ %r390 bra $L26;
.loc 1 1198 11
shl.b64 %r391,%r412,%r122;
.loc 1 1201 8
shl.b64 %r393,%r162,32;
and.b64 %r394,%r157,4294967295;
add.u64 %r395,%r393,%r394;
.loc 1 1203 39
set.u32.lt.u64 %r397,%r391,%r395;
neg.s32 %r398,%r397;
.loc 1 1203 27
set.u32.eq.u64 %r400,%r150,%r164;
neg.s32 %r401,%r400;
.loc 1 1203 33
cvt.u16.u32 %r403,%r398;
cvt.u16.u32 %r404,%r401;
and.b16 %r402,%r403,%r404;
.loc 1 1203 20
cvt.u32.u16 %r405,%r402;
cvt.u16.u8 %r406,%r405;
setp.ne.u16 %r407,%r406,0;
@ %r407 bra $L26;
.loc 1 1223 17
mov.u64 %r175,%r152;
mov.u64 %r178,0;
bra $L10;
$L26:
.loc 1 1205 7
add.u64 %r175,%r152,-1;
.loc 1 1223 17
mov.u64 %r178,0;
bra $L10;
$L33:
mov.u64 %r178,0;
mov.u64 %r175,%r178;
$L10:
.loc 1 1320 10
st.u64 [%r205],%r175;
st.u64 [%r205+8],%r178;
.loc 1 1321 1
ret;
}

_umoddi3.o/     1608280949  0     0     100666  17095     `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __umodti3
.visible .func __umodti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __umodti3
.visible .func __umodti3 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,16;
sub.u64 %stack,%frame,0;
}
.reg .u64 %r24;
.reg .u64 %r27;
.reg .u64 %r28;
.reg .u64 %r29;
.reg .u64 %r30;
.reg .u64 %r32;
.reg .u64 %r34;
.reg .u64 %r37;
.reg .u64 %r38;
.reg .u64 %r41;
.reg .u64 %r42;
.reg .u64 %r43;
.reg .u64 %r44;
.reg .u64 %r45;
.reg .u64 %r48;
.reg .u64 %r49;
.reg .u64 %r50;
.reg .u64 %r51;
.reg .u64 %r52;
.reg .u64 %r55;
.reg .u64 %r56;
.reg .u64 %r58;
.reg .u64 %r60;
.reg .u64 %r63;
.reg .u64 %r64;
.reg .u64 %r65;
.reg .u32 %r66;
.reg .u64 %r67;
.reg .u64 %r68;
.reg .u64 %r70;
.reg .u64 %r71;
.reg .u64 %r72;
.reg .u64 %r73;
.reg .u64 %r76;
.reg .u64 %r77;
.reg .u64 %r78;
.reg .u64 %r79;
.reg .u64 %r80;
.reg .u64 %r83;
.reg .u64 %r84;
.reg .u64 %r85;
.reg .u64 %r86;
.reg .u64 %r89;
.reg .u64 %r90;
.reg .u64 %r91;
.reg .u64 %r92;
.reg .u64 %r93;
.reg .u64 %r96;
.reg .u64 %r103;
.reg .u64 %r105;
.reg .u64 %r108;
.reg .u64 %r109;
.reg .u64 %r114;
.reg .u32 %r119;
.reg .u64 %r120;
.reg .u32 %r121;
.reg .u64 %r123;
.reg .u64 %r124;
.reg .u64 %r125;
.reg .u64 %r126;
.reg .u64 %r128;
.reg .u64 %r129;
.reg .u64 %r130;
.reg .u64 %r131;
.reg .u64 %r132;
.reg .u64 %r133;
.reg .u64 %r134;
.reg .u64 %r137;
.reg .u64 %r138;
.reg .u64 %r139;
.reg .u64 %r140;
.reg .u64 %r141;
.reg .u64 %r142;
.reg .u64 %r145;
.reg .u64 %r146;
.reg .u64 %r147;
.reg .u64 %r149;
.reg .u64 %r150;
.reg .u64 %r151;
.reg .u64 %r152;
.reg .u64 %r153;
.reg .u64 %r154;
.reg .u64 %r156;
.reg .u64 %r157;
.reg .u64 %r159;
.reg .u64 %r164;
.reg .u64 %r168;
.reg .u64 %r171;
.reg .u64 %r172;
.reg .u64 %r176;
.reg .u32 %r184;
.reg .u64 %r185;
.reg .u64 %r186;
.reg .u64 %r187;
.reg .u64 %r194;
.reg .u64 %r214;
.reg .u64 %r215;
.reg .u64 %r217;
.reg .pred %r219;
.reg .pred %r220;
.reg .u32 %r221;
.reg .u64 %r222;
.reg .pred %r223;
.reg .pred %r224;
.reg .u64 %r225;
.reg .u64 %r226;
.reg .u64 %r227;
.reg .u64 %r228;
.reg .pred %r230;
.reg .u32 %r231;
.reg .u32 %r232;
.reg .u64 %r233;
.reg .u64 %r234;
.reg .u64 %r235;
.reg .pred %r236;
.reg .u32 %r238;
.reg .u32 %r239;
.reg .u32 %r241;
.reg .u32 %r242;
.reg .u16 %r243;
.reg .u16 %r244;
.reg .u16 %r245;
.reg .u32 %r246;
.reg .u16 %r247;
.reg .pred %r248;
.reg .u64 %r249;
.reg .u64 %r250;
.reg .pred %r251;
.reg .u32 %r253;
.reg .u32 %r254;
.reg .u32 %r256;
.reg .u32 %r257;
.reg .u16 %r258;
.reg .u16 %r259;
.reg .u16 %r260;
.reg .u32 %r261;
.reg .u16 %r262;
.reg .pred %r263;
.reg .pred %r264;
.reg .u64 %r265;
.reg .u32 %r267;
.reg .u64 %r268;
.reg .pred %r269;
.reg .pred %r270;
.reg .u64 %r271;
.reg .u64 %r272;
.reg .u64 %r273;
.reg .u64 %r275;
.reg .pred %r276;
.reg .u64 %r277;
.reg .u64 %r278;
.reg .u64 %r279;
.reg .pred %r280;
.reg .u32 %r282;
.reg .u32 %r283;
.reg .u32 %r285;
.reg .u32 %r286;
.reg .u16 %r287;
.reg .u16 %r288;
.reg .u16 %r289;
.reg .u32 %r290;
.reg .u16 %r291;
.reg .pred %r292;
.reg .u64 %r293;
.reg .u64 %r294;
.reg .pred %r295;
.reg .u32 %r297;
.reg .u32 %r298;
.reg .u32 %r300;
.reg .u32 %r301;
.reg .u16 %r302;
.reg .u16 %r303;
.reg .u16 %r304;
.reg .u32 %r305;
.reg .u16 %r306;
.reg .pred %r307;
.reg .u64 %r308;
.reg .u64 %r309;
.reg .pred %r310;
.reg .u32 %r312;
.reg .u32 %r313;
.reg .u32 %r315;
.reg .u32 %r316;
.reg .u16 %r317;
.reg .u16 %r318;
.reg .u16 %r319;
.reg .u32 %r320;
.reg .u16 %r321;
.reg .pred %r322;
.reg .u64 %r323;
.reg .u64 %r324;
.reg .pred %r325;
.reg .u32 %r327;
.reg .u32 %r328;
.reg .u32 %r330;
.reg .u32 %r331;
.reg .u16 %r332;
.reg .u16 %r333;
.reg .u16 %r334;
.reg .u32 %r335;
.reg .u16 %r336;
.reg .pred %r337;
.reg .pred %r340;
.reg .u32 %r341;
.reg .u64 %r342;
.reg .pred %r343;
.reg .pred %r344;
.reg .u64 %r345;
.reg .u64 %r346;
.reg .u64 %r347;
.reg .u64 %r349;
.reg .pred %r350;
.reg .u32 %r352;
.reg .u32 %r353;
.reg .u32 %r355;
.reg .u32 %r356;
.reg .u16 %r357;
.reg .u16 %r358;
.reg .u16 %r359;
.reg .u32 %r360;
.reg .u16 %r361;
.reg .pred %r362;
.reg .u64 %r363;
.reg .u32 %r364;
.reg .u64 %r366;
.reg .u64 %r367;
.reg .u64 %r368;
.reg .u64 %r369;
.reg .pred %r370;
.reg .u32 %r372;
.reg .u32 %r373;
.reg .u32 %r375;
.reg .u32 %r376;
.reg .u16 %r377;
.reg .u16 %r378;
.reg .u16 %r379;
.reg .u32 %r380;
.reg .u16 %r381;
.reg .pred %r382;
.reg .u64 %r383;
.reg .u64 %r384;
.reg .pred %r385;
.reg .u32 %r387;
.reg .u32 %r388;
.reg .u32 %r390;
.reg .u32 %r391;
.reg .u16 %r392;
.reg .u16 %r393;
.reg .u16 %r394;
.reg .u32 %r395;
.reg .u16 %r396;
.reg .pred %r397;
.reg .u64 %r398;
.reg .u64 %r400;
.reg .pred %r401;
.reg .u64 %r402;
.reg .u64 %r404;
.reg .u64 %r405;
.reg .pred %r406;
.reg .u32 %r408;
.reg .u32 %r409;
.reg .u32 %r411;
.reg .u32 %r412;
.reg .u16 %r413;
.reg .u16 %r414;
.reg .u16 %r415;
.reg .u32 %r416;
.reg .u16 %r417;
.reg .pred %r418;
.reg .u64 %r419;
.reg .u32 %r420;
.reg .u64 %r422;
.reg .u64 %r423;
.reg .u64 %r424;
.reg .u32 %r425;
.reg .u64 %r427;
.reg .u64 %r428;
.reg .u64 %r433;
.reg .u64 %r434;
.reg .u64 %r435;
.reg .u64 %r436;
.reg .u64 %r437;
.reg .u64 %r438;
mov.u64 %r214,%ar0;
mov.u64 %r215,%ar1;
ld.u64 %r435,[%r215];
ld.u64 %r436,[%r215+8];
mov.u64 %r217,%ar2;
ld.u64 %r437,[%r217];
ld.u64 %r438,[%r217+8];
.loc 1 1024 6
mov.u64 %r24,%r437;
.loc 1 1026 6
mov.u64 %r28,%r435;
mov.u64 %r29,%r436;
.loc 1 1027 6
mov.u64 %r30,%r436;
.loc 1 1064 6
setp.ne.u64 %r219,%r438,0;
@ %r219 bra $L2;
.loc 1 1066 10
setp.le.u64 %r220,%r437,%r436;
@ %r220 bra $L3;
.loc 1 1070 4
mov.u64 %r34,56;
$L5:
cvt.u32.u64 %r221,%r34;
shr.u64 %r32,%r437,%r221;
and.b64 %r222,%r32,255;
setp.ne.u64 %r223,%r222,0;
@ %r223 bra $L4;
add.u64 %r34,%r34,-8;
setp.ne.u64 %r224,%r34,0;
@ %r224 bra $L5;
mov.u64 %r32,%r437;
mov.u64 %r185,64;
bra $L6;
$L4:
mov.u64 %r225,64;
sub.u64 %r185,%r225,%r34;
$L6:
cvta.const.u64 %r226,__clz_tab;
add.u64 %r227,%r226,%r32;
ld.u8 %r228,[%r227];
sub.u64 %r37,%r185,%r228;
.loc 1 1072 7
setp.eq.u64 %r230,%r185,%r228;
@ %r230 bra $L30;
.loc 1 1077 16
cvt.u32.u64 %r184,%r37;
.loc 1 1077 11
shl.b64 %r24,%r437,%r184;
.loc 1 1078 17
shl.b64 %r38,%r436,%r184;
.loc 1 1078 46
mov.u32 %r232,64;
sub.u32 %r231,%r232,%r184;
.loc 1 1078 30
shr.u64 %r233,%r435,%r231;
.loc 1 1078 11
or.b64 %r30,%r233,%r38;
.loc 1 1079 11
shl.b64 %r28,%r435,%r184;
bra $L7;
$L30:
cvt.u32.u64 %r184,%r37;
$L7:
.loc 1 1082 4
shr.u64 %r41,%r24,32;
and.b64 %r42,%r24,4294967295;
rem.u64 %r43,%r30,%r41;
div.u64 %r44,%r30,%r41;
mul.lo.u64 %r45,%r42,%r44;
shl.b64 %r234,%r43,32;
shr.u64 %r235,%r28,32;
or.b64 %r48,%r234,%r235;
setp.le.u64 %r236,%r45,%r48;
@ %r236 bra $L8;
add.u64 %r48,%r48,%r24;
set.u32.le.u64 %r238,%r24,%r48;
neg.s32 %r239,%r238;
set.u32.gt.u64 %r241,%r45,%r48;
neg.s32 %r242,%r241;
cvt.u16.u32 %r244,%r239;
cvt.u16.u32 %r245,%r242;
and.b16 %r243,%r244,%r245;
cvt.u32.u16 %r246,%r243;
cvt.u16.u8 %r247,%r246;
setp.eq.u16 %r248,%r247,0;
@ %r248 bra $L8;
add.u64 %r48,%r48,%r24;
$L8:
sub.u64 %r49,%r48,%r45;
rem.u64 %r50,%r49,%r41;
div.u64 %r51,%r49,%r41;
mul.lo.u64 %r52,%r42,%r51;
shl.b64 %r249,%r50,32;
and.b64 %r250,%r28,4294967295;
or.b64 %r55,%r249,%r250;
setp.le.u64 %r251,%r52,%r55;
@ %r251 bra $L9;
add.u64 %r55,%r55,%r24;
set.u32.gt.u64 %r253,%r52,%r55;
neg.s32 %r254,%r253;
set.u32.le.u64 %r256,%r24,%r55;
neg.s32 %r257,%r256;
cvt.u16.u32 %r259,%r254;
cvt.u16.u32 %r260,%r257;
and.b16 %r258,%r259,%r260;
cvt.u32.u16 %r261,%r258;
cvt.u16.u8 %r262,%r261;
setp.eq.u16 %r263,%r262,0;
@ %r263 bra $L9;
add.u64 %r55,%r55,%r24;
$L9:
sub.u64 %r56,%r55,%r52;
bra $L10;
$L3:
.loc 1 1091 7
setp.ne.u64 %r264,%r24,0;
@ %r264 bra $L11;
.loc 1 1092 9
mov.u64 %r265,1;
div.u64 %r24,%r265,0;
$L11:
.loc 1 1094 4
mov.u64 %r60,56;
$L13:
cvt.u32.u64 %r267,%r60;
shr.u64 %r58,%r24,%r267;
and.b64 %r268,%r58,255;
setp.ne.u64 %r269,%r268,0;
@ %r269 bra $L12;
add.u64 %r60,%r60,-8;
setp.ne.u64 %r270,%r60,0;
@ %r270 bra $L13;
mov.u64 %r58,%r24;
$L12:
cvta.const.u64 %r271,__clz_tab;
add.u64 %r272,%r271,%r58;
ld.u8 %r273,[%r272];
add.u64 %r63,%r273,%r60;
mov.u64 %r275,64;
sub.u64 %r64,%r275,%r63;
.loc 1 1096 7
setp.ne.u64 %r276,%r275,%r63;
@ %r276 bra $L14;
.loc 1 1105 11
sub.u64 %r65,%r436,%r24;
.loc 1 1124 4
shr.u64 %r186,%r24,32;
and.b64 %r187,%r24,4294967295;
cvt.u32.u64 %r184,%r64;
bra $L15;
$L14:
.loc 1 1114 16
cvt.u32.u64 %r184,%r64;
.loc 1 1114 11
shl.b64 %r24,%r24,%r184;
.loc 1 1115 16
cvt.u32.u64 %r66,%r63;
.loc 1 1115 11
shr.u64 %r67,%r436,%r66;
.loc 1 1116 17
shl.b64 %r68,%r436,%r184;
.loc 1 1116 30
shr.u64 %r277,%r435,%r66;
.loc 1 1116 11
or.b64 %r70,%r277,%r68;
.loc 1 1117 11
shl.b64 %r28,%r435,%r184;
.loc 1 1119 8
shr.u64 %r186,%r24,32;
and.b64 %r187,%r24,4294967295;
rem.u64 %r71,%r67,%r186;
div.u64 %r72,%r67,%r186;
mul.lo.u64 %r73,%r187,%r72;
shl.b64 %r278,%r71,32;
shr.u64 %r279,%r70,32;
or.b64 %r76,%r278,%r279;
setp.le.u64 %r280,%r73,%r76;
@ %r280 bra $L16;
add.u64 %r76,%r76,%r24;
set.u32.le.u64 %r282,%r24,%r76;
neg.s32 %r283,%r282;
set.u32.gt.u64 %r285,%r73,%r76;
neg.s32 %r286,%r285;
cvt.u16.u32 %r288,%r283;
cvt.u16.u32 %r289,%r286;
and.b16 %r287,%r288,%r289;
cvt.u32.u16 %r290,%r287;
cvt.u16.u8 %r291,%r290;
setp.eq.u16 %r292,%r291,0;
@ %r292 bra $L16;
add.u64 %r76,%r76,%r24;
$L16:
sub.u64 %r77,%r76,%r73;
rem.u64 %r78,%r77,%r186;
div.u64 %r79,%r77,%r186;
mul.lo.u64 %r80,%r187,%r79;
shl.b64 %r293,%r78,32;
and.b64 %r294,%r70,4294967295;
or.b64 %r83,%r293,%r294;
setp.le.u64 %r295,%r80,%r83;
@ %r295 bra $L17;
add.u64 %r83,%r83,%r24;
set.u32.gt.u64 %r297,%r80,%r83;
neg.s32 %r298,%r297;
set.u32.le.u64 %r300,%r24,%r83;
neg.s32 %r301,%r300;
cvt.u16.u32 %r303,%r298;
cvt.u16.u32 %r304,%r301;
and.b16 %r302,%r303,%r304;
cvt.u32.u16 %r305,%r302;
cvt.u16.u8 %r306,%r305;
setp.eq.u16 %r307,%r306,0;
@ %r307 bra $L17;
add.u64 %r83,%r83,%r24;
$L17:
sub.u64 %r65,%r83,%r80;
$L15:
.loc 1 1124 4
rem.u64 %r84,%r65,%r186;
div.u64 %r85,%r65,%r186;
mul.lo.u64 %r86,%r85,%r187;
shl.b64 %r308,%r84,32;
shr.u64 %r309,%r28,32;
or.b64 %r89,%r308,%r309;
setp.le.u64 %r310,%r86,%r89;
@ %r310 bra $L18;
add.u64 %r89,%r89,%r24;
set.u32.le.u64 %r312,%r24,%r89;
neg.s32 %r313,%r312;
set.u32.gt.u64 %r315,%r86,%r89;
neg.s32 %r316,%r315;
cvt.u16.u32 %r318,%r313;
cvt.u16.u32 %r319,%r316;
and.b16 %r317,%r318,%r319;
cvt.u32.u16 %r320,%r317;
cvt.u16.u8 %r321,%r320;
setp.eq.u16 %r322,%r321,0;
@ %r322 bra $L18;
add.u64 %r89,%r89,%r24;
$L18:
sub.u64 %r90,%r89,%r86;
rem.u64 %r91,%r90,%r186;
div.u64 %r92,%r90,%r186;
mul.lo.u64 %r93,%r92,%r187;
shl.b64 %r323,%r91,32;
and.b64 %r324,%r28,4294967295;
or.b64 %r96,%r323,%r324;
setp.le.u64 %r325,%r93,%r96;
@ %r325 bra $L19;
add.u64 %r96,%r96,%r24;
set.u32.le.u64 %r327,%r24,%r96;
neg.s32 %r328,%r327;
set.u32.gt.u64 %r330,%r93,%r96;
neg.s32 %r331,%r330;
cvt.u16.u32 %r333,%r328;
cvt.u16.u32 %r334,%r331;
and.b16 %r332,%r333,%r334;
cvt.u32.u16 %r335,%r332;
cvt.u16.u8 %r336,%r335;
setp.eq.u16 %r337,%r336,0;
@ %r337 bra $L19;
add.u64 %r96,%r96,%r24;
$L19:
sub.u64 %r56,%r96,%r93;
$L10:
.loc 1 1133 12
shr.u64 %r433,%r56,%r184;
mov.u64 %r434,0;
bra $L20;
$L2:
mov.u64 %r27,%r435;
.loc 1 1140 10
setp.le.u64 %r340,%r438,%r436;
@ %r340 bra $L31;
.loc 1 1152 16
mov.u64 %r433,%r435;
mov.u64 %r434,%r436;
bra $L20;
$L31:
.loc 1 1159 4
mov.u64 %r105,56;
$L21:
cvt.u32.u64 %r341,%r105;
shr.u64 %r103,%r438,%r341;
and.b64 %r342,%r103,255;
setp.ne.u64 %r343,%r342,0;
@ %r343 bra $L22;
add.u64 %r105,%r105,-8;
setp.ne.u64 %r344,%r105,0;
@ %r344 bra $L21;
mov.u64 %r103,%r438;
$L22:
cvta.const.u64 %r345,__clz_tab;
add.u64 %r346,%r345,%r103;
ld.u8 %r347,[%r346];
add.u64 %r108,%r347,%r105;
mov.u64 %r349,64;
sub.u64 %r109,%r349,%r108;
.loc 1 1160 7
setp.ne.u64 %r350,%r349,%r108;
@ %r350 bra $L23;
.loc 1 1170 15
set.u32.lt.u64 %r352,%r438,%r436;
neg.s32 %r353,%r352;
.loc 1 1170 26
set.u32.le.u64 %r355,%r437,%r435;
neg.s32 %r356,%r355;
.loc 1 1170 20
cvt.u16.u32 %r358,%r353;
cvt.u16.u32 %r359,%r356;
or.b16 %r357,%r358,%r359;
.loc 1 1170 11
cvt.u32.u16 %r360,%r357;
cvt.u16.u8 %r361,%r360;
setp.eq.u16 %r362,%r361,0;
@ %r362 bra $L24;
.loc 1 1173 5
sub.u64 %r114,%r436,%r438;
.loc 1 1182 14
sub.u64 %r27,%r435,%r437;
.loc 1 1173 5
set.u32.lt.u64 %r364,%r435,%r27;
cvt.s64.s32 %r363,%r364;
add.u64 %r29,%r114,%r363;
$L24:
.loc 1 1184 13
mov.u64 %r433,%r27;
mov.u64 %r434,%r29;
bra $L20;
$L23:
.loc 1 1194 17
cvt.u32.u64 %r119,%r109;
shl.b64 %r120,%r438,%r119;
.loc 1 1194 30
cvt.u32.u64 %r121,%r108;
shr.u64 %r366,%r437,%r121;
.loc 1 1194 11
or.b64 %r123,%r366,%r120;
.loc 1 1195 11
shl.b64 %r124,%r437,%r119;
.loc 1 1196 11
shr.u64 %r125,%r436,%r121;
.loc 1 1197 17
shl.b64 %r126,%r436,%r119;
.loc 1 1197 30
shr.u64 %r367,%r435,%r121;
.loc 1 1197 11
or.b64 %r128,%r367,%r126;
.loc 1 1198 11
shl.b64 %r129,%r435,%r119;
.loc 1 1200 8
shr.u64 %r130,%r123,32;
and.b64 %r131,%r123,4294967295;
rem.u64 %r132,%r125,%r130;
div.u64 %r133,%r125,%r130;
mul.lo.u64 %r134,%r131,%r133;
shl.b64 %r368,%r132,32;
shr.u64 %r369,%r128,32;
or.b64 %r137,%r368,%r369;
setp.le.u64 %r370,%r134,%r137;
@ %r370 bra $L25;
add.u64 %r138,%r133,-1;
add.u64 %r137,%r137,%r123;
set.u32.le.u64 %r372,%r123,%r137;
neg.s32 %r373,%r372;
set.u32.gt.u64 %r375,%r134,%r137;
neg.s32 %r376,%r375;
cvt.u16.u32 %r378,%r373;
cvt.u16.u32 %r379,%r376;
and.b16 %r377,%r378,%r379;
cvt.u32.u16 %r380,%r377;
cvt.u16.u8 %r381,%r380;
setp.eq.u16 %r382,%r381,0;
@ %r382 bra $L32;
add.u64 %r133,%r133,-2;
add.u64 %r137,%r137,%r123;
bra $L25;
$L32:
mov.u64 %r133,%r138;
$L25:
sub.u64 %r139,%r137,%r134;
rem.u64 %r140,%r139,%r130;
div.u64 %r141,%r139,%r130;
mul.lo.u64 %r142,%r131,%r141;
shl.b64 %r383,%r140,32;
and.b64 %r384,%r128,4294967295;
or.b64 %r145,%r383,%r384;
setp.le.u64 %r385,%r142,%r145;
@ %r385 bra $L26;
add.u64 %r146,%r141,-1;
add.u64 %r145,%r145,%r123;
set.u32.gt.u64 %r387,%r142,%r145;
neg.s32 %r388,%r387;
set.u32.le.u64 %r390,%r123,%r145;
neg.s32 %r391,%r390;
cvt.u16.u32 %r393,%r388;
cvt.u16.u32 %r394,%r391;
and.b16 %r392,%r393,%r394;
cvt.u32.u16 %r395,%r392;
cvt.u16.u8 %r396,%r395;
setp.eq.u16 %r397,%r396,0;
@ %r397 bra $L33;
add.u64 %r141,%r141,-2;
add.u64 %r145,%r145,%r123;
bra $L26;
$L33:
mov.u64 %r141,%r146;
$L26:
sub.u64 %r147,%r145,%r142;
shl.b64 %r398,%r133,32;
or.b64 %r149,%r398,%r141;
.loc 1 1201 8
and.b64 %r150,%r141,4294967295;
shr.u64 %r151,%r149,32;
and.b64 %r152,%r124,4294967295;
shr.u64 %r153,%r124,32;
mul.lo.u64 %r154,%r150,%r152;
mul.lo.u64 %r156,%r151,%r152;
mul.lo.u64 %r157,%r151,%r153;
mad.lo.u64 %r194,%r150,%r153,%r156;
shr.u64 %r400,%r154,32;
add.u64 %r159,%r400,%r194;
setp.le.u64 %r401,%r156,%r159;
@ %r401 bra $L27;
add.u64 %r157,%r157,4294967296;
$L27:
shr.u64 %r402,%r159,32;
add.u64 %r171,%r402,%r157;
shl.b64 %r404,%r159,32;
and.b64 %r405,%r154,4294967295;
add.u64 %r164,%r404,%r405;
.loc 1 1203 11
setp.lt.u64 %r406,%r147,%r171;
@ %r406 bra $L28;
.loc 1 1203 27
set.u32.eq.u64 %r408,%r147,%r171;
neg.s32 %r409,%r408;
.loc 1 1203 39
set.u32.lt.u64 %r411,%r129,%r164;
neg.s32 %r412,%r411;
.loc 1 1203 33
cvt.u16.u32 %r414,%r409;
cvt.u16.u32 %r415,%r412;
and.b16 %r413,%r414,%r415;
.loc 1 1203 20
cvt.u32.u16 %r416,%r413;
cvt.u16.u8 %r417,%r416;
setp.eq.u16 %r418,%r417,0;
@ %r418 bra $L34;
$L28:
.loc 1 1206 5
sub.u64 %r168,%r164,%r124;
set.u32.lt.u64 %r420,%r164,%r168;
cvt.s64.s32 %r419,%r420;
sub.u64 %r422,%r123,%r419;
sub.u64 %r171,%r171,%r422;
bra $L29;
$L34:
.loc 1 1201 8
mov.u64 %r168,%r164;
$L29:
.loc 1 1214 5
sub.u64 %r172,%r129,%r168;
sub.u64 %r423,%r147,%r171;
set.u32.lt.u64 %r425,%r129,%r172;
cvt.s64.s32 %r424,%r425;
add.u64 %r176,%r423,%r424;
.loc 1 1215 20
shl.b64 %r427,%r176,%r121;
.loc 1 1215 32
shr.u64 %r428,%r172,%r119;
.loc 1 1217 13
or.b64 %r433,%r427,%r428;
shr.u64 %r434,%r176,%r119;
$L20:
.loc 1 1312 10
st.u64 [%r214],%r433;
st.u64 [%r214+8],%r434;
.loc 1 1313 1
ret;
}

_udivmoddi4.o/  1608280949  0     0     100666  19205     `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __udivmodti4
.visible .func __udivmodti4 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2, .param .u64 %in_ar3);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL VAR DECL: __clz_tab
.extern .const .align 1 .u8 __clz_tab[256];
// BEGIN GLOBAL VAR DECL: __nvptx_stacks
.extern .shared .u64 __nvptx_stacks[32];
// BEGIN GLOBAL FUNCTION DEF: __udivmodti4
.visible .func __udivmodti4 (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2, .param .u64 %in_ar3)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %ar3;
ld.param.u64 %ar3,[%in_ar3];
.reg .u64 %stack;
.reg .u64 %frame;
.reg .u64 %sspslot;
.reg .u64 %sspprev;
{
.reg .u32 %fstmp0;
.reg .u64 %fstmp1;
.reg .u64 %fstmp2;
mov.u32 %fstmp0,%tid.y;
mul.wide.u32 %fstmp1,%fstmp0,8;
mov.u64 %fstmp2,__nvptx_stacks;
add.u64 %sspslot,%fstmp2,%fstmp1;
ld.shared.u64 %sspprev,[%sspslot];
sub.u64 %frame,%sspprev,32;
sub.u64 %stack,%frame,0;
}
.reg .u64 %r24;
.reg .u32 %r27;
.reg .u64 %r28;
.reg .u64 %r36;
.reg .u64 %r39;
.reg .u32 %r40;
.reg .u32 %r41;
.reg .u64 %r42;
.reg .u64 %r61;
.reg .u64 %r64;
.reg .u64 %r68;
.reg .u32 %r75;
.reg .u64 %r76;
.reg .u32 %r77;
.reg .u64 %r79;
.reg .u64 %r109;
.reg .u64 %r110;
.reg .u64 %r111;
.reg .u64 %r112;
.reg .u64 %r113;
.reg .u64 %r114;
.reg .u64 %r115;
.reg .u64 %r116;
.reg .u64 %r118;
.reg .u64 %r119;
.reg .u64 %r120;
.reg .u64 %r121;
.reg .u64 %r123;
.reg .u64 %r124;
.reg .u64 %r125;
.reg .u64 %r126;
.reg .u64 %r127;
.reg .u64 %r128;
.reg .u64 %r129;
.reg .u64 %r130;
.reg .u64 %r132;
.reg .u64 %r133;
.reg .u64 %r134;
.reg .u64 %r135;
.reg .u64 %r136;
.reg .u64 %r137;
.reg .u64 %r138;
.reg .u64 %r140;
.reg .u64 %r142;
.reg .u64 %r143;
.reg .u64 %r144;
.reg .u64 %r145;
.reg .u64 %r146;
.reg .u64 %r147;
.reg .u64 %r148;
.reg .u64 %r149;
.reg .u64 %r150;
.reg .u64 %r151;
.reg .u64 %r152;
.reg .u64 %r153;
.reg .u64 %r154;
.reg .u64 %r157;
.reg .u64 %r158;
.reg .u64 %r159;
.reg .u64 %r161;
.reg .u64 %r162;
.reg .u64 %r163;
.reg .u64 %r164;
.reg .u64 %r165;
.reg .u64 %r167;
.reg .u64 %r168;
.reg .u64 %r169;
.reg .u64 %r170;
.reg .u64 %r171;
.reg .u64 %r172;
.reg .u64 %r173;
.reg .u64 %r175;
.reg .u64 %r176;
.reg .u64 %r177;
.reg .u64 %r178;
.reg .u64 %r179;
.reg .u64 %r180;
.reg .u64 %r181;
.reg .u64 %r182;
.reg .u64 %r183;
.reg .u64 %r185;
.reg .u64 %r186;
.reg .u64 %r187;
.reg .u64 %r188;
.reg .u64 %r189;
.reg .u64 %r190;
.reg .u64 %r191;
.reg .u64 %r192;
.reg .u64 %r194;
.reg .u64 %r195;
.reg .u64 %r196;
.reg .u64 %r197;
.reg .u64 %r198;
.reg .u64 %r199;
.reg .u64 %r200;
.reg .u64 %r201;
.reg .u64 %r202;
.reg .u64 %r203;
.reg .u64 %r204;
.reg .u64 %r205;
.reg .u64 %r224;
.reg .u64 %r225;
.reg .u64 %r226;
.reg .u64 %r234;
.reg .u64 %r235;
.reg .u64 %r237;
.reg .u64 %r239;
.reg .pred %r240;
.reg .pred %r241;
.reg .u32 %r242;
.reg .u64 %r243;
.reg .pred %r244;
.reg .pred %r245;
.reg .u64 %r246;
.reg .u64 %r247;
.reg .u64 %r248;
.reg .u64 %r249;
.reg .pred %r251;
.reg .u32 %r252;
.reg .u32 %r253;
.reg .u64 %r254;
.reg .u64 %r255;
.reg .u64 %r256;
.reg .pred %r257;
.reg .u32 %r259;
.reg .u32 %r260;
.reg .u32 %r262;
.reg .u32 %r263;
.reg .u16 %r264;
.reg .u16 %r265;
.reg .u16 %r266;
.reg .u32 %r267;
.reg .u16 %r268;
.reg .pred %r269;
.reg .u64 %r270;
.reg .u64 %r271;
.reg .pred %r272;
.reg .u32 %r274;
.reg .u32 %r275;
.reg .u32 %r277;
.reg .u32 %r278;
.reg .u16 %r279;
.reg .u16 %r280;
.reg .u16 %r281;
.reg .u32 %r282;
.reg .u16 %r283;
.reg .pred %r284;
.reg .u64 %r285;
.reg .pred %r286;
.reg .u64 %r287;
.reg .u32 %r289;
.reg .u64 %r290;
.reg .pred %r291;
.reg .pred %r292;
.reg .u64 %r293;
.reg .u64 %r294;
.reg .u64 %r295;
.reg .u64 %r297;
.reg .pred %r298;
.reg .u64 %r299;
.reg .u64 %r300;
.reg .u64 %r301;
.reg .pred %r302;
.reg .u32 %r304;
.reg .u32 %r305;
.reg .u32 %r307;
.reg .u32 %r308;
.reg .u16 %r309;
.reg .u16 %r310;
.reg .u16 %r311;
.reg .u32 %r312;
.reg .u16 %r313;
.reg .pred %r314;
.reg .u64 %r315;
.reg .u64 %r316;
.reg .pred %r317;
.reg .u32 %r319;
.reg .u32 %r320;
.reg .u32 %r322;
.reg .u32 %r323;
.reg .u16 %r324;
.reg .u16 %r325;
.reg .u16 %r326;
.reg .u32 %r327;
.reg .u16 %r328;
.reg .pred %r329;
.reg .u64 %r330;
.reg .u64 %r331;
.reg .u64 %r332;
.reg .pred %r333;
.reg .u32 %r335;
.reg .u32 %r336;
.reg .u32 %r338;
.reg .u32 %r339;
.reg .u16 %r340;
.reg .u16 %r341;
.reg .u16 %r342;
.reg .u32 %r343;
.reg .u16 %r344;
.reg .pred %r345;
.reg .u64 %r346;
.reg .u64 %r347;
.reg .pred %r348;
.reg .u32 %r350;
.reg .u32 %r351;
.reg .u32 %r353;
.reg .u32 %r354;
.reg .u16 %r355;
.reg .u16 %r356;
.reg .u16 %r357;
.reg .u32 %r358;
.reg .u16 %r359;
.reg .pred %r360;
.reg .u64 %r361;
.reg .pred %r362;
.reg .u64 %r363;
.reg .u32 %r364;
.reg .u64 %r365;
.reg .pred %r368;
.reg .pred %r369;
.reg .u32 %r373;
.reg .u64 %r374;
.reg .pred %r375;
.reg .pred %r376;
.reg .u64 %r377;
.reg .u64 %r378;
.reg .u64 %r379;
.reg .u64 %r381;
.reg .pred %r382;
.reg .u32 %r384;
.reg .u32 %r385;
.reg .u32 %r387;
.reg .u32 %r388;
.reg .u16 %r389;
.reg .u16 %r390;
.reg .u16 %r391;
.reg .u32 %r392;
.reg .u16 %r393;
.reg .pred %r394;
.reg .u64 %r395;
.reg .u32 %r396;
.reg .pred %r398;
.reg .u64 %r401;
.reg .u64 %r402;
.reg .u64 %r403;
.reg .u64 %r404;
.reg .pred %r405;
.reg .u32 %r407;
.reg .u32 %r408;
.reg .u32 %r410;
.reg .u32 %r411;
.reg .u16 %r412;
.reg .u16 %r413;
.reg .u16 %r414;
.reg .u32 %r415;
.reg .u16 %r416;
.reg .pred %r417;
.reg .u64 %r418;
.reg .u64 %r419;
.reg .pred %r420;
.reg .u32 %r422;
.reg .u32 %r423;
.reg .u32 %r425;
.reg .u32 %r426;
.reg .u16 %r427;
.reg .u16 %r428;
.reg .u16 %r429;
.reg .u32 %r430;
.reg .u16 %r431;
.reg .pred %r432;
.reg .u64 %r433;
.reg .u64 %r435;
.reg .pred %r436;
.reg .u64 %r437;
.reg .u64 %r439;
.reg .u64 %r440;
.reg .pred %r441;
.reg .u32 %r443;
.reg .u32 %r444;
.reg .u32 %r446;
.reg .u32 %r447;
.reg .u16 %r448;
.reg .u16 %r449;
.reg .u16 %r450;
.reg .u32 %r451;
.reg .u16 %r452;
.reg .pred %r453;
.reg .u64 %r454;
.reg .u32 %r455;
.reg .u64 %r457;
.reg .pred %r458;
.reg .u64 %r459;
.reg .u64 %r460;
.reg .u32 %r461;
.reg .u64 %r463;
.reg .u64 %r464;
.reg .u64 %r465;
.reg .u64 %r466;
.reg .u64 %r471;
.reg .u64 %r472;
.reg .u64 %r473;
.reg .u64 %r474;
mov.u64 %r234,%ar0;
mov.u64 %r235,%ar1;
ld.u64 %r471,[%r235];
ld.u64 %r472,[%r235+8];
mov.u64 %r237,%ar2;
ld.u64 %r473,[%r237];
ld.u64 %r474,[%r237+8];
mov.u64 %r239,%ar3;
.loc 1 1024 6
mov.u64 %r109,%r473;
.loc 1 1026 6
mov.u64 %r110,%r471;
.loc 1 1027 6
mov.u64 %r112,%r472;
.loc 1 1064 6
setp.ne.u64 %r240,%r474,0;
@ %r240 bra $L2;
.loc 1 1066 10
setp.le.u64 %r241,%r473,%r472;
@ %r241 bra $L3;
.loc 1 1070 4
mov.u64 %r192,56;
$L5:
cvt.u32.u64 %r242,%r192;
shr.u64 %r24,%r473,%r242;
and.b64 %r243,%r24,255;
setp.ne.u64 %r244,%r243,0;
@ %r244 bra $L4;
add.u64 %r192,%r192,-8;
setp.ne.u64 %r245,%r192,0;
@ %r245 bra $L5;
mov.u64 %r24,%r473;
mov.u64 %r224,64;
bra $L6;
$L4:
mov.u64 %r246,64;
sub.u64 %r224,%r246,%r192;
$L6:
cvta.const.u64 %r247,__clz_tab;
add.u64 %r248,%r247,%r24;
ld.u8 %r249,[%r248];
sub.u64 %r116,%r224,%r249;
.loc 1 1072 7
setp.eq.u64 %r251,%r224,%r249;
@ %r251 bra $L7;
.loc 1 1077 16
cvt.u32.u64 %r27,%r116;
.loc 1 1077 11
shl.b64 %r109,%r473,%r27;
.loc 1 1078 17
shl.b64 %r28,%r472,%r27;
.loc 1 1078 46
mov.u32 %r253,64;
sub.u32 %r252,%r253,%r27;
.loc 1 1078 30
shr.u64 %r254,%r471,%r252;
.loc 1 1078 11
or.b64 %r112,%r254,%r28;
.loc 1 1079 11
shl.b64 %r110,%r471,%r27;
$L7:
.loc 1 1082 4
shr.u64 %r194,%r109,32;
and.b64 %r195,%r109,4294967295;
rem.u64 %r196,%r112,%r194;
div.u64 %r118,%r112,%r194;
mul.lo.u64 %r197,%r195,%r118;
shl.b64 %r255,%r196,32;
shr.u64 %r256,%r110,32;
or.b64 %r120,%r255,%r256;
setp.le.u64 %r257,%r197,%r120;
@ %r257 bra $L8;
add.u64 %r198,%r118,-1;
add.u64 %r120,%r120,%r109;
set.u32.le.u64 %r259,%r109,%r120;
neg.s32 %r260,%r259;
set.u32.gt.u64 %r262,%r197,%r120;
neg.s32 %r263,%r262;
cvt.u16.u32 %r265,%r260;
cvt.u16.u32 %r266,%r263;
and.b16 %r264,%r265,%r266;
cvt.u32.u16 %r267,%r264;
cvt.u16.u8 %r268,%r267;
setp.eq.u16 %r269,%r268,0;
@ %r269 bra $L30;
add.u64 %r118,%r118,-2;
add.u64 %r120,%r120,%r109;
bra $L8;
$L30:
mov.u64 %r118,%r198;
$L8:
sub.u64 %r199,%r120,%r197;
rem.u64 %r200,%r199,%r194;
div.u64 %r119,%r199,%r194;
mul.lo.u64 %r201,%r195,%r119;
shl.b64 %r270,%r200,32;
and.b64 %r271,%r110,4294967295;
or.b64 %r121,%r270,%r271;
setp.le.u64 %r272,%r201,%r121;
@ %r272 bra $L9;
add.u64 %r202,%r119,-1;
add.u64 %r121,%r121,%r109;
set.u32.gt.u64 %r274,%r201,%r121;
neg.s32 %r275,%r274;
set.u32.le.u64 %r277,%r109,%r121;
neg.s32 %r278,%r277;
cvt.u16.u32 %r280,%r275;
cvt.u16.u32 %r281,%r278;
and.b16 %r279,%r280,%r281;
cvt.u32.u16 %r282,%r279;
cvt.u16.u8 %r283,%r282;
setp.eq.u16 %r284,%r283,0;
@ %r284 bra $L31;
add.u64 %r119,%r119,-2;
add.u64 %r121,%r121,%r109;
bra $L9;
$L31:
mov.u64 %r119,%r202;
$L9:
sub.u64 %r111,%r121,%r201;
shl.b64 %r285,%r118,32;
or.b64 %r114,%r285,%r119;
mov.u64 %r203,0;
bra $L10;
$L3:
.loc 1 1091 7
setp.ne.u64 %r286,%r109,0;
@ %r286 bra $L11;
.loc 1 1092 9
mov.u64 %r287,1;
div.u64 %r109,%r287,0;
$L11:
.loc 1 1094 4
mov.u64 %r173,56;
$L13:
cvt.u32.u64 %r289,%r173;
shr.u64 %r36,%r109,%r289;
and.b64 %r290,%r36,255;
setp.ne.u64 %r291,%r290,0;
@ %r291 bra $L12;
add.u64 %r173,%r173,-8;
setp.ne.u64 %r292,%r173,0;
@ %r292 bra $L13;
mov.u64 %r36,%r109;
$L12:
cvta.const.u64 %r293,__clz_tab;
add.u64 %r294,%r293,%r36;
ld.u8 %r295,[%r294];
add.u64 %r39,%r295,%r173;
mov.u64 %r297,64;
sub.u64 %r116,%r297,%r39;
.loc 1 1096 7
setp.ne.u64 %r298,%r297,%r39;
@ %r298 bra $L14;
.loc 1 1105 11
sub.u64 %r113,%r472,%r109;
.loc 1 1124 4
shr.u64 %r226,%r109,32;
and.b64 %r225,%r109,4294967295;
mov.u64 %r203,1;
bra $L15;
$L14:
.loc 1 1114 16
cvt.u32.u64 %r40,%r116;
.loc 1 1114 11
shl.b64 %r109,%r109,%r40;
.loc 1 1115 16
cvt.u32.u64 %r41,%r39;
.loc 1 1115 11
shr.u64 %r175,%r472,%r41;
.loc 1 1116 17
shl.b64 %r42,%r472,%r40;
.loc 1 1116 30
shr.u64 %r299,%r471,%r41;
.loc 1 1116 11
or.b64 %r176,%r299,%r42;
.loc 1 1117 11
shl.b64 %r110,%r471,%r40;
.loc 1 1119 8
shr.u64 %r226,%r109,32;
and.b64 %r225,%r109,4294967295;
rem.u64 %r177,%r175,%r226;
div.u64 %r123,%r175,%r226;
mul.lo.u64 %r178,%r225,%r123;
shl.b64 %r300,%r177,32;
shr.u64 %r301,%r176,32;
or.b64 %r125,%r300,%r301;
setp.le.u64 %r302,%r178,%r125;
@ %r302 bra $L16;
add.u64 %r179,%r123,-1;
add.u64 %r125,%r125,%r109;
set.u32.le.u64 %r304,%r109,%r125;
neg.s32 %r305,%r304;
set.u32.gt.u64 %r307,%r178,%r125;
neg.s32 %r308,%r307;
cvt.u16.u32 %r310,%r305;
cvt.u16.u32 %r311,%r308;
and.b16 %r309,%r310,%r311;
cvt.u32.u16 %r312,%r309;
cvt.u16.u8 %r313,%r312;
setp.eq.u16 %r314,%r313,0;
@ %r314 bra $L32;
add.u64 %r123,%r123,-2;
add.u64 %r125,%r125,%r109;
bra $L16;
$L32:
mov.u64 %r123,%r179;
$L16:
sub.u64 %r180,%r125,%r178;
rem.u64 %r181,%r180,%r226;
div.u64 %r124,%r180,%r226;
mul.lo.u64 %r182,%r225,%r124;
shl.b64 %r315,%r181,32;
and.b64 %r316,%r176,4294967295;
or.b64 %r126,%r315,%r316;
setp.le.u64 %r317,%r182,%r126;
@ %r317 bra $L17;
add.u64 %r183,%r124,-1;
add.u64 %r126,%r126,%r109;
set.u32.le.u64 %r319,%r109,%r126;
neg.s32 %r320,%r319;
set.u32.gt.u64 %r322,%r182,%r126;
neg.s32 %r323,%r322;
cvt.u16.u32 %r325,%r320;
cvt.u16.u32 %r326,%r323;
and.b16 %r324,%r325,%r326;
cvt.u32.u16 %r327,%r324;
cvt.u16.u8 %r328,%r327;
setp.eq.u16 %r329,%r328,0;
@ %r329 bra $L33;
add.u64 %r124,%r124,-2;
add.u64 %r126,%r126,%r109;
bra $L17;
$L33:
mov.u64 %r124,%r183;
$L17:
sub.u64 %r113,%r126,%r182;
shl.b64 %r330,%r123,32;
or.b64 %r203,%r330,%r124;
$L15:
.loc 1 1124 4
rem.u64 %r185,%r113,%r226;
div.u64 %r127,%r113,%r226;
mul.lo.u64 %r186,%r127,%r225;
shl.b64 %r331,%r185,32;
shr.u64 %r332,%r110,32;
or.b64 %r129,%r331,%r332;
setp.le.u64 %r333,%r186,%r129;
@ %r333 bra $L18;
add.u64 %r187,%r127,-1;
add.u64 %r129,%r129,%r109;
set.u32.gt.u64 %r335,%r186,%r129;
neg.s32 %r336,%r335;
set.u32.le.u64 %r338,%r109,%r129;
neg.s32 %r339,%r338;
cvt.u16.u32 %r341,%r336;
cvt.u16.u32 %r342,%r339;
and.b16 %r340,%r341,%r342;
cvt.u32.u16 %r343,%r340;
cvt.u16.u8 %r344,%r343;
setp.eq.u16 %r345,%r344,0;
@ %r345 bra $L34;
add.u64 %r127,%r127,-2;
add.u64 %r129,%r129,%r109;
bra $L18;
$L34:
mov.u64 %r127,%r187;
$L18:
sub.u64 %r188,%r129,%r186;
rem.u64 %r189,%r188,%r226;
div.u64 %r128,%r188,%r226;
mul.lo.u64 %r190,%r128,%r225;
shl.b64 %r346,%r189,32;
and.b64 %r347,%r110,4294967295;
or.b64 %r130,%r346,%r347;
setp.le.u64 %r348,%r190,%r130;
@ %r348 bra $L19;
add.u64 %r191,%r128,-1;
add.u64 %r130,%r130,%r109;
set.u32.gt.u64 %r350,%r190,%r130;
neg.s32 %r351,%r350;
set.u32.le.u64 %r353,%r109,%r130;
neg.s32 %r354,%r353;
cvt.u16.u32 %r356,%r351;
cvt.u16.u32 %r357,%r354;
and.b16 %r355,%r356,%r357;
cvt.u32.u16 %r358,%r355;
cvt.u16.u8 %r359,%r358;
setp.eq.u16 %r360,%r359,0;
@ %r360 bra $L35;
add.u64 %r128,%r128,-2;
add.u64 %r130,%r130,%r109;
bra $L19;
$L35:
mov.u64 %r128,%r191;
$L19:
sub.u64 %r111,%r130,%r190;
shl.b64 %r361,%r127,32;
or.b64 %r114,%r361,%r128;
$L10:
.loc 1 1223 17
mov.u64 %r204,%r114;
.loc 1 1129 10
setp.eq.u64 %r362,%r239,0;
@ %r362 bra $L20;
.loc 1 1131 18
cvt.u32.u64 %r364,%r116;
shr.u64 %r363,%r111,%r364;
.loc 1 1132 14
mov.u64 %r365,0;
.loc 1 1133 8
st.u64 [%r239],%r363;
st.u64 [%r239+8],%r365;
bra $L20;
$L2:
.loc 1 1140 10
setp.le.u64 %r368,%r474,%r472;
@ %r368 bra $L36;
.loc 1 1148 7
setp.eq.u64 %r369,%r239,0;
@ %r369 bra $L37;
.loc 1 1152 12
st.u64 [%r239],%r471;
st.u64 [%r239+8],%r472;
mov.u64 %r203,0;
mov.u64 %r204,%r203;
bra $L20;
$L36:
.loc 1 1159 4
mov.u64 %r140,56;
$L21:
cvt.u32.u64 %r373,%r140;
shr.u64 %r61,%r474,%r373;
and.b64 %r374,%r61,255;
setp.ne.u64 %r375,%r374,0;
@ %r375 bra $L22;
add.u64 %r140,%r140,-8;
setp.ne.u64 %r376,%r140,0;
@ %r376 bra $L21;
mov.u64 %r61,%r474;
$L22:
cvta.const.u64 %r377,__clz_tab;
add.u64 %r378,%r377,%r61;
ld.u8 %r379,[%r378];
add.u64 %r64,%r379,%r140;
mov.u64 %r381,64;
sub.u64 %r142,%r381,%r64;
.loc 1 1160 7
setp.ne.u64 %r382,%r381,%r64;
@ %r382 bra $L23;
.loc 1 1170 15
set.u32.lt.u64 %r384,%r474,%r472;
neg.s32 %r385,%r384;
.loc 1 1170 26
set.u32.le.u64 %r387,%r473,%r471;
neg.s32 %r388,%r387;
.loc 1 1170 20
cvt.u16.u32 %r390,%r385;
cvt.u16.u32 %r391,%r388;
or.b16 %r389,%r390,%r391;
.loc 1 1170 11
cvt.u32.u16 %r392,%r389;
cvt.u16.u8 %r393,%r392;
setp.eq.u16 %r394,%r393,0;
@ %r394 bra $L38;
.loc 1 1173 5
sub.u64 %r172,%r471,%r473;
sub.u64 %r68,%r472,%r474;
set.u32.lt.u64 %r396,%r471,%r172;
cvt.s64.s32 %r395,%r396;
add.u64 %r112,%r68,%r395;
mov.u64 %r110,%r172;
mov.u64 %r204,1;
bra $L24;
$L38:
mov.u64 %r204,%r142;
$L24:
.loc 1 1180 11
setp.eq.u64 %r398,%r239,0;
@ %r398 bra $L39;
.loc 1 1184 9
st.u64 [%r239],%r110;
st.u64 [%r239+8],%r112;
mov.u64 %r203,0;
bra $L20;
$L23:
.loc 1 1194 17
cvt.u32.u64 %r75,%r142;
shl.b64 %r76,%r474,%r75;
.loc 1 1194 30
cvt.u32.u64 %r77,%r64;
shr.u64 %r401,%r473,%r77;
.loc 1 1194 11
or.b64 %r143,%r401,%r76;
.loc 1 1195 11
shl.b64 %r144,%r473,%r75;
.loc 1 1196 11
shr.u64 %r145,%r472,%r77;
.loc 1 1197 17
shl.b64 %r79,%r472,%r75;
.loc 1 1197 30
shr.u64 %r402,%r471,%r77;
.loc 1 1197 11
or.b64 %r146,%r402,%r79;
.loc 1 1198 11
shl.b64 %r147,%r471,%r75;
.loc 1 1200 8
shr.u64 %r148,%r143,32;
and.b64 %r149,%r143,4294967295;
rem.u64 %r150,%r145,%r148;
div.u64 %r134,%r145,%r148;
mul.lo.u64 %r151,%r149,%r134;
shl.b64 %r403,%r150,32;
shr.u64 %r404,%r146,32;
or.b64 %r136,%r403,%r404;
setp.le.u64 %r405,%r151,%r136;
@ %r405 bra $L25;
add.u64 %r152,%r134,-1;
add.u64 %r136,%r136,%r143;
set.u32.gt.u64 %r407,%r151,%r136;
neg.s32 %r408,%r407;
set.u32.le.u64 %r410,%r143,%r136;
neg.s32 %r411,%r410;
cvt.u16.u32 %r413,%r408;
cvt.u16.u32 %r414,%r411;
and.b16 %r412,%r413,%r414;
cvt.u32.u16 %r415,%r412;
cvt.u16.u8 %r416,%r415;
setp.eq.u16 %r417,%r416,0;
@ %r417 bra $L40;
add.u64 %r134,%r134,-2;
add.u64 %r136,%r136,%r143;
bra $L25;
$L40:
mov.u64 %r134,%r152;
$L25:
sub.u64 %r153,%r136,%r151;
rem.u64 %r154,%r153,%r148;
div.u64 %r135,%r153,%r148;
mul.lo.u64 %r157,%r149,%r135;
shl.b64 %r418,%r154,32;
and.b64 %r419,%r146,4294967295;
or.b64 %r137,%r418,%r419;
setp.le.u64 %r420,%r157,%r137;
@ %r420 bra $L26;
add.u64 %r158,%r135,-1;
add.u64 %r137,%r137,%r143;
set.u32.le.u64 %r422,%r143,%r137;
neg.s32 %r423,%r422;
set.u32.gt.u64 %r425,%r157,%r137;
neg.s32 %r426,%r425;
cvt.u16.u32 %r428,%r423;
cvt.u16.u32 %r429,%r426;
and.b16 %r427,%r428,%r429;
cvt.u32.u16 %r430,%r427;
cvt.u16.u8 %r431,%r430;
setp.eq.u16 %r432,%r431,0;
@ %r432 bra $L41;
add.u64 %r135,%r135,-2;
add.u64 %r137,%r137,%r143;
bra $L26;
$L41:
mov.u64 %r135,%r158;
$L26:
sub.u64 %r159,%r137,%r157;
shl.b64 %r433,%r134,32;
or.b64 %r115,%r433,%r135;
.loc 1 1201 8
and.b64 %r161,%r135,4294967295;
shr.u64 %r162,%r115,32;
and.b64 %r163,%r144,4294967295;
shr.u64 %r164,%r144,32;
mul.lo.u64 %r165,%r161,%r163;
mul.lo.u64 %r167,%r162,%r163;
mul.lo.u64 %r138,%r162,%r164;
mad.lo.u64 %r205,%r161,%r164,%r167;
shr.u64 %r435,%r165,32;
add.u64 %r168,%r435,%r205;
setp.le.u64 %r436,%r167,%r168;
@ %r436 bra $L27;
add.u64 %r138,%r138,4294967296;
$L27:
shr.u64 %r437,%r168,32;
add.u64 %r132,%r437,%r138;
shl.b64 %r439,%r168,32;
and.b64 %r440,%r165,4294967295;
add.u64 %r169,%r439,%r440;
.loc 1 1203 11
setp.lt.u64 %r441,%r159,%r132;
@ %r441 bra $L28;
.loc 1 1203 27
set.u32.eq.u64 %r443,%r159,%r132;
neg.s32 %r444,%r443;
.loc 1 1203 39
set.u32.lt.u64 %r446,%r147,%r169;
neg.s32 %r447,%r446;
.loc 1 1203 33
cvt.u16.u32 %r449,%r444;
cvt.u16.u32 %r450,%r447;
and.b16 %r448,%r449,%r450;
.loc 1 1203 20
cvt.u32.u16 %r451,%r448;
cvt.u16.u8 %r452,%r451;
setp.eq.u16 %r453,%r452,0;
@ %r453 bra $L42;
$L28:
.loc 1 1205 7
add.u64 %r115,%r115,-1;
.loc 1 1206 5
sub.u64 %r133,%r169,%r144;
set.u32.lt.u64 %r455,%r169,%r133;
cvt.s64.s32 %r454,%r455;
sub.u64 %r457,%r143,%r454;
sub.u64 %r132,%r132,%r457;
bra $L29;
$L42:
.loc 1 1201 8
mov.u64 %r133,%r169;
$L29:
.loc 1 1223 17
mov.u64 %r204,%r115;
.loc 1 1212 11
setp.eq.u64 %r458,%r239,0;
@ %r458 bra $L43;
.loc 1 1214 5
sub.u64 %r170,%r147,%r133;
sub.u64 %r459,%r159,%r132;
set.u32.lt.u64 %r461,%r147,%r170;
cvt.s64.s32 %r460,%r461;
add.u64 %r171,%r459,%r460;
.loc 1 1215 20
shl.b64 %r463,%r171,%r77;
.loc 1 1215 32
shr.u64 %r464,%r170,%r75;
.loc 1 1215 26
or.b64 %r465,%r463,%r464;
.loc 1 1216 20
shr.u64 %r466,%r171,%r75;
.loc 1 1217 9
st.u64 [%r239],%r465;
st.u64 [%r239+8],%r466;
mov.u64 %r203,0;
bra $L20;
$L37:
mov.u64 %r203,%r239;
mov.u64 %r204,%r203;
bra $L20;
$L39:
mov.u64 %r203,%r239;
bra $L20;
$L43:
mov.u64 %r203,%r239;
$L20:
.loc 1 1224 12
st.u64 [%r234],%r204;
st.u64 [%r234+8],%r203;
.loc 1 1225 1
ret;
}

_udiv_w_sdiv.o/ 1608280949  0     0     100666  797       `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __udiv_w_sdiv
.visible .func (.param .u64 %value_out) __udiv_w_sdiv (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2, .param .u64 %in_ar3);
.file 1 "../../../../libgcc/libgcc2.c"
// BEGIN GLOBAL FUNCTION DEF: __udiv_w_sdiv
.visible .func (.param .u64 %value_out) __udiv_w_sdiv (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2, .param .u64 %in_ar3)
{
.reg .u64 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %ar3;
ld.param.u64 %ar3,[%in_ar3];
.loc 1 678 10
mov.u64 %value,0;
.loc 1 679 1
st.param.u64 [%value_out],%value;
ret;
}

reduction.o/    1608280949  0     0     100666  179       `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL VAR DEF: __reduction_lock
.visible .global .align 4 .u32 __reduction_lock[1];

mgomp.o/        1608280949  0     0     100666  263       `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL VAR DEF: __nvptx_uni
.visible .shared .align 4 .u32 __nvptx_uni[32];
// BEGIN GLOBAL VAR DEF: __nvptx_stacks
.visible .shared .align 8 .u64 __nvptx_stacks[32];

/0              1608280949  0     0     100666  421       `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __enable_execute_stack
.visible .func __enable_execute_stack (.param .u64 %in_ar0);
.file 1 "enable-execute-stack.c"
// BEGIN GLOBAL FUNCTION DEF: __enable_execute_stack
.visible .func __enable_execute_stack (.param .u64 %in_ar0)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.loc 1 10 1
ret;
}

emutls.o/       1608280950  0     0     100666  4715      `
// BEGIN PREAMBLE
.version 3.1
.target sm_30
.address_size 64
// END PREAMBLE
// BEGIN GLOBAL FUNCTION DECL: __emutls_get_address
.visible .func (.param .u64 %value_out) __emutls_get_address (.param .u64 %in_ar0);
.file 1 "../../../../libgcc/emutls.c"
// BEGIN GLOBAL FUNCTION DECL: __emutls_register_common
.visible .func __emutls_register_common (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2, .param .u64 %in_ar3);
// BEGIN GLOBAL FUNCTION DECL: __nvptx_malloc
.extern .func (.param .u64 %value_out) __nvptx_malloc (.param .u64 %in_ar0);
// BEGIN GLOBAL FUNCTION DECL: abort
.extern .func abort;
// BEGIN GLOBAL FUNCTION DECL: memcpy
.extern .func (.param .u64 %value_out) memcpy (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2);
// BEGIN GLOBAL FUNCTION DECL: memset
.extern .func (.param .u64 %value_out) memset (.param .u64 %in_ar0, .param .u32 %in_ar1, .param .u64 %in_ar2);
// BEGIN GLOBAL FUNCTION DEF: __emutls_get_address
.visible .func (.param .u64 %value_out) __emutls_get_address (.param .u64 %in_ar0)
{
.reg .u64 %value;
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %r22;
.reg .u64 %r23;
.reg .u64 %r34;
.reg .u64 %r35;
.reg .u64 %r36;
.reg .pred %r37;
.reg .pred %r38;
.reg .u64 %r40;
.reg .u64 %r41;
.reg .pred %r43;
.reg .u64 %r45;
.reg .u64 %r46;
.reg .u64 %r47;
.reg .pred %r49;
.reg .u64 %r50;
.reg .u64 %r51;
.reg .u64 %r52;
.reg .pred %r53;
.reg .u64 %r60;
.reg .u32 %r65;
.reg .u64 %r67;
mov.u64 %r36,%ar0;
.loc 1 131 37
ld.u64 %r35,[%r36+16];
.loc 1 131 10
setp.ne.u64 %r37,%r35,0;
@ %r37 bra $L1;
.loc 1 100 10
ld.u64 %r23,[%r36+8];
.loc 1 102 24
ld.u64 %r22,[%r36];
.loc 1 100 6
setp.gt.u64 %r38,%r23,8;
@ %r38 bra $L3;
.loc 1 102 13
add.u64 %r40,%r22,8;
{
.param .u64 %value_in;
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%r40;
call (%value_in),__nvptx_malloc,(%out_arg1);
ld.param.u64 %r41,[%value_in];
}
.loc 1 103 10
setp.ne.u64 %r43,%r41,0;
@ %r43 bra $L4;
$L6:
.loc 1 104 2
{
call abort;
trap;
// (noreturn)
exit;
// (noreturn)
}
$L4:
.loc 1 105 26
st.u64 [%r41],%r41;
.loc 1 106 11
add.u64 %r35,%r41,8;
bra $L5;
$L3:
.loc 1 110 49
add.u64 %r45,%r22,%r23;
.loc 1 110 13
add.u64 %r46,%r45,7;
{
.param .u64 %value_in;
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%r46;
call (%value_in),__nvptx_malloc,(%out_arg1);
ld.param.u64 %r47,[%value_in];
}
.loc 1 111 10
setp.eq.u64 %r49,%r47,0;
@ %r49 bra $L6;
.loc 1 113 70
add.u64 %r50,%r23,7;
add.u64 %r51,%r47,%r50;
.loc 1 114 11
neg.s64 %r52,%r23;
.loc 1 114 9
and.b64 %r35,%r51,%r52;
.loc 1 115 27
st.u64 [%r35+-8],%r47;
$L5:
.loc 1 118 10
ld.u64 %r34,[%r36+24];
.loc 1 118 6
setp.eq.u64 %r53,%r34,0;
@ %r53 bra $L7;
.loc 1 119 5
{
.param .u64 %value_in;
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%r35;
.param .u64 %out_arg2;
st.param.u64 [%out_arg2],%r34;
.param .u64 %out_arg3;
st.param.u64 [%out_arg3],%r22;
call (%value_in),memcpy,(%out_arg1,%out_arg2,%out_arg3);
ld.param.u64 %r60,[%value_in];
}
bra $L8;
$L7:
.loc 1 121 5
cvt.u32.u64 %r65,%r34;
{
.param .u64 %value_in;
.param .u64 %out_arg1;
st.param.u64 [%out_arg1],%r35;
.param .u32 %out_arg2;
st.param.u32 [%out_arg2],%r65;
.param .u64 %out_arg3;
st.param.u64 [%out_arg3],%r22;
call (%value_in),memset,(%out_arg1,%out_arg2,%out_arg3);
ld.param.u64 %r67,[%value_in];
}
$L8:
.loc 1 132 15
st.u64 [%r36+16],%r35;
$L1:
.loc 1 188 1
mov.u64 %value,%r35;
st.param.u64 [%value_out],%value;
ret;
}
// BEGIN GLOBAL FUNCTION DEF: __emutls_register_common
.visible .func __emutls_register_common (.param .u64 %in_ar0, .param .u64 %in_ar1, .param .u64 %in_ar2, .param .u64 %in_ar3)
{
.reg .u64 %ar0;
ld.param.u64 %ar0,[%in_ar0];
.reg .u64 %ar1;
ld.param.u64 %ar1,[%in_ar1];
.reg .u64 %ar2;
ld.param.u64 %ar2,[%in_ar2];
.reg .u64 %ar3;
ld.param.u64 %ar3,[%in_ar3];
.reg .u64 %r25;
.reg .u64 %r26;
.reg .u64 %r27;
.reg .u64 %r28;
.reg .u64 %r29;
.reg .pred %r30;
.reg .u64 %r31;
.reg .u64 %r32;
.reg .pred %r33;
.reg .pred %r34;
.reg .u64 %r35;
.reg .pred %r36;
mov.u64 %r25,%ar0;
mov.u64 %r26,%ar1;
mov.u64 %r27,%ar2;
mov.u64 %r28,%ar3;
.loc 1 194 6
ld.u64 %r29,[%r25];
setp.ge.u64 %r30,%r29,%r26;
@ %r30 bra $L13;
.loc 1 196 17
st.u64 [%r25],%r26;
.loc 1 197 18
mov.u64 %r31,0;
st.u64 [%r25+24],%r31;
$L13:
.loc 1 199 6
ld.u64 %r32,[%r25+8];
setp.ge.u64 %r33,%r32,%r27;
@ %r33 bra $L14;
.loc 1 200 16
st.u64 [%r25+8],%r27;
$L14:
.loc 1 201 6
setp.eq.u64 %r34,%r28,0;
@ %r34 bra $L12;
.loc 1 201 13
ld.u64 %r35,[%r25];
setp.ne.u64 %r36,%r35,%r26;
@ %r36 bra $L12;
.loc 1 202 16
st.u64 [%r25+24],%r28;
$L12:
.loc 1 203 1
ret;
}

